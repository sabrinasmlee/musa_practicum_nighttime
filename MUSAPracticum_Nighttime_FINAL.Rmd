---
title: 'After Hours: Studying nightlife mobility patterns in  Philadelphia, Pennsylvania'
author: "Maddy Kornhauser, Brian Rawn, Sabrina Lee"
date: "5/7/2021"
output: 
  html_document: 
        code_folding: hide
        toc: true
        toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	out.width = "100%"
)
```

```{r load packages, include=FALSE}
library(tidyverse)
library(tidycensus)
library(sf)
library(lubridate)
library(datetime)
library(viridis)
library(gridExtra)
library(kableExtra)
library(dplyr)
library(ggplot2)
library(gganimate)
library(FNN)
library(caret)
library(stargazer)
library(ranger)
library(tidymodels)
library(ggcorrplot)
library(vip)

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}
q5 <- function(variable) {as.factor(ntile(variable, 5))}
palette3 <- viridis_pal()(3)
palette5 <- viridis_pal()(5)
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}
mapTheme_dark <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_rect(fill = "black"),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "black"),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}


plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    dplyr::summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}

setwd("~/GitHub/musa_practicum_nighttime")
```

```{r load & wrangle data, include=FALSE}
dat <- read.csv("./data/moves_2018.csv")
data2020 <- read.csv("./data/moves_monthly2020.csv")

phila <- st_read("./demo/phila.geojson", quiet = TRUE)

dat2 <- dat %>% 
  dplyr::select(safegraph_place_id, 
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                visits_by_day, 
                poi_cbg, 
                visitor_home_cbgs, 
                visitor_daytime_cbgs, 
                visitor_work_cbgs, 
                visitor_country_of_origin,
                distance_from_home, 
                median_dwell, 
                bucketed_dwell_times, 
                related_same_day_brand, 
                related_same_month_brand, 
                popularity_by_hour, 
                popularity_by_day, 
                device_type) %>%
  left_join(., phila, by = "safegraph_place_id") %>% 
  st_as_sf() %>%
  st_transform('ESRI:102728')

#Block group shapefiles (projected & unprojected)
phl_cbg <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10))%>%
  st_transform('ESRI:102728') 
phl_cbg_unproj <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10),
         Lat = as.numeric(INTPTLAT10),
         Lon = as.numeric(INTPTLON10))

#Boundaries shapefiles (projected & unprojected)
phl_boundary <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728')

phl_boundary_unproj <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)

#Corridor shapefiles (projected & unprojected)
phl_corridors <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728') %>%
  mutate(corr_type = ifelse(CORRIDOR_TYPE == 1, "Neighborhood Subcenter", 
                            ifelse(CORRIDOR_TYPE == 2, "Neighborhood Center", 
                                   ifelse(CORRIDOR_TYPE == 3, "Community Center", 
                                          ifelse(CORRIDOR_TYPE == 4, "Regional Center", 
                                                 ifelse(CORRIDOR_TYPE == 5, "Superregional Center", 
                                                        ifelse(CORRIDOR_TYPE == 6, "Specialty Center", "Other")))))))

phl_corridors_unproj <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)

#Neighborhood shapefiles (projected & unprojected)
phl_nhoods <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE) %>%
  st_transform('ESRI:102728')
phl_nhoods_unproj <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE)

#Philadelphia zip codes
phl_zip <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/b54ec5210cee41c3a884c9086f7af1be_0.geojson", quiet = TRUE) %>%
  st_transform('ESRI:102728') %>%
  mutate(CODE = as.numeric(CODE))
```

# 1. Introduction

## 1.1 About This Project

This project is part of the Spring 2021 [Master of Urban Spatial Analytics Practicum course](https://pennmusa.github.io/MUSA_801.io/) at the University of Pennsylvania taught by Ken Steif, Michael Fichman, and Matthew Harris. We are incredibly thankful for their their time, knowledge, and generosity during this challenging and fully online semester. Additionally, we want to take this opportunity to thank Daniel Lodise & Dave Maynard from Philadelphia City Councilmember Isaiah Thomas' office for sharing their perspectives on policy decision-making for the nighttime economy. Additionally, we are incredibly grateful to Kae Anderson from the Fishtown Business Improvement District for fantastic insights about how economic development professionals manage corridors and make decisions. We also want to acknowledge Andrew Renninger and Eugene Chong for their invaluable support accessing the SafeGraph dataset that was integral to this project and sharing general knowledge about the dataset. 

Finally we want to acknowledge the support and feedback from our classmates in the MUSA and city planning programs at the University of Pennsylvania. We thank you for your help!

## 1.1 Abstract
This project studies nightlife mobility patterns in Philadelphia, Pennsylvania and develops a web aplication that predicts nightlife traffic to commercial corridors based on retail mix. This document provides an overview of the key takeaways from our analysis as well as an appendix at the end of the document including the code to replicate this analysis.

While nighttime activity is an important component to Philadelphia's economy, culture, and identity, there is limited empirical data available to help decisionmakers govern the nighttime economy. As a resulting, many of the logistical and policy decisions are largely based on emotional perceptions of the negative externalities of the nighttime economy, such as noise pollution and safety concerns. This project uses the novel SafeGraph dataset to analyze nighttime mobility patterns in Philadelphia and develop a model to predict nighttime trips to commercial corridors. Our model utilizes a variety of factors including retail mix, built environment features, and demographic data. Our findings indicate that changing the corridor retail mix impacts traffic during evening hours. Additionally, our research provides new quantitative insights into behavior of visitors during nighttime hours in Philadelphia which have important implications for economic development in the city, particuarly in the post COVID-19 climate.

## 1.2 Motivation

Broadly defined as economic activity that takes place during the evening hours and centered around food, drink and entertainment, the nighttime economy is an important component for any vibrant city. Philadelphia, the focus of this study, has a dynamic nightlife economy that features a dynamic arts and culture scene. In 2017, The Philadelphia Cultural Alliance estimated that [arts and culture in the city has a total economic impact of over $4 billion in the region](https://www.philaculture.org/why-arts-culture/prosperity). Philadelphia is also home to a renowned selection of restaurants that also have an important economic impact on the city. [A 2019 report by the Economy League of Greater Philadelphia and the Philadelphia Department of Public Health](https://economyleague.org/uploads/files/4171470634539374-goodeats-finalreport.pdf) estimated that food jobs account for 12% of all jobs in the city and food related businesses acount for 18% of all firms. These sectors are clearly and important piece of the wider economy with much of their activity and business taking place during the evening hours.

Despite Philadelphia's nighttime economy being both culturally and economically important to the city, there is relatively limited knowledge of the nighttime economy's impact at the neighborhoood or corridor scale. As many policy and logisitcal decisions governing the nighttime economy are drawn from perceptions of its negative externalities, such as noise pollution and safety concerns, there is a lack of data explaining the positive effects of the nighttime economy at this hyper-local level. Therefore, a key motivation of this project is to better understand how the nighttime economy contributes to corridor traffic, which we understand as a proxy for local economic activity. We hope that this research will help policy makers better weigh the costs and benefits when making decisions governing the nighttime economy.

A separate motivation for this project comes from the unprecedented economic shock of the COVID-19 pandemic beginning in March 2020 and continuing through the release of this report. As shown in the below Figure X.X, traffic to restaurants, bars and arts establishments have decreased by about 50% compared to 2018 measurements. While the days of the pandemic apear to wane in Philadelphia, there is still much uncertainty about how these esablishments will rebound from this unprecedented shock. As these business types that are integral to the nighttime economy largely depend on gathering large groups of people indoors, it is important to economic development professionals in Philadelphia have a deep understanding how the possible benefits of investing in this sector to help aid the city and local businesses from rebounding from this devasting economic event.

```{r COVID, echo=FALSE}
dat_2018 <- 
  dat %>% 
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2018 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_2018 <- dat_2018 %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                popularity_by_day,
                NightVisits2018) %>%
  rename(raw_visit_counts2018 = raw_visit_counts, 
         raw_visitor_counts2018 = raw_visitor_counts, 
         popularity_by_day2018 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7))

dat_2020 <- 
  data2020 %>% 
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2020 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_join <- dat_2020 %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                popularity_by_day,
                NightVisits2020) %>%
  rename(raw_visit_counts2020 = raw_visit_counts, 
         raw_visitor_counts2020 = raw_visitor_counts, 
         popularity_by_day2020 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7)) %>%
  inner_join(., dat_2018, by = c("safegraph_place_id", "month", "location_name")) %>%
  mutate(Month = case_when(month == "01" ~ "January",
                    month == "02" ~ "February",
                    month == "03" ~ "March",
                    month == "04" ~ "April",
                    month == "05" ~ "May", 
                    month == "06" ~ "Jun",
                    month == "07" ~ "May",
                    month == "08" ~ "May",
                    month == "09" ~ "May",
                    month == "10" ~ "May",
                    month == "11" ~ "May",
                    month == "12" ~ "May"))

dat_join <- dat_join %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                raw_visit_counts2018,
                raw_visit_counts2020,
                NightVisits2018,
                NightVisits2020,
                popularity_by_day2018,
                popularity_by_day2020,
                month) %>%
  left_join(., phila, by = "safegraph_place_id") %>% 
  st_as_sf() %>%
  st_transform('ESRI:102728') 

dat_citywide <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Separate by commercial use  
dat_citywide2 <- dat_join %>%
    filter(top_category == "Drinking Places (Alcoholic Beverages)" |
             top_category == "Restaurants and Other Eating Places" |
             top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
             top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
           top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
           top_category == "Performing Arts Companies" ~ "Arts")) %>%
    group_by(category, month) %>%
    summarize(Total_Visits2018 = sum(NightVisits2018),
              Total_Visits2020 = sum(NightVisits2020)) %>%
    mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100) 

#Generate lineplot
rbind(
  (dat_join %>% 
  group_by(month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100,
         category = "All")), 
  dat_citywide2) %>%
  ggplot(., aes(x = month, y = Percent_Change, group = category, color = category)) + 
  geom_line(lwd = 1.5) +
  geom_hline(yintercept=0, lwd = 1.5, linetype="dotted")+
  scale_color_manual(values = c("#d3d3d3", "#440154", "#21908C", "#FDE725")) +
  scale_x_discrete(name ="Month")+  
  scale_y_continuous(name ="Percent Change") +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X") +
  plotTheme()
```

## 1.3 Use Case

Our goal is to help business improvement districts (BIDs) and economic development professionals understand nightlife patterns across Philadelphia’s commercial corridors. Not only do we believe this insight will provide valuable and interesting findings that will deepen the understanding of evening traffic patterns, but also that this can help further recovery efforts following the COVID-19 pandemic. While we believe that there are many potential applications for this work, we envisioned the following speciifc uses for our research, analysis, and web application.

* Understand relative popularity of commercial corridors to inform decisions to grant licenses or small business assistance.
* Understand origins and demographics of visitors to more effectively target marketing resources. 
* Understand the effects of changing the nightlife retail mix in a given commercial corridor.

## 1.4 Summary of Methodology

In this study, we use a combination of public and private datasets to study nighttime trends across commercial corridors in Philadelphia. Our model predicts trips between the hours of 7PM and 12AM at the corridor level. After an iterative process of feature engineering, we built a model that ultimately combined features from Safegraph, the built environment, and demographic data. Ultimately, we embed this model into a [web application](*ADD URL HERE*) that allows users to understand the impact a corridor's retail mix on the evening trip traffic. While the model has limited accuracy and generalizability indicating that it requires continual calibration, this proof-of-concept web application is an important step in making informed, data-driven policy decisions in the nighttime economy.

This document walks through our model-building process in detail and includes relevant code to replicate our analysis. This code is available in the appendix at the end of the document.

# 2. The Data

## 2.1 The SafeGraph Dataset

SafeGraph is a novel data source that uses anonymized cell phone GPS data to record trips to commercial points of interest. For this project, we used two datasets from SafeGraph: the Monthly Patterns dataset and the Places dataset. For a given point of interest, the Monthly Patterns dataset tells us detailed infomration on the montly traffic patterns, such as the number of trips and visitors, the median distance travelled, the median time spent at the establishment, and the origin census block group. Complementing the Patterns dataset, the Places dataset provides detailed information about the given point of interest, including the business category, the hours open, business hours and other descriptive tags to help categorize the place.

The SafeGraph data are brand new and have numerous unexplored applications and insights. The dataset was essential to this project as it allowed us to see trip patterns with unprecedented detail and [far higher accuracy](https://www.safegraph.com/home2?utm_campaign=branded_exact&utm_term=safegraph&rm_ci=8481213813&rm_gid=88800951800&utm_medium=cpc&utm_source=google&utm_content=493407744937&utm_term=safegraph&rm_kw=safegraph&rm_mt=e&rm_n=g&rm_cr=493407744937device=c&creative=493407744937&placement=&gclid=Cj0KCQjw4cOEBhDMARIsAA3XDRh1mi035mxENy-peI5SMcH2K8moBuUyS0tonTvV9kOEO_7ybGvbIfcaAsSZEALw_wcB) than other mobility datasets. While SafeGraph is undoubtedly the cutting edge of mobility data, we encountered some limitations. Primarily, as the data is based on GPS data, it is inherently noisy with trips incorrectly attributed to certain points of interest. For example, if someone is waiting for a bus outside of an establishment, this may be recorded in the data as a trip to the establishment. In dense urban areas where points of interest may be located on multiple floors of the same building or in close proximity to one another, this may result in inaccurate counts across the dataset.

Separately, a substantial part of our app analyzes who many trips come from a given census block group. [Due to privacy concerns, SafeGraph only records census block groups with at least 2 devices and any census block group with less than 5 devices are reported as 4. This limits the resolution with which we can see low-traffic census block groups](https://docs.safegraph.com/v4.0/docs/places-manual#section-privacy).

## 2.2 Other Sources

We also used data from [Open Data Philly](https://www.opendataphilly.org/) to capture features in the built environment such as transit, park space, and building size. The dataset we used are summarized in the below table. While these features are relatively standard datasets, replicatng this analysis and model for other citys would require that they have similar sources available.

Finally, we used 2018 American Community Survey 5-Year Estimates to describe demographic data for each corridor

## 2.3 Philadelphia Commercial Corridors

As our model predicts nighttime trips at the commercial corridor level, we relied heavily on a shapefile from the City of Philadelphia's Planning department which demarcates individual corridors and districts throughout the city. According to the [available metadata](https://metadata.phila.gov/#home/datasetdetails/564236a55737e1f263ae5e3f/representationdetails/56423a4e902dbdd813db9a55/) "locations range from large, regional and specialty destinations to corridors that reflect the evolving economy, culture, and aesthetic traditions of surrounding neighborhoods." We also use the administrative corridor categories defined in the dataset. a description of these cateogries is included below

Corridor Type | Gross Leasable Area | Store Types
------------- | --------------------|-------------
Neighborhood Subcenter | 10,000 - 35,000 sq.ft. | Convenience store grocery, pharmacy, dry cleaner, deli, etc.
Neighborhood Center | 30,000 - 120,000 sq.ft. | Supermarket, variety store, bank, pharmacy, post office, etc.
Community Center | 100,000 - 500, 000 sq. ft. | Discount dept store, home improvement, "big boxes" or equiv., "power center"
Regional Center | 300,000 - 900,000+ sq.ft. | One or two full-line department stores or equivalent
Superregional Center | 500,000 - 2,000,000+ sq.ft. | Three or more full-line department stores or equivalent
Specialty Center | N/A | Specialty goods or services, dining, bars, amusements, arts, etc.

Figure X.X shows the different types of commercial corridors based on classification by Philadelphia.
```{r echo=FALSE}
phl_corridors %>%
  drop_na(corr_type) %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(aes(fill=factor(corr_type, 
                          levels=c("Neighborhood Subcenter",
                                   "Neighborhood Center",
                                   "Community Center",
                                   "Regional Center",
                                   "Superregional Center",
                                   "Specialty Center")), 
          color = factor(corr_type, 
                          levels=c("Neighborhood Subcenter",
                                   "Neighborhood Center",
                                   "Community Center",
                                   "Regional Center",
                                   "Superregional Center",
                                   "Specialty Center")))) +
  scale_fill_viridis_d() +
  scale_color_viridis_d()+
  labs(title = "Philadelphia Corridor Typologies",
       subtitle = "Figure X.X") +
  mapTheme() +
  theme(legend.position = "bottom",
        legend.title = element_blank())
```

# 3. Exploratory Data Analysis

Before explaining the model building process, it is important to understand the overall trends in the data. In addition to informing which variables to incorporate into the model, this section highlights the descriptive capabilities of the SafeGraph dataset. While our model uses a broad range of datasets to describe Philadelphia's socio-economic and built environment characteristics, this section primarily focuses on our analysis of the SafeGraph dataset.

Key findings from the below analysis include:

* While we primarily examine retaurants, bars, and arts establishments as the key business types that contribute to the nighttime economy, all three business types in Philadelphia generate traffic during all hours of the day. 
* COVID-19 has caused a drastic decrease in business traffic to the businesses we consider nightlife establishments. While the data indicate that arts establishments across Philadelphia were able to recover some of the loss towards the end of 2020, bars and restaurants maintained over a 50% decrease in traffic. This could be related to the relatively high risk associated with frequenting these establishment types.
* Of the six corridor types defined above, Regional and Superregional Centers have the highest share of traffic during the workday. Smaller corridors outside the central core of Philadelphia tend ot have a higher share of evening and early morning traffic. This suggests that people leave Center City outside of working hours.
* The volume of trips varies by corridor type. Regional and Superregional Centers tend to draw a higher volume of travellers, while the smaller neighborhood corridors draw fewer visitors. Community Centers and Specialty Centers fall somewhere in the middle.
* People travel further to the Center City area.

## 3.1 Philadelphia Nightlife Establishments

Our first research question is where Philadelphia nightlife establishments are located across the city. The following maps indicate where businesses that contribute to the city's nightlife economy are located. The categories include:

* Bars
* Restaurants 
* Arts Venues

Figure X.X below shows the spatial patterns of the business categories. Bars and restaurants represent the highest number of businesses which are spread across the city. Hotels are mostly clustered in the central district of the city and near the airport in the southwest portion of the city. There are far fewer casinos and arts venues.

Throughout the analysis, we pay special attention to bars and restaurants, as these organizations are well distributed throughout the city and apply to a local Philadelphia customer base.

```{r establishment locations, echo=FALSE}
dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
                              top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
                              top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
                              top_category == "Performing Arts Companies" ~ "Arts")) %>%
  ggplot() + 
  geom_sf(data = phl_cbg, fill = "grey80", color = "transparent") +
  geom_sf(color = "red", size = .1) +
  labs(title = "Location of Nightlife Establishments",
       subtitle = "Figure X.X") +
  facet_wrap(~category, nrow = 1) +
  mapTheme()
```

To look at the spatial distribution of business types another way, we review the distribution of businesses with a fishnet grid. The fishnet allows us to visualize clusters of each business type, as clusters are aggregated to the individual cell level. This allows us to more effectively see the density of these business types more effectively than the above Figure X.X. While all three business types are mostly concentrated within Center City, the below Figure X.X demonstrates how restaurants are most thoroughly distributed throughout Philadelphia. 
```{r unnesting hour dataset, echo=FALSE}
fishnet <- 
  st_make_grid(phl_boundary, cellsize = 1000, square = FALSE) %>%
  .[phl_boundary] %>% 
  st_sf() %>%
  mutate(uniqueID = rownames(.))

#Filter restaurants
restaurants <- dat2 %>%
  filter(top_category == "Restaurants and Other Eating Places")%>%
  mutate(Legend = "Restaurants")

#aggregate restaurant count by fishnet cell
restaurants_net <-
  dplyr::select(restaurants) %>% 
  mutate(countRestaurants = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRestaurants = replace_na(countRestaurants, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

#Bars
bars <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)") %>% 
  mutate(Legend = "Bars")

#aggregate bars by fishnet cell
bars_net <-
  dplyr::select(bars) %>% 
  mutate(countBars = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countBars = replace_na(countBars, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE)) %>%
  mutate(Legend = "Bars")

#Performing arts
performingarts <- dat2 %>%
  filter(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(Legend = "Performing Arts")

performingarts_net <-
  dplyr::select(performingarts) %>% 
  mutate(countPerformingarts = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countPerformingarts = replace_na(countPerformingarts, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

# Combining fishnets into a single dataframe
vars_net <- 
  rbind(restaurants, 
        bars, 
        performingarts) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  dplyr::summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(Legend,count, fill=0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup()

vars_net.long <- gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

#Plotting small multiple maps
for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange, c(mapList, 
                        ncol=3, top="Count of Nightlife Businesses per Fishnet", 
                        bottom = "Figure X.X"))
```

Figure X.X below breaks down the density of restaunts in a given corridor.  While centralized corridors tend to have more restaurants per square mile other smaller corridors in the city indicate a high concentration of restaurants as well. 
```{r}
st_join(phl_corridors, restaurants) %>%
  group_by(NAME.x) %>%
  summarize(count = n()) %>%
  st_as_sf() %>%
  mutate(area = st_area(geometry) * 3.587006427E-8,
         count_per_mile = as.numeric(count/ area)) %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80") +
  geom_sf(aes(fill = count_per_mile), color = "transparent") +
  scale_fill_viridis(trans = "sqrt",
                     name = "Count Per Sq. Mi.") +
  labs(title = "Restaurant Density by Commercial Corridor",
       subtitle = "Figure X.X") +
  mapTheme() 
```

Similar to the above, Figure X.X shows the density of bars along each commercial corridor. Again, we see the corridors around Center City generally showing a higher concentration of bars. Distinct from the restaurant density map in Figure X.X above, there seem to be many more corridors with a low density of bars. 
```{r Bars by corridor, echo=FALSE}
st_join(phl_corridors, bars) %>%
  group_by(NAME.x) %>%
  summarize(count = n()) %>%
  st_as_sf() %>%
  mutate(area = st_area(geometry) * 3.587006427E-8,
         count_per_mile = as.numeric(count/ area)) %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80") +
  geom_sf(aes(fill = count_per_mile), color = "transparent") +
  scale_fill_viridis(trans = "sqrt",
                     name = "Count Per Sq. Mi.") +
  labs(title = "Bar Density by Commercial Corridor",
       subtitle = "Figure X.X") +
  mapTheme() 
```

Finally, Figure X.X below shows the density of arts venues by commercial corridor. The majority of corridors have a very low density of performing arts establishments as there are fewer destinations across the city.
```{r echo=FALSE}
st_join(phl_corridors, performingarts) %>%
  group_by(NAME.x) %>%
  summarize(count = n()) %>%
  st_as_sf() %>%
  mutate(area = st_area(geometry) * 3.587006427E-8,
         count_per_mile = as.numeric(count/ area)) %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80") +
  geom_sf(aes(fill = count_per_mile), color = "transparent") +
  scale_fill_viridis(trans = "sqrt",
                     name = "Count Per Sq. Mi.") +
  labs(title = "Arts Venue Density by Commercial Corridor",
       subtitle = "Figure X.X") +
  mapTheme() 
```

## 3.2 The Impacts of COVID-19 on Nightlife Establishments & Commercial Corridors

Now that we have investigated the distribution of nightlife establishments across Philadelphia, it is important to understand how these establishments have been impacted by theCOVID-19 pandemic. Using SafeGraph data, we are able to see that the pandemic has a drastic impact in foot traffic across sectors and space, though not necessarily evenly.
```{r data wrangling for COVID-19, include=FALSE}
# # Modify 2018 data
# dat_2018 <- 
#   dat %>% 
#   mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
#   unnest(popularity_by_hour) %>% #unnest values
#   separate(.,
#            popularity_by_hour,
#            c("18",
#              "19", "20", "21", "22", "23"),
#            sep = ",") %>%
#   mutate(.,NightVisits2018 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))
# 
# dat_2018 <- dat_2018 %>% 
#   dplyr::select(safegraph_place_id, 
#                 location_name,
#                 date_range_start, 
#                 date_range_end, 
#                 raw_visit_counts,
#                 raw_visitor_counts, 
#                 popularity_by_day,
#                 NightVisits2018) %>%
#   rename(raw_visit_counts2018 = raw_visit_counts, 
#          raw_visitor_counts2018 = raw_visitor_counts, 
#          popularity_by_day2018 = popularity_by_day) %>%
#   mutate(month = substring(date_range_start,6,7))
# 
# dat_2020 <- 
#   data2020 %>% 
#   mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
#   unnest(popularity_by_hour) %>% #unnest values
#   separate(.,
#            popularity_by_hour,
#            c("18",
#              "19", "20", "21", "22", "23"),
#            sep = ",") %>%
#   mutate(.,NightVisits2020 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))
# 
# dat_join <- dat_2020 %>% 
#   dplyr::select(safegraph_place_id, 
#                 location_name,
#                 date_range_start, 
#                 date_range_end, 
#                 raw_visit_counts,
#                 raw_visitor_counts, 
#                 popularity_by_day,
#                 NightVisits2020) %>%
#   rename(raw_visit_counts2020 = raw_visit_counts, 
#          raw_visitor_counts2020 = raw_visitor_counts, 
#          popularity_by_day2020 = popularity_by_day) %>%
#   mutate(month = substring(date_range_start,6,7)) %>%
#   inner_join(., dat_2018, by = c("safegraph_place_id", "month", "location_name")) %>%
#   mutate(Month = case_when(month == "01" ~ "January",
#                     month == "02" ~ "February",
#                     month == "03" ~ "March",
#                     month == "04" ~ "April",
#                     month == "05" ~ "May", 
#                     month == "06" ~ "Jun",
#                     month == "07" ~ "May",
#                     month == "08" ~ "May",
#                     month == "09" ~ "May",
#                     month == "10" ~ "May",
#                     month == "11" ~ "May",
#                     month == "12" ~ "May"))
# 
# dat_join <- dat_join %>% 
#   dplyr::select(safegraph_place_id, 
#                 location_name,
#                 raw_visit_counts2018,
#                 raw_visit_counts2020,
#                 NightVisits2018,
#                 NightVisits2020,
#                 popularity_by_day2018,
#                 popularity_by_day2020,
#                 month) %>%
#   left_join(., phila, by = "safegraph_place_id") %>% 
#   st_as_sf() %>%
#   st_transform('ESRI:102728') 
```

First, we observe citywide changes in foot traffic over the course of the pandemic. Comparing 2020 traffic to our 2018 dataset, we see that traffic across the city drastically decreased in March 2020 and represented less then half of the 2018 traffic. This trend continued thorughout the year.
```{r echo=FALSE}
#Citywide nighttime visits
# dat_citywide <- dat_join %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)" |
#            top_category == "Restaurants and Other Eating Places" |
#            top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
#            top_category == "Performing Arts Companies") %>%
#   group_by(month) %>%
#   summarize(Total_Visits2018 = sum(NightVisits2018),
#             Total_Visits2020 = sum(NightVisits2020)) %>%
#   mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot citywide chart
dat_citywide %>%
ggplot(., aes(x = month, y = Percent_Change, fill = Percent_Change)) + 
  geom_col() +
  scale_fill_viridis_c() +
  # scale_fill_distiller(palette="viridis", direction = 1) +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X", y = "Percent Change", x = "Month") +
  plotTheme() 
```

The next graphics splits out the percent change in traffic by the business types relevant to our nightlife study: arts establishments, bars, and restaurants. The data show arts establishments were able recover some of its traffic towards the end of 2020. Bars and restaurants, on the other hand, suffered the decreased traffic volumes throughout the end of the year. One possible explanation for this trend is that it may be more likely for arts establishments to hold programming while adhering to COVID-19 safety standards (e.g. mask-wearing and social distancing). Restaurants and bars in Philadelphia, are often in smaller spaces and require that visitors remove masks to partake in the experience. 
```{r echo=FALSE}
#Separate by commercial use  
dat_citywide2 <- dat_join %>%
    filter(top_category == "Drinking Places (Alcoholic Beverages)" |
             top_category == "Restaurants and Other Eating Places" |
             top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
             top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
           top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
           top_category == "Performing Arts Companies" ~ "Arts")) %>%
    group_by(category, month) %>%
    summarize(Total_Visits2018 = sum(NightVisits2018),
              Total_Visits2020 = sum(NightVisits2020)) %>%
    mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)  
  
#Plot citywide chart by commercial use
dat_citywide2 %>%
  ggplot(., aes(x = month, y = Percent_Change, fill = Percent_Change)) + 
  geom_col() +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X") +
  scale_fill_viridis_c() +
  # scale_fill_distiller(palette="PiYG", direction = 1) +
  facet_wrap(~category) +
  plotTheme() +
  theme(legend.position = "bottom")
```

In addition to looking at traffic by business type, the data allows us to view change in business traffic across space. The below Figure X.X shows the change in census block group traffic where the three business types are located. Dark grey areas indicate that no place that fits the business category is location in that census block group. While there are a few exceptions, almost all block groups show a sharp decrease in business traffic, many by well over 50%. The following Figure X.X aggregates the change in traffic across all nightlife business categories, underscoring the drastic economic impact the pandemic has had on businesses across the city.
```{r echo=FALSE}
# dat_join %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)" |
#              top_category == "Restaurants and Other Eating Places" |
#              top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
#              top_category == "Performing Arts Companies") %>%
#   mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
#            top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
#            top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
#            top_category == "Performing Arts Companies" ~ "Arts")) %>%
#   filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
#   mutate(GEOID10 = as.numeric(GEOID)) %>%
#   group_by(GEOID10, category) %>%
#   summarize(Total_Visits2018 = sum(NightVisits2018),
#             Total_Visits2020 = sum(NightVisits2020)) %>%
#   st_drop_geometry() %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100, 
#          percent_change = case_when(Percent_Change > 100 ~ 100, Percent_Change <= 100 ~ Percent_Change)) %>%
#   ggplot() + 
#   geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
#   geom_sf(aes(fill = percent_change), color = "transparent") + 
#   scale_fill_distiller(palette="RdYlGn", direction = 1) +
#   labs(title = "Nightlife Establishment Trip  % Change, 2018 & 2020",
#        subtitle = "Figure X.X") +
#   facet_wrap(~category) +
#   mapTheme()

dat_night <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
             top_category == "Restaurants and Other Eating Places" |
             top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
             top_category == "Performing Arts Companies") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  group_by(GEOID10) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  st_drop_geometry() %>%
  left_join(phl_cbg) %>% 
  st_as_sf() %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot map
dat_night %>%  
  mutate(percent_change = case_when(Percent_Change > 100 ~ 100, 
                                    Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
  geom_sf(aes(fill = percent_change), color = "transparent") + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Nightlife Trip % Change, 2018 & 2020") +
  mapTheme()
```

Finally, we are interested to see how this impacts individual commercial corridors across Philadelphia. The below map shows decrease of traffic to nightlife establishments along such corridors. While some smaller corridors did not experience much change in traffic or even a small increase in traffic, the majority of corridors saw a large decrease in traffic. This is particularly evident in Center City, along Market Street in West Philadelphia and at the airport in far Southwest Philadelphia. 
```{r corridor analysis}
corridors_filter <- phl_corridors %>%
  select(OBJECTID, NAME, GLA, P_DIST, ST_EXT, PT_ADD, VAC_RATE) %>%
  mutate(VAC_RATE = str_remove_all(VAC_RATE, pattern = "%")) %>%
  mutate(VAC_RATE = as.numeric(VAC_RATE)) %>%
  st_as_sf() %>%
  st_transform('ESRI:102728') 
  
dat_corr <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  st_join(corridors_filter) %>% 
  group_by(NAME.y, month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100) %>%
  drop_na(NAME.y) %>%
  st_as_sf() %>%
  st_transform('ESRI:102728') %>%
  st_drop_geometry() 

dat_corr <- dat_corr %>%
  mutate(NAME = NAME.y) %>%
  left_join(corridors_filter)

#Average across all months
dat_corr_avg <- dat_corr %>%  
  group_by(NAME) %>%
  summarize(Percent_Change = mean(Percent_Change))

#All Commercial Uses Corridor Map
dat_corr %>%  
  filter(month == "04") %>%
  mutate(Percent_Change = case_when(Percent_Change > 100 ~ 100, 
                                    Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey20", color = "darkgrey")+
  geom_sf(aes(fill = Percent_Change, color = Percent_Change, geometry = geometry)) + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  scale_color_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Commercial Nighttime Trip % Change, April 2018 & 2020") +
  mapTheme()
```

## 3.3 Hourly Traffic Volume Across Corridor and Business Category

Next we wanted to understand the hourly traffic patterns of the nightlife establishments and corridor types that we are studying in this project. Figure X.X shows the average daily foot traffic by business type. This graphic indicates that though certain business types are considererd part of the nightlife economy, they do not exclusively experience traffic in the evenings. Restaurants are a good example of this, where the data indicates that the highest levels of traffic occur in the middle of the day. Arts venues, on the other hand, have a clear patterns indicating that they are more popular later in the day.
```{r traffic by nightlife establishment, echo=FALSE}
#Unnesting popularity by hour variable
dat_hour <- 
  dat2 %>% 
  select(safegraph_place_id, 
         date_range_start, 
         top_category, 
         sub_category, 
         popularity_by_hour, 
         poi_cbg, 
         median_dwell) %>% #select variables
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #clean-up
  unnest(popularity_by_hour) %>% #unnest
  separate(.,
           popularity_by_hour,
           c("0", "1", "2", "3", "4", "5", "6", 
             "7", "8", "9", "10", "11", "12", 
             "13", "14", "15", "16", "17", "18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>% #separate hour values into individual columns
  pivot_longer(cols = 4:27, names_to = "Hour", values_to = "Count") %>% #convert to long format
  mutate(Hour = as.numeric(Hour),
         Count = as.numeric(Count)) #convert hour trip counts to numeric values

dat_hour %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
                              top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
                              top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
                              top_category == "Performing Arts Companies" ~ "Arts")) %>%
  group_by(Hour, category) %>%
  dplyr::summarize(Count = mean(Count)) %>%
  ggplot(., aes(x = Hour, y = Count)) + 
  geom_col() +
  labs(title = "Philadelphia Nightlife Organizations, Average Traffic by Hour",
       subtitle = "Figure X.X") +
  facet_wrap(~category, scales = "free") +
  plotTheme()
```

The following animation shows restaurant visitor counts by census block group over the course of the day. We observe the highest amount of traffic in center city in the middle of the day and then a resurgence of traffic elsewhere in the city in the evening. This suggests that people dine at neighborhood establishments close to their home in the evening.
```{r}
# dat_restaurants <-
#   dat_hour %>%
#   filter(top_category == "Restaurants and Other Eating Places") 
# 
# dat_restaurant_filter <-
#   dat_restaurants %>%
#   dplyr::rename(., GEOID10 = poi_cbg) %>%
#   dplyr::group_by(GEOID10, Hour) %>%
#   dplyr::summarize(Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count)) %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Visits_Per_Area = Total_Visits / Shape__Area * 100)
# 
# #Animation of restaurant popularity by hour
# restaurant.animation.data <-
#     dat_restaurant_filter %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area < .4 ~ "5",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.8 ~ "4",
#                               Visits_Per_Area >= .8 & Visits_Per_Area <1.2 ~ "3",
#                               Visits_Per_Area >= 1.2 & Visits_Per_Area <1.6 ~ "2",
#                               Visits_Per_Area >= 2 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# restaurant_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent") +   
#   geom_sf(data = restaurant.animation.data, aes(fill = Pop_String), color = "transparent") +
#     scale_fill_manual(values = palette5) +
#     labs(title = "Restaurant Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
#   
# 
# animate(restaurant_animation, duration=20, renderer = gifski_renderer())
```

The following animation shows the same metric for bars. We observe traffic increasing throughout the day starting in the afternoon.
```{r bar animation}
# #Bar Analysis
# #Filter Bars
# dat_bars <- dat_hour %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)") 
# 
# #Merge CBGs with popularity by hour data
# dat_bars_filter <-
#   dat_bars %>%
#   dplyr::rename(., GEOID10 = poi_cbg) %>%
#   dplyr::group_by(GEOID10, Hour) %>%
#   dplyr::summarize(Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count)) %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Visits_Per_Area = Total_Visits / Shape__Area * 100)
# 
# #Animation of bar popularity by hour
# bar.animation.data <-
#     dat_bars_filter %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area == 0 ~ "5",
#                               Visits_Per_Area > 0 & Visits_Per_Area <.2 ~ "4",
#                               Visits_Per_Area >= .2 & Visits_Per_Area <.4 ~ "3",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.6 ~ "2",
#                               Visits_Per_Area >= .6 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# bar_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent", ) +
#   geom_sf(data = bar.animation.data, aes(fill = Pop_String), color = "transparent") +
#     scale_fill_manual(values = palette5) +
#     labs(title = "Bar Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
# 
# animate(bar_animation, duration=20, renderer = gifski_renderer())
```

To further understand the role of nightlife for the different corridors across Philadelphia, we examine traffic by time of day for the six different corridor times introduced above. Figure X.X below aggregates the data by corridor type and shows the share of daily traffic. We see that Regional Centers and Superregional Centers, larger corridors that tend to be located closer to Center City demonstrate the highest share of day time traffic between the hours of 6AM and 6PM. This makes sense, as these are the city's major job hubs that attract a large share of the city's day time traffic.  Smaller corridors, such as the Neighborhood Subcetners and Neighborhood Centers, demonstrate a more signficant share of their overall traffic occuring during the early morning and evening hours between 6PM and 6AM. The higher share of evening traffic in these areas suggests that the city's nighttime economy is relatively active in the smaller corridors outside of Center City.

```{r wrangling new hour variables, include=FALSE}
dat_1_6 <- dat_hour %>%
  #select trip counts between the hours of 1AM and 6AM
  filter(Hour == "1" | Hour == "2" | Hour == "3" | Hour == "4" | Hour == "5" | Hour == "6") %>% 
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs1_6 = sum(Count)) 

dat_7_12 <- dat_hour %>%
  #select trip counts between the hours of 7AM and 12PM
  filter(Hour == "7" | Hour == "8" | Hour == "9" | Hour == "10" | Hour == "11" | Hour == "12") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs7_12 = sum(Count)) 

dat_13_18 <- dat_hour %>%
  #select trip counts between the hours of 1PM and 6PM
  filter(Hour == "13" | Hour == "14" | Hour == "15" | Hour == "16" | Hour == "17" | Hour == "18") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs13_18 = sum(Count)) 

dat_19_0 <- dat_hour %>%
  #select trip counts between the hours of 6PM and 12AM
  filter(Hour == "19" | Hour == "20" | Hour == "21" | Hour == "22" | Hour == "23" | Hour == "0") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs19_0 = sum(Count)) 

dat_workday <- dat_hour %>%
  #select trip counts between workday hours of 9AM and 6PM
  filter(Hour == "9" | Hour == "10" | Hour == "11" | Hour == "12" | Hour == "13" | Hour == "14" |Hour == "15" | Hour == "16" |Hour == "17" |Hour == "18") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs_workday = sum(Count))

#Combine into new dataset with hour trip counts and corridor + neighborhood information
dat3 <- 
  dat2 %>% 
  left_join(dat_1_6, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_7_12, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_13_18, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_19_0, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_workday, by = c('safegraph_place_id', 'date_range_start')) %>%
  st_join(phl_corridors, join = st_intersects) %>%
  st_join(phl_nhoods, join = st_intersects)
```

```{r echo=FALSE}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  group_by(corr_type) %>%
  summarise(Early_AM = sum(Hrs1_6),
            Late_AM = sum(Hrs7_12),
            Early_PM = sum(Hrs13_18),
            Late_PM = sum(Hrs19_0)) %>%
  pivot_longer(cols = 2:5,
               names_to = "Time",
               values_to = "Traffic") %>%
  ggplot(aes(fill=factor(Time, levels=c("Late_PM", 
                                        "Early_PM", 
                                        "Late_AM", 
                                        "Early_AM")), 
             y=Traffic, 
             x=factor(corr_type, levels=c("Specialty Center",
                                          "Superregional Center",
                                          "Regional Center",
                                          "Community Center",
                                          "Neighborhood Center",
                                          "Neighborhood Subcenter")))) + 
  geom_bar(position="fill", stat="identity") +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(title = "Share of Traffic by Time of Day Across Corridor Types",
       subtitle = "Figure X.X") +
  plotTheme() +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

The below Figure X.X looks into the daiy traffic patterns in greater detail and breaks out daily traffic pattern by each corridor type and specifically for the traffic to the specific business categories we are studying.  Based on this graphic, Arts Centers in Neighborhood Centers,Specialty Centers, and Superregional Cetners receive the highest share of evening traffic of the groups that we are looking at. It is worth noting that the arts category is our smallest group of business types, so a certain establishment might be skewing these results. 

Restaurants and bars are more evenly split throughout the day. Notably, restaurants in Regional Centers serve the highest share of day time traffic of the six corridor types. It is also clear that bars tend to have higher traffic in the evening than other business types.
```{r}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = ifelse(top_category == "Drinking Places (Alcoholic Beverages)", "Bars",
                           ifelse(top_category == "Restaurants and Other Eating Places", "Restaurants",
                                  ifelse(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
                                           top_category == "Performing Arts Companies", "Arts", "Other")))) %>%
  group_by(corr_type, category) %>%
  summarise(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  pivot_longer(cols = 3:6,
               names_to = "Time",
               values_to = "Traffic") %>%
  ggplot(aes(fill=factor(Time, levels=c("Hrs19_0", "Hrs13_18", "Hrs7_12", "Hrs1_6")), 
             y=Traffic, 
             x=category)) + 
  geom_bar(position="fill", stat="identity") +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(title = "Total Daily Traffic Volume by Corridor Type",
       subtitle = "Figure X.X") +
  facet_wrap(~factor(corr_type,levels=c("Neighborhood Subcenter",
                                        "Neighborhood Center",
                                        "Community Center",
                                        "Regional Center", 
                                        "Superregional Center", 
                                        "Specialty Center"))) +
  guides(fill=guide_legend(title=NULL)) +
  plotTheme()
```

The below Figure X.X shows that Neighborhood Subcenters and Superregional Centers have the highest shares of traffic between the hours of 7PM and 12AM. Regional Centers, on average, have a substantially lower share of evening traffic at just over 12%. That being said, there is not huge variation amongst the different corridor types indicating that nighttime traffic occurs in many different space and in different corridor types throughout the city.
```{r bar plot}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  group_by(corr_type) %>%
  summarize(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  mutate(TotalTrips = Hrs1_6 + Hrs7_12 + Hrs13_18 + Hrs19_0,
         Pct.EveningTrips = Hrs19_0 / TotalTrips *100) %>%
  ggplot(aes(y = Pct.EveningTrips, x=factor(corr_type, 
                                            levels=c("Neighborhood Subcenter",
                                                     "Neighborhood Center",
                                                     "Community Center",
                                                     "Regional Center",
                                                     "Superregional Center",
                                                     "Specialty Center")))) +
  geom_bar(stat = "identity") + 
  geom_text(aes(label=round(Pct.EveningTrips, digits = 1)), vjust=1.6, color="white", size=3.5)+
  labs(title = "Share of Total Trips that Occur During the Evening Hours by Corridor Type",
       subtitle = "Figure X.X") +
  plotTheme() +
  scale_x_discrete(name ="Corridor Type")+  
  scale_y_continuous(name ="Percent of Trips during Evening")
```

Finally, the below map shows which corridors have a higher share of evening traffic. The dark purple, representing the lowest quintile of evening traffic is largely concentrated in Center City, suggesting that typically people leave the area after work hours without hanging around to frequent businesses. Interestingly, the waterfront corridors directly to the east of Center City are in the highest quintile for nighttime traffic. This suggests that the program of these corridors is quite distinct from their neighbors.
```{r map}
dat3 %>%
  group_by(NAME.y) %>%
  summarize(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  mutate(TotalTrips = Hrs1_6 + Hrs7_12 + Hrs13_18 + Hrs19_0,
         Pct.EveningTrips = Hrs19_0 / TotalTrips *100) %>%
  st_drop_geometry() %>%
  dplyr::rename(NAME = NAME.y) %>%
  left_join(phl_corridors %>% select(NAME, geometry)) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = 'grey80', color = 'grey40') +
  geom_sf(aes(fill = q5(Pct.EveningTrips), color = q5(Pct.EveningTrips))) +
  scale_fill_manual(values = palette5,
                    aesthetics = "fill",
                    name = "Share of Evening Trips \n(Quintile)") +
  scale_color_manual(values = palette5,
                    aesthetics = "colour",
                    name = "Share of Evening Trips \n(Quintile)") +
  labs(title = "Share of Total Trips that Occur During \nthe Evening Hours (Quintile)",
       subtitle = "Figure X.X") +
  mapTheme() +
  theme(legend.position = "bottom")
```

## 3.4 Trip Flows: Origins & destinations

One of the fascinating features of the SafeGraph dataset is its ability to capture flows of traffic across space by connecting a series of origins and destinations. By mapping the origins and destinations of trips taking place across Philadelphia, we can observe which regions of the city draw from a larger crowd across the city, and which areas cater to a more local population.

To study these trends in the data, we chose a selection of representative corridors that represented each of the six corridor types and were located within the central core of the city. The selected corridors and corridor type are listed below. Though we only show a subset of the corridors here, this information is available for all Philadelphia commercial corridors on our app.

Corridor Name | Corridor Type
------------- | --------------
South Street/16th-21st | Neighborhood Subcenter
Fairmount/19th-25th | Neighborhood Center
Central Waterfront/Washington | Community Center
Market West | Regional Center
Market East | Superregional Center
Old City | Specialty Center


Figures X.X below shows the volume of visitors to the selected corridors by census block group. [While visitors from across the city frequent East Girard corridor, particularly for its restaurants, Figure X.X clarifies that the corridor mostly caters to a local customer base of surrounding census tracts.] Block groups shaded grey indicate that no resident made a trip to the corridor.

```{r CBG data wrangling}
corr_select <-
  phl_corridors %>%
  filter(NAME == "South Street/16th-21st" | #Neighborhood Subcenter
           NAME == "Fairmount/19th-25th" | #Neighborhood Center
           NAME == "Central Waterfront/Washington" | #Community Center
           NAME == "Market West" | #Regional Center
           NAME == "Market East" | #Superregional Center
           NAME == "Old City") %>% #Specialty Center
  st_as_sf()

dat_corr_select <- dat3[corr_select,]

corr_select_cbg <-
  dat_corr_select %>%
  select(safegraph_place_id,
         date_range_start,
         top_category,
         sub_category,
         visitor_home_cbgs,
         NAME.y,
         geometry) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
         top_category == "Restaurants and Other Eating Places" |
         top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
         top_category == "Performing Arts Companies") %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\[|\\]")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\{|\\}")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = '\\"|\\"')) %>%
  mutate(visitor_home_cbgs = str_split(visitor_home_cbgs, pattern = ",")) %>%
  unnest(visitor_home_cbgs) %>%
  separate(.,
           visitor_home_cbgs,
           c("cbg_origin", "visitors"),
           sep = ":") %>%
  mutate(cbg_origin = as.numeric(cbg_origin),
         visitors = as.numeric(visitors)) 

corr_select_cbg_map <-  
  corr_select_cbg %>%
  dplyr::group_by(cbg_origin, NAME.y) %>%
  dplyr::summarize(visitors = sum(visitors)) %>%
  st_drop_geometry() %>%
  dplyr::rename(., GEOID10 = cbg_origin) %>%
  left_join(phl_cbg, by = "GEOID10") %>%
  st_as_sf() %>%
  drop_na(geometry) %>%
  mutate(corr_type = case_when(NAME.y == "South Street/16th-21st" ~ "Neighborhood Subcenter",
                               NAME.y == "Fairmount/19th-25th"~ "Neighborhood Center",
                               NAME.y == "Central Waterfront/Washington" ~ "Community Center",
                               NAME.y == "Market West" ~ "Regional Center",
                               NAME.y == "Market East" ~ "Superregional Center",
                                NAME.y == "Old City" ~ "Specialty Center")) 

corr_select_cbg_map %>%
  ggplot() +
  geom_sf(data = phl_cbg, fill = "grey70", color = "transparent") +
  geom_sf(aes(fill = q5(visitors), geometry = geometry), color = "transparent") +
  # geom_sf(data = phl_nhoods, color = "white", fill = "transparent") +
  # geom_sf(data = EastGirard_corr, color = "red", fill = "transparent", lwd = 1) +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Visitor Count \n(Quintile)") +
  mapTheme() +
  labs(title = "Where do nightlife visitors come from? (Quintile)",
       subtitle = "Figure X.X") +
  facet_wrap(~factor(corr_type, 
                     levels=c("Neighborhood Subcenter",
                              "Neighborhood Center",
                              "Community Center",
                              "Regional Center",
                              "Superregional Center",
                              "Specialty Center")))
```

Visualizing the origins and destinations in another way, the following maps look at the origins and destinations for trips to restaurants, bars, and arts venues across the city. Specifically, it shows the distance between the centroid of the origin neighborhood to the centroid of the destination commercial corridor. We selected 6 corridors across Philadelphia in different areas of the city that we felt represented a diverse array of commercial corridors in the city. Not that any trips from outside of the city are not included in this graphic.

For this graphic we chose six different corridor types located within the Center City District as a representative sample. The graphic demonstrates how traffic flows change across corridor types, with the larger corridors generating far more traffic than neighborhood level corridors. This has important implications for the nighttime economy in Phialdelphia as we know that the corridor types that tend to generate more traffic also see a larger share of this traffic during the day time hours. This suggests that businesses catering to a nighttime crowd are pulling from a smaller subset of the traffic that these larger corridors are seeing.
```{r flows data wrangling, echo=FALSE}
flows <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>% #filter for business types
  st_join(phl_corridors) %>% #join destinations to phl corridors (apply corridor destination to each trip)
  st_as_sf() %>%
  st_drop_geometry() %>% 
  select(safegraph_place_id, 
         date_range_start,
         top_category,
         poi_cbg,
         visitor_home_cbgs,
         NAME.y) %>% #select columns
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\[|\\]")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\{|\\}")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = '\\"|\\"')) %>%
  mutate(visitor_home_cbgs = str_split(visitor_home_cbgs, pattern = ",")) %>%
  unnest(visitor_home_cbgs) %>% #unnest visitor cbg column
  separate(.,
           visitor_home_cbgs,
           c("visitor_cbg", "count"),
           sep = ":") %>% #separate count column from visitor cbg
  mutate(count = as.numeric(count),
         visitor_cbg = as.numeric(visitor_cbg)) %>%
  dplyr::rename(., corridor_dest = NAME.y) %>%
  drop_na(corridor_dest) #Remove trips with destinations outside of corridors

#prepare PHL boundary file to coordinates for plotting
phl_boundary_unproj <-
  phl_boundary_unproj %>%
  st_coordinates() # split out coordinates

phl_boundary_unproj <-
  as.data.frame(phl_boundary_unproj) # save as dataframe

#----MAP V1: NEIGHBORHOOD CENTROID TO CORRIDOR CENTROIDS
#Generate CBG centroid
phl_cbg_cent <- 
  phl_cbg_unproj %>% 
  select(GEOID10, geometry) %>% 
  st_centroid()

#Generate neighborhood centroids
phl_nhood_cent <- 
  phl_nhoods_unproj %>% 
  select(name) %>%
  st_centroid()

#Generate corridor centroid
phl_corr_cent <- 
  phl_corridors_unproj %>% 
  select(NAME, geometry) %>% 
  st_centroid()

#Join CBG centroid to neighborhood shapefile
phl_cbg_nhood <- 
  st_join(phl_nhoods_unproj, phl_cbg_cent, join = st_intersects) %>%
  select(GEOID10, name) %>%
  st_centroid()

flows_nhood <- flows %>%
  left_join(phl_cbg_nhood, by=c("visitor_cbg"="GEOID10")) %>% #join visitor CBGs to nhoods
  dplyr::rename(., nhood_origin = name) %>% #cleanup columns for clarity
  drop_na(nhood_origin) %>% #dropping trips outside of Philadelphia
  st_as_sf() %>%
  st_drop_geometry() %>% 
  group_by(nhood_origin, top_category, corridor_dest) %>% #grouping trip counts by origin neighborhood
  summarize(count = sum(count)) %>%
  left_join(phl_nhood_cent, by=c("nhood_origin"="name")) %>% #join origin nhood to nhood centroid
  left_join(., phl_corr_cent, by=c("corridor_dest"="NAME")) %>% #join destination corridor to corr centroid
  dplyr::rename(., origin.geom = geometry.x,
                        dest.geom = geometry.y) #clean-up columns for clarity

#Convert from tibble to data frame for next step
flows_nhood <- as.data.frame(flows_nhood) 

#split point data into lat and long columns
flows_nhood <- flows_nhood %>% 
  mutate(lat.origin = unlist(map(flows_nhood$origin.geom,1)),
         long.origin = unlist(map(flows_nhood$origin.geom,2)),
         lat.dest = unlist(map(flows_nhood$dest.geom,1)),
         long.dest = unlist(map(flows_nhood$dest.geom,2)),
         id = as.character(c(1:nrow(.))))

#Maps - straight line segment example
flows_nhood %>% 
  filter(corridor_dest == "South Street/16th-21st" | #Neighborhood Subcenter
           corridor_dest == "Fairmount/19th-25th" | #Neighborhood Center
           corridor_dest == "Central Waterfront/Washington" | #Community Center
           corridor_dest == "Market West" | #Regional Center
           corridor_dest == "Market East" | #Superregional Center
           corridor_dest == "Old City") %>% #Specialty Center
  ggplot() + 
  geom_polygon(data = phl_boundary_unproj, aes(x=X, y=Y), fill = "grey40") + 
  geom_segment(aes(x = lat.origin, y = long.origin, xend = lat.dest, yend = long.dest,  
                   color=log(count)),
               # arrow = arrow(length = unit(0.01, "cm")), 
               size = .5,
               lineend = "round") +
  # scale_colour_distiller(palette="Reds", name="Count", guide = "colorbar", direction = 1) +
  scale_color_viridis_c() +
  coord_equal() +
  mapTheme() + 
  facet_wrap(~corridor_dest, ncol = 3) +
  labs(title = "Trips")
```

## 3.5 Other Exploratory Analysis with SafeGraph Data

The SafeGraph dataset is incredibly rich and there are many more fascinating variables to investigate. The following section shows a selection of other discrete analyses that we conducted on the SafeGraph dataset that had interesting implications for use case.

### Distance from Home

Figures X.X and X.X below visualize SafeGraph "distance_from_home" variable, which takes the average distance travelled from a visitor's home to the point of interest along the corridor. For Figure X.X, we have aggregated this variable by corridor to show that on average, visitors travel farther to Center Center and corridors close to the city's border. Smaller corridors throughout the city draw more local visitors that travel shorter distances. One possible explanation for this pattern could be the presence of job hubs. With jobs concentrated in Center City and a handful of other centers, such as the airport in Southwest Philadelphia and the Navy Yard in South Phialdelphia, this could indicate that the people are willing to travel relatively long distances to these corridors. Another possible explanation for this pattern could be the connectivity of these corridors. The commercial corridors in Center City are well-served by public transit and the corridors located close to the city's border, particularly around South Philly are well connected to the interstate network, facilitating car travel to these destinations. Finally, tourism could play a role in the aggreggated distance from home variable. Most of the city's tourist-friendly attractions are located in the city core, so visitors from outside of Philadelphia could be skewing this variable higher.
```{r echo=FALSE}
dat3 %>%
  drop_na(NAME.y) %>%
  group_by(NAME.y) %>%
  summarize(distance_from_home = mean(distance_from_home, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  rename("NAME" = "NAME.y") %>%
  left_join(., phl_corridors) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(aes(fill = q5(distance_from_home)), color = "transparent") +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Distance from Home (Quintile)") +
  labs(title = "Distance from Home (Quintile)",
       subtitle = "Figure X.X") +
  mapTheme() +
  theme(legend.position = "bottom")
```

Looking at the same variable across the corridor tyeps, we see that the Regional, Superregional, and Specialty Centers have a substantially higher average distance travelled corridor at 6.4, 14.8 and 9.7 miles respectively. Neighborhood Subcenters have the smallest distance from home value, suggesting that, on average, this corridor type appeals to a more local crowd.
```{r echo=FALSE}
#Barplots
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(corr_type) %>%
  summarise(Avg_Distance_mi = mean(distance_from_home, na.rm = TRUE)*0.000621371) %>%
  ggplot(aes(y=Avg_Distance_mi, 
             x=factor(corr_type, levels=c("Neighborhood Subcenter",
                                          "Neighborhood Center",
                                          "Community Center",
                                          "Regional Center",
                                          "Superregional Center",
                                          "Specialty Center")))) + 
  geom_bar(stat="identity") +
  labs(title = "Distance from Home (miles)",
       subtitle = "Figure X.X") +
  # facet_wrap(~corr_type) +
  guides(fill=guide_legend(title=NULL)) +
  theme(axis.title.x = element_blank()) +
  geom_text(aes(label=round(Avg_Distance_mi, digits = 1)), vjust=1.6, color="white", size=3.5)+
  plotTheme() 
```

### Median Dwell Time

Another variable unique to the SafeGraph dataset is the median_dwell variable which aggregates the median amount of time spent by all visitors at a given point of interest. While we do not see as clear of a spatial pattern in the map as we did with the above distance_from_home variable, the bar plot in Figure X.X below indicates that Neighborhood Subcenters have the highest median dwell time at over 45 minutes, while Community Centers have the lowest. As Community Centers tend to be auto-oriented and suburban style commercial centers, these corridors may be optimized for convenience and, therefore, encourage visitors to spend less time.

Applying this finding to the nighttime economy, establishments that are integral to the nighttime economy tend to benefit when visitors spend a longer time at the establishment. For example, at bars and restaurants, the longer a patron spends at the establishment, the more likely they are to purchase additional items, translating to increased business revenue. This could have implications for 

This could suggest that businesses located in Community Centers are less likely to cater to those seeking out arts, entertainment and culture. It could also mean that something about the environment in Community Centers encourages people to spend less time at individual business.
```{r echo=FALSE}
#Fix axes!
dat3 %>%  
  drop_na(NAME.y, corr_type) %>%
  group_by(NAME.y) %>%
  summarize(median_dwell = median(median_dwell, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  rename("NAME" = "NAME.y") %>%
  left_join(., phl_corridors) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey60", color = "transparent") +
  geom_sf(aes(fill = q5(median_dwell)), color = "transparent") +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Median Dwell \n(Quintile)") +
  labs(title = "Median Dwell (Quintile)",
       subtitle = "Figure X.X") +
  mapTheme()

#Barplots
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(corr_type) %>%
  summarise(Dwell = median(median_dwell, na.rm = TRUE)) %>%
  ggplot(aes(y=Dwell, 
             x=factor(corr_type, levels=c("Neighborhood Subcenter",
                                          "Neighborhood Center",
                                          "Community Center",
                                          "Regional Center",
                                          "Superregional Center",
                                          "Specialty Center")))) + 
  geom_bar(stat="identity") +
  scale_fill_viridis_d() +
  labs(title = "Median Dwell by Establishment and Corridor Type (Minutes)",
       subtitle = "Figure X.X") +
  geom_text(aes(label=round(Dwell, digits = 1)), vjust=1.6, color="white", size=3.5)+
  guides(fill=guide_legend(title=NULL)) +
  plotTheme()
```

## 3.6 Concluding Thoughts from Exploratory Data Analysis

The SafeGraph dataset is incredibly rich and the above analysis merely demonstrates a small sample of the possibilities of this data. By combining the SafeGraph dataset with Philadelphia's local commercial corridors, we were able to see unique patterns that further distinguish the corridor types as well as provide important insights into the behavior of people participating in the nighttime economy. 

# 4 Predictive Model

Informed by the above exploratory analysis, the following section discusses how we developed a predictive model by explaining the features that we ultimately chose for the model, the modelling approach, and an evaluation of our error terms.

## 4.1 Feature Summary

Our model predicts the number of trips between the hours of 7PM and 12AM to Philadelphia commercial corridors. After and extensive and iterative process of data wrangling, we ended up with three main categories of variables.

* *SafeGraph Features*: These features are entirely sourced from the SafeGraph dataset. They help describe the denity of certain business types along a certain corridor, a measure of retail mix, the distance home and dwell time (explore further in the above Section 3), and how late businesses are open.

* *Built environment Features*: These features are sourced from local datasets maintained on Open Data Philly and describe the built environment of the corridor. They include information on distance to transit, parks, and average building size.

* *Demographic Features*: These features are sourced from U.S. Census data and describe socio-economic characteristics of a corridor.

```{r loading in prediction data, message=FALSE, warning=FALSE, include=FALSE}
#SafeGraph Features
# bar.sf <- dat2 %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf(coords = "geometry", crs = 4326, agr = "constant")
# 
# restaurant.sf <- dat2 %>%
#   filter(top_category == "Restaurants and Other Eating Places") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()
# 
# arts.sf <- dat2 %>%
#   filter(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
#            top_category == "Performing Arts Companies") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()
# 
# # college.sf <- dat2 %>%
# #   filter(top_category == "Colleges, Universities, and Professional Schools") %>%
# #   dplyr::select(location_name) %>%
# #   st_as_sf()
# 
# sports.sf <- dat2 %>%
#   filter(top_category == "Spectator Sports") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

# casinos.sf <- dat2 %>%
#   filter(sub_category == "Casino Hotels") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

# hotels.sf <- dat2 %>%
#   filter(sub_category == "Hotels (except Casino Hotels) and Motels") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

# parking.sf <- dat2 %>%
#   filter(sub_category == "Parking Lots and Garages") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

#Philadelphia Features
phl_corridors_pred <- phl_corridors %>%
  st_as_sf() %>%
  dplyr::select(4:5,18, 'corr_type') %>%
  rename(., corridor = NAME,
         district = P_DIST,
         vacancy_rate = VAC_RATE) %>%
  mutate(vacancy_rate = str_remove_all(vacancy_rate, pattern = "%"),
         vacancy_rate = str_remove_all(vacancy_rate, pattern = "\r\n"),
         vacancy_rate = as.numeric(vacancy_rate),
         corr_area_sqft = as.numeric(st_area(phl_corridors)),
         corr_area_sqmi = as.numeric(st_area(phl_corridors)*0.000000035870))

phl_corridors_pred$vacancy_rate <- phl_corridors_pred$vacancy_rate %>% replace_na(0)

# phl_dist <-
#   st_read("http://data.phl.opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson",
#           quiet = TRUE) %>%
#   st_transform('ESRI:102728')

# phl_nhoods <- 
#   st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", quiet = TRUE) %>%
#   st_transform('ESRI:102728') %>%
#   dplyr::select(mapname) %>%
#   dplyr::rename(., neighborhood = mapname)

# CenterCity.sf <- phl_dist %>% 
#   dplyr::select(DIST_NAME) %>%
#   filter(DIST_NAME == "Central") %>%
#   st_centroid()

# CityHall.sf <- 
#   dat3 %>% 
#   dplyr::select(location_name, date_range_start, top_category) %>%
#   filter(location_name == "City Hall", date_range_start == "2018-01-01T05:00:00Z")

# Temple.sf <- 
#   dat3 %>% 
#   dplyr::select(location_name, date_range_start, top_category) %>%
#   filter(location_name == "Temple University", 
#          top_category == "Colleges, Universities, and Professional Schools",
#          date_range_start == "2018-01-01T05:00:00Z")

UPenn.sf <- 
  dat3 %>% 
  dplyr::select(location_name, date_range_start, top_category) %>%
  filter(location_name == "Univ of Penn",
         top_category == "Colleges, Universities, and Professional Schools",
         date_range_start == "2018-01-01T05:00:00Z")

septaStops <- 
  rbind(
    st_read("https://opendata.arcgis.com/datasets/8c6e2575c8ad46eb887e6bb35825e1a6_0.geojson", quiet = TRUE) %>% 
      dplyr::mutate(Line = "El") %>% 
      st_transform('ESRI:102728') %>%
      dplyr::select(Station, Line),
    st_read("https://opendata.arcgis.com/datasets/2e9037fd5bef406488ffe5bb67d21312_0.geojson", quiet = TRUE) %>%
      dplyr::mutate(Line ="Broad_St") %>%
      st_transform('ESRI:102728') %>%
      dplyr::select(Station, Line)) 

parks <-
  st_read("https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson", 
          quiet = TRUE) %>%
  st_transform('ESRI:102728') %>%
  dplyr::select(PUBLIC_NAME)

phl_building_footprints <-
  st_read("https://opendata.arcgis.com/datasets/ab9e89e1273f445bb265846c90b38a96_0.geojson", 
          quiet = TRUE) %>%
  dplyr::select(ADDRESS) %>%
  st_transform('ESRI:102728')

phl_building_footprints <- phl_building_footprints %>%
  dplyr::mutate(bld_area_sqft = as.numeric(st_area(phl_building_footprints)),
         bld_area_sqmi = as.numeric(st_area(phl_building_footprints)*0.000000035870))

# phl_busstop <-
#   st_read("https://opendata.arcgis.com/datasets/e09e9f98bdf04eada214d2217f3adbf1_0.geojson") %>%
#   st_transform('ESRI:102728') %>%
#   .[phl_boundary,] %>%
#   filter(Mode == "Bus")

phl_trolley <-
  st_read("https://opendata.arcgis.com/datasets/e09e9f98bdf04eada214d2217f3adbf1_0.geojson") %>%
  st_transform('ESRI:102728') %>%
  .[phl_boundary,] %>%
  filter(Mode == "Trolley")

#Demographic data
phl_blockgroups <- 
  get_acs(geography = "block group", 
          variables = c("B01003_001E", 
                        "B02001_002E", 
                        "B01002_001E",
                        "B19013_001E", 
                        "B25064_001E"
                        # "B03002_012E",
                        # "B02001_003E"
                        ),
          year=2018, 
          state=42, 
          county=101, 
          geometry=T, 
          output = "wide") %>%
  st_transform('ESRI:102728')%>%
  dplyr::rename(TotalPop = B01003_001E,
                White = B02001_002E,
                MedAge = B01002_001E,
                MedHHInc = B19013_001E,
                MedRent = B25064_001E,
                # Hisp = B03002_012E,
                # Black = 	B02001_003E,
                GEOID10 = GEOID) %>%
  dplyr::select(-ends_with("M")) %>%
  dplyr::mutate(pctWhite = ((White / TotalPop)*100),
                # pctBlack = ((Black / TotalPop)*100),
                # pctHisp = ((Hisp / TotalPop)*100),
                tract_area_mi = as.numeric(st_area(geometry)*0.000000035870),
                popdens_mi = TotalPop / tract_area_mi
         ) %>%
  st_as_sf()

st_c <- st_coordinates

dat_pred_temp <- 
  dat2 %>% 
  left_join(dat_1_6, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_7_12, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_13_18, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_19_0, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_workday, by = c('safegraph_place_id', 'date_range_start')) %>%
  st_join(phl_blockgroups) %>%
  st_join(phl_nhoods) %>%
  st_join(phl_corridors_pred) %>%
  st_join(., phl_building_footprints) %>%
  drop_na(corridor)

#Engineer variables at the destination level.
dat_pred <-
  dat_pred_temp %>%
  dplyr::mutate(total = 1,
         bars = ifelse(top_category == 'Drinking Places (Alcoholic Beverages)', 1, 0),
         restaurant = ifelse(top_category == 'Restaurants and Other Eating Places', 1, 0),
         arts = ifelse(top_category == 'Promoters of Performing Arts, Sports, and Similar Events' |
                         top_category == 'Performing Arts Companies', 1, 0),
         grocery = ifelse(top_category == 'Grocery Stores', 1, 0),
         # childcare = ifelse(top_category == "Child Day Care Services", 1, 0),
         # gas = ifelse(top_category == "Gasoline Stations", 1, 0),
         # religious = ifelse(top_category == "Religious Organization", 1, 0),
         # personal = ifelse(top_category == "Personal Care Services", 1, 0),
         # liquor = ifelse(top_category == "Beer, Wine, and Liquor Stores", 1, 0),
         # amusement = ifelse(top_category == 'Other Amusement and Recreation Industries', 1, 0),
         # college = ifelse(top_category == 'Colleges, Universities, and Professional Schools', 1, 0),
         sports = ifelse(top_category == 'Spectator Sports', 1, 0),
         # museum = ifelse(top_category == 'Museums, Historical Sites, and Similar Institutions', 1, 0),
         # hotels = ifelse(top_category == 'Traveler Accommodation', 1, 0),
         transit_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(septaStops)), 2),
         # bars_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(bar.sf)), 4),
         # rest_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(restaurant.sf)), 4),
         # arts_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(arts.sf)), 4),
         # college_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(college.sf)), 1),
         # sports_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(sports.sf)), 1),
         # hotels_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(hotels.sf)), 4),
         # casinos_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(casinos.sf)), 1),
         parks_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(parks)), 4),
         # parking_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(parking.sf)), 1),
         # busstop_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(phl_busstop)), 4),
         trolley_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(phl_trolley)), 4),
         late_night = if_else(grepl("Late Night", dat_pred_temp$category_tags), 1, 0),
         # bar_pub = if_else(grepl("Bar or Pub", dat_pred_temp$category_tags), 1, 0),
         # drinks = if_else(grepl("Drinks", dat_pred_temp$category_tags), 1, 0),
         # cocktail = if_else(grepl("Cocktail Lounge", dat_pred_temp$category_tags), 1, 0),
         # SocHill = if_else(neighborhood == "Society Hill", 1, 0),
         # UCity = if_else(neighborhood == "University City", 1, 0),
         # NavyYard = if_else(neighborhood == "Navy Yard", 1, 0),
         # PM_Workday = Hrs19_0 / Hrs_workday,
         # AM_PM = (Hrs1_6 + Hrs7_12) / (Hrs13_18+Hrs19_0),
         # restaurant_sqft = ifelse(top_category == "Restaurants and Other Eating Places", bld_area_sqft, 0),
         # bars_sqft = ifelse(top_category == "Drinking Places (Alcoholic Beverages)", bld_area_sqft, 0),
         closing_time = ifelse(str_detect(open_hours, paste(c("20:00", "21:00", "22:00", "23:00", "0:00", "1:00", "2:00", "3:00"), collapse = "|")), "OPEN LATE", "NOT OPEN LATE"),
         closing_time = ifelse(is.na(closing_time) == TRUE, "NO DATA", closing_time),
         open_late = ifelse(closing_time == "OPEN LATE", 1, 0)
	)

# dat_pred$CenterCity <- as.numeric(st_distance(dat_pred, CenterCity.sf))
# dat_pred$CityHall <- as.numeric(st_distance(dat_pred, CityHall.sf))
# dat_pred$Temple <- as.numeric(st_distance(dat_pred, Temple.sf))
dat_pred$UPenn <- as.numeric(st_distance(dat_pred, UPenn.sf))

#Aggregating up to the corridor level
dat_pred_agg <- 
  dat_pred %>%
  group_by(corridor, date_range_start, corr_type) %>%
  summarize(Night_visits = sum(Hrs19_0),
            Workday_visits = sum(Hrs_workday),
            phl_area_sqmi = mean(corr_area_sqmi, na.rm = TRUE),
            Night_visits_sqmi = (Night_visits + 1) / phl_area_sqmi,
            Night_visits_sqmi_log = log(Night_visits_sqmi),
            Workday_visits_sqmi = (Workday_visits +1) / phl_area_sqmi,
            Workday_visits_sqmi_log = log(Workday_visits_sqmi),
            total = sum(total),
            phl_building_size = mean(bld_area_sqft +1, na.rm = TRUE),
            phl_building_size_log = log(phl_building_size),
            # phl_building_size_med = median(bld_area_sqft, na.rm = TRUE),
            # phl_CenterCity = mean(CenterCity),
            # phl_CityHall = mean(CityHall),
            # phl_CityHall_log = log(phl_CityHall),
            # phl_Temple = mean(Temple),
            phl_UPenn = mean(UPenn),
            # phl_vacrate = mean(vacancy_rate + 1),
            # phl_vacrate_log = log(phl_vacrate),
            # phl_rest_sqft = mean(restaurant_sqft +1,na.rm = T),
            # phl_rest_sqft_log = log(phl_rest_sqft),
            # phl_bar_sqft = mean(bars_sqft +1, na.rm = T),
            # phl_bar_sqft_log = log(phl_bar_sqft),
            # sg_visitors = sum(raw_visitor_counts),
            # sg_visits = sum(raw_visit_counts),
            sg_dwell = mean(median_dwell, na.rm = TRUE),
            sg_distance_home = mean(distance_from_home, na.rm = TRUE),
            # sg_workday = mean(PM_Workday, na.rm = TRUE),
            # sg_AM_PM = mean(AM_PM, na.rm = TRUE),
            sg_distance_home_log = log(sg_distance_home),
            count_bars_a = (sum(bars, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_rest_a = (sum(restaurant, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_arts_a = (sum(arts, na.rm = TRUE) +1)/phl_area_sqmi,
            # count_jrcol_a = sum(jrcol, na.rm = TRUE)/phl_area_sqmi,
            # count_college_a = (sum(college, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_sports_a = (sum(sports, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_museums_a = (sum(museum, na.rm = TRUE)  + 1)/phl_area_sqmi,
            # count_amuse_a = (sum(amusement, na.rm = TRUE)  + 1)/phl_area_sqmi,
            # count_hotels_a = (sum(hotels, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_grocery_a = (sum(grocery, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_childcare_a = (sum(childcare, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_gas_a = (sum(gas, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_religious_a = (sum(religious, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_personal_a = (sum(personal, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_retailmix_top = n_distinct(top_category),
            count_retailmix_sub = n_distinct(sub_category),
            count_late_tag = (sum(late_night, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_barpub_tag = (sum(bar_pub, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_drinks_tag = (sum(drinks, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_cocktail_tag = (sum(cocktail, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_openlate = (sum(open_late, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_bars_a_log = log(count_bars_a),
            count_rest_a_log = log(count_rest_a),
            count_arts_a_log = log(count_arts_a),
            count_grocery_a_log = log(count_grocery_a),
            # count_religious_a_log = log(count_religious_a),
            # count_childcare_a_log = log(count_childcare_a),
            # log_jrcol_a = log(sum(jrcol, na.rm = TRUE)/phl_area_sqmi),
            # log_college_a = log(sum(college, na.rm = TRUE)/phl_area_sqmi),
            # log_sports_a = log(sum(sports, na.rm = TRUE)/phl_area_sqmi),
            # log_museums_a = log(sum(museum, na.rm = TRUE)/phl_area_sqmi),
            # count_amuse_a_log = log(count_amuse_a),
            # count_barpub_log = log(count_barpub_tag),
            count_late_log = log(count_late_tag),
            count_retailmix_top_log = log(count_retailmix_top),
            count_retailmix_sub_log = log(count_retailmix_sub),
            count_openlate_log = log(count_openlate),
            nn_transit = mean(transit_nn),
            nn_parks = mean(parks_nn),
            # nn_parking = mean(parking_nn),
            # nn_busstop = mean(busstop_nn),
            nn_trolley = mean(trolley_nn),
            # nn_bars = mean(bars_nn),
            # nn_rest = mean(rest_nn),
            # nn_arts = mean(arts_nn),
            # nn_college = mean(college_nn),
            # nn_sports = mean(sports_nn),
            # nn_casinos = mean(casinos_nn),
            # nn_hotels = mean(hotels_nn),
            nn_parks_log = log(nn_parks),
            nn_transit_log = log(nn_transit),
            # nn_parking_log = log(nn_parking),
            # nn_busstop_log = log(nn_busstop),
            nn_trolley_log = log(nn_trolley),
            demo_popdens = mean(popdens_mi),
            demo_popdens_log = log(demo_popdens),
            demo_pctWhite = weighted.mean(pctWhite, Hrs19_0, na.rm = TRUE),
            # demo_pctBlack = weighted.mean(pctBlack, Hrs19_0, na.rm = TRUE),
            # demo_pctHisp = weighted.mean(pctHisp, Hrs19_0, na.rm = TRUE),
            # demo_pctHisp_log = log(demo_pctHisp + 1),
            demo_medAge = weighted.mean(MedAge, Hrs19_0, na.rm = TRUE),
            demo_MHI = weighted.mean(MedHHInc, Hrs19_0, na.rm = TRUE),
            demo_medrent = weighted.mean(MedRent, Hrs19_0, na.rm = TRUE)) %>% 
  # mutate_if(is.numeric, list(~na_if(., Inf))) %>%
  st_drop_geometry() %>%
  left_join(phl_corridors_pred %>% dplyr::select(corridor)) %>%
  drop_na(corridor, demo_MHI, demo_medrent) %>% #Some of the census variables aren't reporting for our block groups
  st_as_sf() %>%
  ungroup() %>%
  na.omit(st_distance_home)
```

The below is a final list of variables as well as a brief description of each.
```{r echo=FALSE}
reg.vars <- c('Night_visits_sqmi_log',
              'phl_building_size_log',
              'phl_UPenn',
              'sg_distance_home_log',
              'sg_dwell',
              'count_bars_a_log',
              'count_rest_a_log',
              'count_arts_a_log',
              'count_grocery_a_log',
              'count_sports_a',
              'count_retailmix_top',
              'count_retailmix_sub_log',
              'count_openlate_log',
              'nn_transit_log',
              'nn_parks_log',
              'nn_trolley',
              'count_late_tag',
              'corr_type',
              'count_late_log',
              'demo_pctWhite',
              'demo_medAge',
              'demo_popdens',
              'demo_medrent',
              'demo_MHI')

reg.vars
```

In Figure X.X below, we see a corrplot display of the final features chosen for the model. There is some collinearity among the variables that describe the density of business types. While this is not ideal for modelling, including these variables were necessary for the ultimate application of this model as a tool to predict nighttime traffic based on different retail mix scenarios. In order to adjust the retail mix for certain nighttime estabishments (bars, restaurants, and arts venues) a variable representing each of these factors needed to be present in the final model. Other variables, though they may have exhibited some degree of collinearity are present in the model because they were ultimately statistically significant.
```{r echo=FALSE}
numericVars <- dat_pred_agg %>% select(reg.vars) %>% st_drop_geometry() %>% select_if(., is.numeric)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = palette3,
  type="full",
  insig = "blank") +  
  plotTheme()+
  labs(title = "Correlation across numeric variables",
       subtitle = "Figure X.X") 
```

## 4.2 Model Building

We developed two primary models: an OLS linear regression and random forest regression. Both models were used to predict the logged nighttime visits per square mile. We made this prediction for each corridor and each month of 2018. We chose to use to use the log of night visits to address the skewed data and generate a more normalized dataset for the model to predict on.

For both models, we split our data into a training and test sets (60% and 40%, respectively) and evaluated the Mean Absolute Error (MAE) and Mean Average Percent Error (MAPE).

### OLS Model

We first developed and evaluated a linear model using our selected features. The results of the regression summary are shown in the table below. We can see that with the exception of the bars and arts variables (which are included for the scenario purposes) and a few of the corridor types, the individual features are quite significant predictors overall. We also see that the R-Squared value is relatively low at about .5.

```{r model building, echo=FALSE}
#Setting up test and training datasets
set.seed(414)
inTrain <- createDataPartition(y=dat_pred_agg$Night_visits_sqmi_log, p = .60, list = FALSE)

phl.training <- dat_pred_agg[inTrain,]
phl.test <- dat_pred_agg[-inTrain,]

#Multivariate Linear regression
reg1 <- 
  lm(Night_visits_sqmi_log ~ ., #change lm to ranger, predictions are a little different
     data = st_drop_geometry(phl.training) %>% 
       dplyr::select(reg.vars))
             
summary(reg1)
```

Figure X.X below compares the predictions and the actual values across the training and the test sets. While the predicted value (the green line) lines up fairly well with the actual value (orange line), the scatterplot indicates a fair amount of variance. Additionally, there are some intense outliers across both the training and the test set that the model is predicting quite poorly.
```{r pred actual scatterplot, out.width = "100%"}
reg1_predict <- exp(predict(reg1, newdata = phl.test))

rmse.train <- caret::MAE(exp(predict(reg1)), phl.training$Night_visits_sqmi)
rmse.test <- caret::MAE(reg1_predict, phl.test$Night_visits_sqmi)

preds.train <- data.frame(pred   = exp(predict(reg1)),
                          actual = phl.training$Night_visits_sqmi,
                          source = "training data")
preds.test  <- data.frame(pred   = reg1_predict,
                          actual = phl.test$Night_visits_sqmi,
                          source = "testing data")

preds <- rbind(preds.train, preds.test)

ggplot(preds, aes(x = pred, y = actual, color = source)) +
  geom_point() +
  geom_smooth(method = "lm", color = "green") +
  geom_abline(color = "orange") +
  theme_bw() +
  coord_equal() +
  facet_wrap(~source, ncol = 2) +
  labs(title = "Comparing predictions to actual values",
       x = "Predicted Value",
       y = "Actual Value",
       subtitle = "Figure X.X") +
  theme(
    legend.position = "none"
  )
```

We also ran a k-fold cross validation test to view the distribution of errors. The MAE for each fold are plotted in the below Figure X.X. 
```{r, out.width = "100%"}
#Figure out how to exponentiate this.

fitControl <- trainControl(method = "cv", 
                           number = 10,
                           savePredictions = TRUE)

# fitControl <- loo_cv(dat_pred_agg)

set.seed(414)
reg1.cv <- 
  train(Night_visits_sqmi_log ~ ., data = st_drop_geometry(dat_pred_agg) %>% 
          dplyr::select(reg.vars), 
        method = "lm", 
        trControl = fitControl, 
        na.action = na.pass)

reg1.cv.resample <- reg1.cv$resample

reg1.cv 
ErrorHist <- 
  ggplot(reg1.cv.resample, aes(x=MAE)) + 
  geom_histogram(color = "grey40", fill = "#27fdf5", bins = 50) + 
  labs(title="Linear Model: Histogram of Mean Absolute Error Across 100 Folds",
       subtitle = "Figure X.X") +
  plotTheme()

ErrorHist
```

Finally, we map the errors by commercial corridor in the following figures. The absolute errors indicate that our model is less accurate predicting nighttime traffic for larger, more heavily-trafficked corridors. The Percent Errors map on the right, actually tells a slightly different story with the highest quintile of percent error along the smaller corridors throughout the city. 
```{r, out.width = "100%"}
cv_preds <- reg1.cv$pred

map_preds <- dat_pred_agg %>% 
  rowid_to_column(var = "rowIndex") %>% 
  left_join(cv_preds, by = "rowIndex") %>%
  group_by(corridor, corr_type) %>%
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            pred = mean(pred)) %>% 
  dplyr::mutate(Visits.AbsError = abs(exp(pred) - Night_visits_sqmi),
         PercentError = (Visits.AbsError / Night_visits_sqmi)*100) 

#Quintile maps
ErrorPlot1 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds, aes(fill = q5(Visits.AbsError), color = q5(Visits.AbsError))) +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds,"Visits.AbsError"),
                      name="Quintile\nBreaks") +
  scale_color_manual(values = palette5,
                      labels=qBr(map_preds,"Visits.AbsError"),
                      name="Quintile\nBreaks") +
  labs(title="Absolute Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

ErrorPlot2 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds, aes(fill = q5(PercentError), color = q5(PercentError))) +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds, "PercentError"),
                      name="Quintile\nBreaks") +
  scale_color_manual(values = palette5,
                      labels=qBr(map_preds,"PercentError"),
                      name="Quintile\nBreaks") +
  labs(title="Percent Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

grid.arrange(ErrorPlot1, ErrorPlot2, ncol=2)
```

Finally the following tables summarize the error terms by corridor type. We acknowledge that the linear is most accurate at predicting traffic for the Neighborhood Center and the Community Centers with an average percent error of about 25%. The model is substantially worse at predicting traffic along Regional Centers and Superregional Centers, where the error terms indicate that the model's average error is about 50%. Not only is the linear model highly inaccurate, but it is not generalizable across corridors. 
```{r echo=FALSE}
#Comparing errors by corr type
map_preds_corr <- 
  map_preds %>%
  dplyr::mutate(MAE = round(abs(exp(pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(corr_type) %>% 
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>% 
  st_drop_geometry() %>%
  dplyr::select(corr_type, MAE, MAPE)

map_preds_corr[order(factor(map_preds_corr$corr_type, 
                            levels = c("Neighborhood Subcenter",
                                       "Neighborhood Center",
                                       "Community Center",
                                       "Regional Center",
                                       "Superregional Center",
                                       "Specialty Center"))),] %>%
  kable(caption = "Errors by Corridor Type") %>%
  kable_styling()
```

We also look at the errors for the linear model across months in the following table. The MAPE remains high across all months, but is particularly high during the winter months of January, February and December.
```{r echo=FALSE}
#Errors by date
dat_pred_agg %>% 
  rowid_to_column(var = "rowIndex") %>% 
  left_join(cv_preds, by = "rowIndex") %>%
  group_by(corridor, date_range_start) %>%
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            pred = mean(pred)) %>% 
  dplyr::mutate(Visits.AbsError = abs(exp(pred) - Night_visits_sqmi),
         PercentError = (Visits.AbsError / Night_visits_sqmi)*100) %>%
  dplyr::mutate(MAE = round(abs(exp(pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(date_range_start) %>% 
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>% 
  st_drop_geometry() %>%
  dplyr::select(date_range_start, MAE, MAPE) %>%
  dplyr:: mutate(date_range_start = as.date(date_range_start)) %>%
  kable(caption = "Errors by Corridor Type") %>%
  kable_styling()

```

### Random Forest Model

As discussed above, the linear model has a number of issues with accuracy and generalizability. In an effort to improve these metrics, we built a random forest model using the same features and dependent variable. In the below summary table, we see much improvement in the random forest model's OOB Error of about 20%, down from about 40% in the linear model. Additionally, the adjusted R-squared value has increased from .5 to .7. This indicates that the model's accuracy has improved.
```{r ranger}
set.seed(414)
inTrain <- createDataPartition(y=dat_pred_agg$Night_visits_sqmi_log, p = .60, list = FALSE)

phl.training.rf <- dat_pred_agg[inTrain,]
phl.test.rf <- dat_pred_agg[-inTrain,]

#Multivariate regression
rf1 <- 
  ranger(Night_visits_sqmi_log ~ ., #change lm to ranger, predictions are a little different
     data = st_drop_geometry(phl.training.rf) %>%
             dplyr::select(reg.vars),
     importance = "impurity")

rf1
```

Next we tune the model's hyperparameters to account for the variance across time. As we saw in the above table, there was extensive variation in the error terms across the monthly predictions of our data. Therefore, we decided to optimize for this metric. After testing different parameters using the tune_grid() function, the final parameters were selected based on the lowest Root Mean Square Error. This results of the grid search are shown in the below table
```{r}
set.seed(414)

phl.training.rf_fit <- dat_pred_agg[inTrain,]
phl.test.rf_fit <- dat_pred_agg[-inTrain,]

data_split <- initial_split(dat_pred_agg, strata = "Night_visits_sqmi_log", prop = 0.60)

model_rec <- recipe(Night_visits_sqmi_log ~ ., data = phl.training.rf %>% 
                      dplyr::select(reg.vars) %>% 
                      st_drop_geometry())

#Splitting by month
cv_splits_time <- group_vfold_cv(phl.training.rf%>%
                      dplyr::select(date_range_start, reg.vars) %>%
                      st_drop_geometry(),
                      strata = "Night_visits_sqmi_log",
                      group = "date_range_start")

rf_plan <- rand_forest() %>%
  set_args(mtry  = tune()) %>%
  set_args(min_n = tune()) %>%
  set_args(trees = 1000) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("regression")

#Setting parameters to try
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20), 
                       min_n = c(5, 10, 50))

rf_wf <-
  workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(rf_plan)

control <- control_resamples(save_pred = TRUE, verbose = TRUE)

#Test hyperparameters
rf_tuned_time <- rf_wf %>%
  tune::tune_grid(.,
                  resamples = cv_splits_time,
                  grid      = rf_grid,
                  control   = control,
                  metrics   = metric_set(rmse, rsq))

show_best(rf_tuned_time, metric = "rmse", n = 15) %>% kable() %>% kable_styling()
```

The below shows the tuned random forest model's updated specifications.
```{r}
rf_best_params_time  <- select_best(rf_tuned_time, metric = "rmse") 

rf_best_wf_time <- finalize_workflow(rf_wf, rf_best_params_time)

rf_val_fit_time <- rf_best_wf_time %>% 
  last_fit(split     = data_split,
           control   = control,
           metrics   = metric_set(mae, rsq))

rf_val_fit_time$.workflow 
```

### Feature Importance

The below Figure X.X is a bar plot showing the final random forest model's relative feature importance. The features ranked more highly were more important predictors for nighttime traffic along commercial corridors, while features ranked lower were less important predictors. A more extensive discussion of the feature importance of this model is included in below in Section 5.
```{r echo=FALSE}
rf_val_fit_time %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 23) +
  plotTheme() +
  labs(title = "Random Forest Model Feature Importance", 
         subtitle = "Figure X.X")
```

Using a similar workflow to evaluate the random forest model errors, the following graphic shows a scatter plot comparing the actual and predicted values between the training and test sets of data. There is less overlap between the green and orange lines than in the analogous plot for the linear model, which suggests that the model could be better calibrated to align the predicted and actual values. However, the distribution of the predictions, indicated by the more normalized clustering of the dots across both datasets, indicates that the random forest model is an improvement over the previous iteration. There are still outliers in both the testing and training datasets that indicate the model has trouble coping with particlarly high values. Again, further calibration and including additional features to account for these high counts would further improve the model's accuracy.
```{r echo=FALSE}
rf1_predict.train_fit <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(phl.training.rf_fit))
rf1_predict.train_fit <- exp(rf1_predict.train_fit %>% as.data.frame())

rf1_predict.test_fit <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(phl.test.rf_fit))
rf1_predict.test_fit <- exp(rf1_predict.test_fit %>% as.data.frame())  

rmse.train.rf_fit <- caret::MAE(rf1_predict.train_fit, phl.training.rf$Night_visits_sqmi)
rmse.test.rf_fit <- caret::MAE(rf1_predict.test_fit, phl.test.rf$Night_visits_sqmi)

preds.train.rf_fit <- data.frame(pred   = rf1_predict.train_fit,
                          actual = phl.training.rf$Night_visits_sqmi,
                          source = "training data")
preds.test.rf_fit <- data.frame(pred   = rf1_predict.test_fit,
                          actual = phl.test.rf$Night_visits_sqmi,
                          source = "testing data")

preds.rf_fit <- rbind(preds.train.rf_fit, preds.test.rf_fit)

ggplot(preds.rf_fit, aes(x = .pred, y = actual, color = source)) +
  geom_point() +
  geom_smooth(method = "lm", color = "green") +
  geom_abline(color = "orange") +
  theme_bw() +
  coord_equal() +
  facet_wrap(~source, ncol = 2) +
  labs(title = "Comparing predictions to actual values - Random Forest Model",
       x = "Predicted Value",
       y = "Actual Value",
       subtitle = "Figure X.X") +
  theme(
    legend.position = "none"
  )
```

Comparing the error terms of the test sets between the Linear Model and the tuned Random Forest Model, we see that the latter is substantially more accurate than the linear model with a mean absolute percent error down to 17% from 40%.
```{r echo=FALSE}
phl.test_table <-
  phl.test %>%
  st_drop_geometry() %>%
  mutate(Regression = "Linear Regression",
         Visits.Predict = exp(predict(reg1, phl.test)),
         Visits.Error = Visits.Predict - Night_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Night_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Night_visits_sqmi)) / Visits.Predict)

phl.test.rf_table <-
  phl.test.rf %>%
  st_drop_geometry() %>%
  mutate(Regression = "Random Forest Regression",
         Visits.Predict = as.numeric(unlist(rf1_predict.test_fit)),
         Visits.Error = Visits.Predict - Night_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Night_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Night_visits_sqmi)) / Visits.Predict)

rbind(phl.test.rf_table, phl.test_table) %>%
  group_by(Regression) %>%
  summarize(MAE = mean(Visits.AbsError, na.rm = TRUE),
            MAPE = mean(Visits.AbsError, na.rm = T) / mean(Night_visits_sqmi, na.rm = T)) %>% 
  kable(caption = "MAE and MAPE for Test Set Data") %>% kable_styling()
```

We also compare the two models's MAE with the below histogram across the 10 folds. We can see that the error terms cluster lower than the errors from the lienar model and are also more concentrated. This further demonstrates an imporvement over the linear model's generalizability. **CHECK CODE ON THIS ONE**
```{r echo=FALSE}
set.seed(414)
folds <- vfold_cv(dat_pred_agg, v = 10)
# folds2 <- vfold_cv(dat_pred_agg, v = 3159)

reg1.cv.rf <- 
  rf_best_wf_time %>% 
  fit_resamples(folds, metrics = metric_set(mae)) 

# reg1.cv.rf <- 
#   rf_best_wf_time %>% 
#   fit_resamples(folds2, metrics = metric_set(mae)) 

# get logged pred and actuals, exponentiate them bad boys and do ur metrics.

reg1.cv.rf.metrics <- collect_metrics(reg1.cv.rf, summarize = FALSE) 
# %>%
#   mutate(.estimate = exp(.estimate))

rbind(reg1.cv.resample %>% 
        mutate(Regression = "Linear Model") %>% 
        dplyr::select(MAE, Regression), 
      reg1.cv.rf.metrics %>% 
        mutate(Regression = "Random Forest Model") %>% 
        dplyr::select(.estimate, Regression) %>%
        dplyr::rename("MAE" = ".estimate")) %>%
  ggplot(aes(x=MAE)) + 
  geom_histogram(color = "grey40", fill = "#27fdf5", bins = 50) + 
  labs(title="Full Dataset: Histogram of Mean Absolute Error Across 10 Folds",
       subtitle = "Figure X.X") +
  facet_wrap(~Regression, ncol = 1) +
  scale_x_continuous(name = "Mean Absolute Error") +
  scale_y_continuous(name = "Count") +
  plotTheme()
```

### Leave One Group Out Cross Validation

Finally, the following code looks at generalizability across time and corridor type for the tuned random forest model. First we compare the model's errors across months. Similar to our analysis of the linear model, this model is far better at predicting during the spring and summer with MAPE's between 10% and 15%. This contrasts greatly to the predictions for the winter months, where the errors are as high as 50%. A continued discussion of why these errors deviate is included in the below Section 5.
```{r}
rf1_predict.full <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(dat_pred_agg))
# rf1_predict.full <- exp(rf1_predict.full %>% as.data.frame())

# cv_preds_rf <- rf_val_fit_time$.predictions %>% as.data.frame()

map_preds_rf <- dat_pred_agg %>% cbind(rf1_predict.full) #NOT SURE THIS IS RIGHT!
#Maybe do a left_join instead

#Comparing errors by time
map_preds_rf %>%
  dplyr::mutate(MAE = round(abs(exp(.pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(date_range_start) %>%
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>%
  st_drop_geometry() %>%
  dplyr::select(date_range_start, MAE, MAPE) %>%
  mutate(date_range_start = as.date(date_range_start)) %>%
  # mutate(date_range_start = str_remove_all(date_range_start, pattern = "T05:00:00Z"),
  #        date_range_start = str_remove_all(date_range_start, pattern = "T04:00:00Z")) %>%
  kable(caption = "Random Forest Model: Errors by Month") %>%
  kable_styling()
```

In addition to studying the random forest model's errors across time, the below table also looks at the errors across corridor type. Contrary to our evaluation of the linear model, where the model predicted nighttime traffic on smaller scale corridors best, the below table shows how our final random forest model predicts the Regional Centers best with a MAPE of a little over 15%. Additionally, the variation in MAPE across the corridor types is far diminished from those of the linear model.
```{r}
#Comparing errors by corr type
map_preds_corr_rf <-
  map_preds_rf %>%
  dplyr::mutate(MAE = round(abs(exp(.pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(corr_type) %>%
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>%
  st_drop_geometry() %>%
  dplyr::select(corr_type, MAE, MAPE)

map_preds_corr_rf[order(factor(map_preds_corr_rf$corr_type,
                            levels = c("Neighborhood Subcenter",
                                       "Neighborhood Center",
                                       "Community Center",
                                       "Regional Center",
                                       "Superregional Center",
                                       "Specialty Center"))),] %>%
  kable(caption = "Random Foreset Model: Errors by Corridor Type") %>%
  kable_styling()
```

### Mapping Errors

As a final evaluation of the random foresst model, we map the errors across Philadelphia commercial corridors in the below Figures X.X and X.X. The map on the left shows the highest quintile of aboslute error tends to occur in smaller corridors. There is a particular cluster in far West Philadelphia and the area north of Center City. When reviewing the Percent Error metric on the right, the best predictions are concentrated in Center City, likely because these corridors see more traffic overall.
```{r echo=FALSE}
map_preds_space <-
  map_preds_rf %>%
  dplyr::mutate(Visits.AbsError = round(abs(exp(.pred) - Night_visits_sqmi),2),
                PercentError = round((Visits.AbsError / Night_visits_sqmi)*100,2)) %>%
  group_by(corridor) %>%
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            Visits.AbsError = mean(Visits.AbsError),
            PercentError = mean(PercentError)) 

#Quintile maps
ErrorPlot1 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds_space, aes(fill = q5(Visits.AbsError), color = q5(Visits.AbsError))) +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds_space,"Visits.AbsError"),
                      name="Quintile\nBreaks") +
  scale_color_manual(values = palette5,
                      labels=qBr(map_preds_space,"Visits.AbsError"),
                      name="Quintile\nBreaks") +
  labs(title="Absolute Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

ErrorPlot2 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds_space, aes(fill = q5(PercentError), color = q5(PercentError))) +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds_space, "PercentError"),
                      name="Quintile\nBreaks") +
  scale_color_manual(values = palette5,
                      labels=qBr(map_preds_space,"PercentError"),
                      name="Quintile\nBreaks") +
  labs(title="Percent Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

grid.arrange(ErrorPlot1, ErrorPlot2, ncol=2)
```

## 4.3 Workday Model

Finally, we were curious to see if our model could predict traffic during other times of day. Using the same fetures, we ran an additional linear model and random forest model predicting *workday traffic* between the hours of 9AM and 6PM. While we were not concerned with evaluating the errors with the same rigor that we did above, we compared the MAE and MAPE to the other models we built. From this comparison we see that the workday model is far less accurate than both the nighttime models with a MAPE's as high as over 125%. 
```{r}
##Linear Workday Model
set.seed(414)
inTrain.day <- createDataPartition(y=dat_pred_agg$Workday_visits_sqmi_log, p = .60, list = FALSE)

#Split data
phl.training.day <- dat_pred_agg[inTrain.day,]
phl.test.day <- dat_pred_agg[-inTrain.day,]

#list of features in the model
reg.vars.day <- c('Workday_visits_sqmi_log',
                  'phl_building_size_log',
                  'phl_UPenn',
                  'sg_distance_home_log',
                  'sg_dwell',
                  'count_bars_a_log',
                  'count_rest_a_log',
                  'count_arts_a_log',
                  'count_grocery_a_log',
                  'count_sports_a',
                  'count_retailmix_top',
                  'count_retailmix_sub_log',
                  'count_openlate_log',
                  'nn_transit_log',
                  'nn_parks_log',
                  'nn_trolley',
                  'count_late_tag',
                  'corr_type',
                  'count_late_log',
                  'demo_pctWhite',
                  'demo_medAge',
                  'demo_popdens',
                  'demo_medrent',
                  'demo_MHI')

#Multivariate regression
reg1.day <- 
  lm(Workday_visits_sqmi_log ~ ., 
     data = st_drop_geometry(phl.training.day) %>% 
       select(reg.vars.day))

#Random Forest Workday model
set.seed(414)
phl.training.rf.day <- dat_pred_agg[inTrain,]
phl.test.rf.day <- dat_pred_agg[-inTrain,]

#RF regression
rf1.day <- 
  ranger(Workday_visits_sqmi_log ~ ., 
     data = st_drop_geometry(phl.training.rf.day) %>%
             select(reg.vars.day),
     importance = "impurity")

#Error table comparison
phl.test.day_table <-
  phl.test.day %>%
  st_drop_geometry() %>%
  mutate(Regression = "Workday Linear Regression",
         Visits.Predict = exp(predict(reg1.day, phl.test.day)),
         Visits.Error = Visits.Predict - Workday_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Workday_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Workday_visits_sqmi)) / Visits.Predict)

rf1_predict.test_day <- predict(rf1.day, data = st_drop_geometry(phl.test.rf.day))
rf1_predict.test_day <- exp(rf1_predict.test_day$predictions)

phl.test.rf.day_table <-
  phl.test.rf %>%
  st_drop_geometry() %>%
  mutate(Regression = "Workday Random Forest Regression",
         Visits.Predict = rf1_predict.test_day,
         Visits.Error = Visits.Predict - Workday_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Workday_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Workday_visits_sqmi)) / Visits.Predict)

rbind(phl.test.rf_table, phl.test_table, phl.test.day_table, phl.test.rf.day_table) %>%
  group_by(Regression) %>%
  summarize(MAE = mean(as.numeric(unlist(Visits.AbsError)), na.rm = TRUE),
            MAPE = MAE / mean(Night_visits_sqmi, na.rm = TRUE)) %>% 
  kable(caption = "MAE and MAPE for Test Set Data") %>% kable_styling()
```

This suggests that the factors determining workday traffic are distinct from the factors determining evening traffic. There does, however, seem to be some overlap in the significant features of the two models. The below summary table from the linear model shows that a number of variables are still statistically signficant, including the density of restaurants, retail mix, adn even if businesses are open late. Surprisingly, the distance to University of Pennsylvania, a signficant job hub witin Philadelphia, is not a signficant predictor. This is possibly due to the fact that the university is situated within a residential area in West Philadelphia. While the university itself may attract a fair amount of day time traffic, the surrounding areas might not. Other variables that are not similarly signficant between the nighttime and workday models include many of the demographic variables, such as percent white, median age, and population density.

```{r}
summary(reg1.day)
```

# 5. Findings & Discussion

While the model requires additional calibration, the model sheds light on research findings that have important implications for the governance of the nighttime economy in Philadelphia and perhaps in other cities as well. The following section discusses these findings in greater detail and hypothesizes on relevant policy implications.

## 5.1 Important Predictors of Nighttime Traffic

According to our final model, the following predictors were most important to estimating nightime traffic:

* Density of Restaurants
* Density of Businesses Open Late
* Average distance home
* Average dwell time
* Population density

The density of restaurants is a substantially more significant predictor of nighttime traffic along commercial corridors than other features. In terms of an economic development takeaway, this suggests that restaurants and food service are important generators of the nighttime economy and that creating and environment that is friendly to these types of establishments can lead to additional traffic along commercial corridors in Philadelphia. This finding is also signficant within the context of COVID-19, as we have seen that restaurant operations have been severely hampered during this difficult year. This suggests that prioritziing restaurants during this economic recovery stage could have a spillover effect into recovering other retail establishments in Philadelphia.

Perhaps unsurprisingly, the density of businesses open late is also an important predictor in the model. While this rather expected in predicting nighttime traffic, this has interesting policy implications in terms of licensing along commercial corridors. To encourage increased participation in the nighttime economy, this finding suggests that faciliating businesses staying open later can lead to increased traffic to commercial corridors. To help businesses bounce back from the pandemic, facilitating businesses staying open later may be another strategy to aid in the economic recovery effort after COVID-19. Certain businesses have time restrictions on the services they can provide late into the night, and easing these restrictions may be an effective way to generate economic activity in the nighttime sector. While negative externalities still need to be considered, this finding suggest that there are economic benefits to keeping businesses open late.

The distance from home and dwell time variables derived from the SafeGraph dataset were also strong predictors of nighttime traffic. This is notable as these are new variables that we have not had access to before the SafeGraph dataset and it appears that there are signficant relationships between these variables and mobility. Therefore, this highlights how this new dataset can be revolutionary in how we understand urban moblility patterns. Reviewing the coefficients of the linear model, we see that distance from home has a negative relationship with nighttime visits, suggesting that as nighttime visits go up, the distance home goes down. This suggests that people are more likely to travel shorter distances later in the evening. On the contrary, the linear model also indicates that the dwell time feature has a positive relationship with nighttime visits, meaning that as nighttime visits go up, people are likely to spend longer at a given establishment. These features provide an interesting insight into the behavior of visitors to establishments during nighttime hours. Visitors are willing to spend longer at an establishment, but are not likely to travel as far. In terms of a policy takeaway from this finding, local corridors close to residential areas of the neighborhood may be important sites to focus efforts to revive the nighttime economy. Additionally, visitors seem willing to spend longer at establishments during the evening hours, so helping restaurants and bars accommodate visitors comfortably (e.g. expanding seating and encouraging businesses to make nighttime destinations comforrtable) may be a viable strategy for increasing business revenue.

Possibly related to the distance home variable is the population density feature pulled from the U.S. Census. Per the above analysis, distance from home is negatively correlated with nighttime visits, suggesting that people tend to travel short distances during the evening hours. The importance of the population variable here also makes sense as area that census tracts with a higher density of residents means that more people are nearby in the evening hours to frequent local establishments. 

Finally, retail mix is another important predictor of nighttime trips, suggesting that the more retail diversity along a corridor, the more traffic it attracts during nighttime hours. This makes instutitive sense, as more retail options along a corridor allow it to cater to a wider group of people, but it also suggests that corridors that are successful generators of the nighttime economy may actually be most successful if the cater to daytime traffic as well and are able to host a mix of uses, not just those that we specifically associate with the nighttime economy. If nighttime establishments do best along places with a diverse mix of retail, some that we are assuming is not open late, this proposes interesting new planning challenges of how to allow corridors to feel both safe and active when some of the businesses have closed for the evening.

## 5.2 Less Important Predictors of Nighttime Traffic

Conversely, the features that were lesss important predictors have generated equally interesting findings and implications for economic development. We will primarily discuss the 3 features listed below and highlighted in the below Figure X.X.

* Corridor Type
* Bar Density
* Arts Density

Though certain corridor types were statistically signficant to our linear regression -- notably the Regional, Superregional, and Specialty Centers -- the variable overall was less important to our random forest model. There are a number of possibilities for why this is the case. For starters, though the corridor categories describe a specific type of retail environment, there may be extensive variation within each corridor typology. For example, there are over a hundred Neighborhood Subcenters across the entire city. The same is true for Neighborhood Centers. While the corridor typology might be useful for describing the other corridor types, of which the ultiamte count is much lower, this may simply be too broad a category to adequately describe these corridor types.

In particular, given our research on the nighttime economy, we were surprised to see that arts esstablishments and bars ranked particularly low in terms of feature importance. These two features were also not statistically signficant to the linear model, but we included in the model anyways for reasons related to the app described above. There are a number of reasons that could contribute to these feature's lack of importance in the model. For one, there seems to be some collinearity with some of the other variables descrbing the density of retail establishments (see Figure X.X above), meaning that they match the pattern of another feature and therefore do not contribute new information to the model. Another possibility for the lack of importance could be related to the hours that we are predicting. The model specifically looks at trips between the hours of 7PM and 12AM - it is possible that a nubmer of late night trips to bars and arts establishmetns are falling outside of this time window.

There may be an additional problem with prediciting traffic to arts venues, as the trips to these destinations are almost entirely reliant on programming (same with the density of sports venues which also ranks low in terms of importance). This abnormality is difficult to model and is likely one of the factors accounting for the feature's relatively weak performance. 

Though the features representing bars and arts venues were not important to our final model, this is not to say that these establishments are unimportant to the nightlife economy. From a quantitative perspective, we discuss in the above section that a diverse retail mix along a corridor is positively correlated with nightlife traffic and an important factor in predicting these patterns. Bars and arts venues undboutedly contribute to a commercial corridor's retail diversity and add to its vibrancy and mix of uses. Separately, though our project has modeled mobility as a proxy for economic importance, an establishments economic viability may not be the only rationale for supporting these business types along a corridor. Even if an arts venue does not attract regular traffic to a commercial corridor, this does not mean that we should not invest in the existence of these places. They enrich our lives and enhance the character along a corridor, and few would argue that this is not worthy of our support. This simply means that the arguments to support these places may not be exclusively economic one. Rather, it relies on the social and cultural benefits of these establishments.

## 5.3 Limited generalizabiliity 

Finally, the above analysis indicates that the model does not predict nighttime traffic with equivalent accuracy across time and and corridor type. Looking first at the generalizability across time, the model is best at predicting values during the spring and summer. In particular, the model's most accurate predictions occur durring March, May, June, and July where the MAPE is as low as 11%. In contrast, the predictions over the winter months is far less accurate, with the December prediction having a MAPE of over 100% and the January and February predictiosn having a MAPE of over 50%. These errors are likely due to far lower evening traffic counts during these months as shown in the below Figure X.X. It is possible that the discrepancy between evening traffic during these months is an error in the data, but it is also possible that it correlates with weather and hours of day light. As the winter months are darker and colder, people may be less likely to participate in the nighttiime economy activities during those months.

```{r}
dat3 %>% 
  group_by(date_range_start) %>%
  summarize(Evening_Hours = sum(Hrs7_12)) %>%
  mutate(date_range_start = as.character(as.date(date_range_start))) %>%
  st_drop_geometry() %>%
  ggplot(aes(x = date_range_start, y = Evening_Hours)) +
  geom_col() +
  plotTheme()

```

Another limitation in the data's generalizability is across corridor types. As discussed in the above section 4.2 on feature importance, the corridor types may be useful adminstrative tools for the City of Philadelphia, but they might not be descriptvie enough for modelling purposes, particularly for the smaller Neighborhood Subcenters and Centers that have the highest errors in our model. There may simply be too much variation within these administrative categories to guarantee accuracy

# 6. Conclusions & Opportunities for Continued Research

While this project has only scratched the surface of the SafeGraph data possibilities, we have generated a interesting set of findings about nighttime traffic to Philadelphia commercial corridors through our exploratory data analysis and model buidling process. These findings are particularly relevant to the city's economic development efforts recovering from the COVID-19 pandemic. 

This work has also contributed to an app that functions as a data dashboard to summarize socio-economic information about the many commercial corridors across Philadelphia and demonstrate where visitors travel from to visit corridors across the city. We hope this tool will be a valuable empirical device for corridor managers and eocnomic development officials across Philadelphia who have a vested interst in exploring the benefits of the nighttime economy at the corridor level. Separately, the app also puts our predictive model into use. Showcasing a selection of corridors across Philadlephia, our allows users to manipulate the retail mix of nightlife establishments along a given corridor and see the impact on nighttime traffic. 

There are many other iterations of the model that could enhance our understanding of the nighttime economy and improve the models accuracy. For one, we could further refine the hours when we are predicting trips. Instead of predicing between the hours of 7PM and 12PM, we could extend the boundaries of this variable to encompass hours into the early morning to get a more comprehensive view of traffic that occurs over the course of the entire night. The model could also incorporate multiple years of SafeGraph data to build a more robust picture of mobility along nightlife corridors. Finally, the model could be extended to other cities, which would expand the sample size, hopefully improving the model's accuracy and extending the findings to other cities that are interested in fostering their nighttime economy. 

# 7. Code Appendix

## Introduction

### Set-Up Packages
```{r eval=FALSE}
library(tidyverse)
library(tidycensus)
library(sf)
library(lubridate)
library(datetime)
library(viridis)
library(gridExtra)
library(kableExtra)
library(dplyr)
library(ggplot2)
library(gganimate)
library(FNN)
library(caret)
library(stargazer)
library(ranger)
library(tidymodels)

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}
q5 <- function(variable) {as.factor(ntile(variable, 5))}
palette3 <- viridis_pal()(3)
palette5 <- viridis_pal()(5)
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}
mapTheme_dark <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_rect(fill = "black"),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "black"),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}


plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    dplyr::summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}

setwd("~/GitHub/musa_practicum_nighttime")
```

### Load Data
```{r eval=FALSE}
dat <- read.csv("./data/moves_2018.csv") #2018 SafeGraph Patterns Data
data2020 <- read.csv("./data/moves_monthly2020.csv") # 2020 SafeGraph Patterns Data

phila <- st_read("./demo/phila.geojson", quiet = TRUE) # SafeGraph Places data

#Wrangle 2018 SafeGraph Patterns and Places data into one dataset
dat2 <- dat %>% 
  dplyr::select(safegraph_place_id, 
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                visits_by_day, 
                poi_cbg, 
                visitor_home_cbgs, 
                visitor_daytime_cbgs, 
                visitor_work_cbgs, 
                visitor_country_of_origin,
                distance_from_home, 
                median_dwell, 
                bucketed_dwell_times, 
                related_same_day_brand, 
                related_same_month_brand, 
                popularity_by_hour, 
                popularity_by_day, 
                device_type) %>%
  left_join(., phila, by = "safegraph_place_id") %>% 
  st_as_sf() %>%
  st_transform('ESRI:102728') #Project to Philly coordinates

#Load census block group shapefile (projected & unprojected)
phl_cbg <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10))%>%
  st_transform('ESRI:102728') 
phl_cbg_unproj <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10),
         Lat = as.numeric(INTPTLAT10),
         Lon = as.numeric(INTPTLON10))

#Load Philadelphia boundary shapefile (projected & unprojected)
phl_boundary <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728')

phl_boundary_unproj <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)

#Load commercial corridor shapefile (projected & unprojected)
phl_corridors <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728') %>%
  mutate(corr_type = ifelse(CORRIDOR_TYPE == 1, "Neighborhood Subcenter", 
                            ifelse(CORRIDOR_TYPE == 2, "Neighborhood Center", 
                                   ifelse(CORRIDOR_TYPE == 3, "Community Center", 
                                          ifelse(CORRIDOR_TYPE == 4, "Regional Center", 
                                                 ifelse(CORRIDOR_TYPE == 5, "Superregional Center", 
                                                        ifelse(CORRIDOR_TYPE == 6, "Specialty Center", "Other")))))))

phl_corridors_unproj <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)

#Load Neighborhood shapefile (projected & unprojected)
phl_nhoods <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE) %>%
  st_transform('ESRI:102728')
phl_nhoods_unproj <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE)

#Load Philadelphia zip code shapefile & project
phl_zip <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/b54ec5210cee41c3a884c9086f7af1be_0.geojson", quiet = TRUE) %>%
  st_transform('ESRI:102728') %>%
  mutate(CODE = as.numeric(CODE))
```

## Exploratory Data Analysis

### Count of Nightlife Establishments by Fishnet
```{r echo=FALSE}
#Generate fishnets
fishnet <- 
  st_make_grid(phl_boundary, cellsize = 1500, square = FALSE) %>%
  .[phl_boundary] %>% 
  st_sf() %>%
  mutate(uniqueID = rownames(.))

#Filter restaurants
restaurants <- dat2 %>%
  filter(top_category == "Restaurants and Other Eating Places")%>%
  mutate(Legend = "Restaurants")

#aggregate restaurant count by fishnet cell
restaurants_net <-
  dplyr::select(restaurants) %>% 
  mutate(countRestaurants = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRestaurants = replace_na(countRestaurants, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

#Bars
bars <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)") %>% 
  mutate(Legend = "Bars")

#aggregate bars by fishnet cell
bars_net <-
  dplyr::select(bars) %>% 
  mutate(countBars = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countBars = replace_na(countBars, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE)) %>%
  mutate(Legend = "Bars")

#Performing arts
performingarts <- dat2 %>%
  filter(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(Legend = "Performing Arts")

performingarts_net <-
  dplyr::select(performingarts) %>% 
  mutate(countPerformingarts = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countPerformingarts = replace_na(countPerformingarts, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

# Combining fishnets into a single dataframe
vars_net <- 
  rbind(restaurants, 
        bars, 
        performingarts) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  dplyr::summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(Legend,count, fill=0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup()

vars_net.long <- gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

#Plotting small multiple maps
for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange, c(mapList, 
                        ncol=3, top="Count of Nightlife Businesses per Fishnet", 
                        bottom = "Figure X.X"))
```

### COVID-19 Data Wrangling
```{r eval=FALSE}
# Modify 2018 data
dat_2018 <-
  dat %>%
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2018 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_2018 <- dat_2018 %>%
  dplyr::select(safegraph_place_id,
                location_name,
                date_range_start,
                date_range_end,
                raw_visit_counts,
                raw_visitor_counts,
                popularity_by_day,
                NightVisits2018) %>%
  rename(raw_visit_counts2018 = raw_visit_counts,
         raw_visitor_counts2018 = raw_visitor_counts,
         popularity_by_day2018 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7))

dat_2020 <-
  data2020 %>%
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2020 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_join <- dat_2020 %>%
  dplyr::select(safegraph_place_id,
                location_name,
                date_range_start,
                date_range_end,
                raw_visit_counts,
                raw_visitor_counts,
                popularity_by_day,
                NightVisits2020) %>%
  rename(raw_visit_counts2020 = raw_visit_counts,
         raw_visitor_counts2020 = raw_visitor_counts,
         popularity_by_day2020 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7)) %>%
  inner_join(., dat_2018, by = c("safegraph_place_id", "month", "location_name")) %>%
  mutate(Month = case_when(month == "01" ~ "January",
                    month == "02" ~ "February",
                    month == "03" ~ "March",
                    month == "04" ~ "April",
                    month == "05" ~ "May",
                    month == "06" ~ "Jun",
                    month == "07" ~ "May",
                    month == "08" ~ "May",
                    month == "09" ~ "May",
                    month == "10" ~ "May",
                    month == "11" ~ "May",
                    month == "12" ~ "May"))

dat_join <- dat_join %>%
  dplyr::select(safegraph_place_id,
                location_name,
                raw_visit_counts2018,
                raw_visit_counts2020,
                NightVisits2018,
                NightVisits2020,
                popularity_by_day2018,
                popularity_by_day2020,
                month) %>%
  left_join(., phila, by = "safegraph_place_id") %>%
  st_as_sf() %>%
  st_transform('ESRI:102728')
```

### Popularity By Hour Data Wrangling & Visualization
```{r eval=FALSE}
#Unnesting popularity by hour variable
dat_hour <- 
  dat2 %>% 
  select(safegraph_place_id, 
         date_range_start, 
         top_category, 
         sub_category, 
         popularity_by_hour, 
         poi_cbg, 
         median_dwell) %>% #select variables
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #clean-up
  unnest(popularity_by_hour) %>% #unnest
  separate(.,
           popularity_by_hour,
           c("0", "1", "2", "3", "4", "5", "6", 
             "7", "8", "9", "10", "11", "12", 
             "13", "14", "15", "16", "17", "18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>% #separate hour values into individual columns
  pivot_longer(cols = 4:27, names_to = "Hour", values_to = "Count") %>% #convert to long format
  mutate(Hour = as.numeric(Hour),
         Count = as.numeric(Count)) #convert hour trip counts to numeric values

dat_hour %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
                              top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
                              top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
                              top_category == "Performing Arts Companies" ~ "Arts")) %>%
  group_by(Hour, category) %>%
  dplyr::summarize(Count = mean(Count)) %>%
  ggplot(., aes(x = Hour, y = Count)) + 
  geom_col() +
  labs(title = "Philadelphia Nightlife Organizations, Average Traffic by Hour",
       subtitle = "Figure X.X") +
  facet_wrap(~category, scales = "free") +
  plotTheme()
```

### App Development 
```{r eval=FALSE}
#Funcion to generate a grid with the combinations.
ComboGrid <- function(rest_factor, bar_factor, arts_factor) {
  
  allCombos <- expand.grid(rest_factor = rest_factor*100,
                           bar_factor = bar_factor*100,
                           arts_factor = arts_factor*100) 
  
  allCombos <- tibble::rowid_to_column(allCombos, "scenario")
  
  allCombos <- 
    allCombos %>% 
    mutate(
      rest = "rest",
      bars = "bars",
      arts = "arts")
  
  allCombos <- allCombos %>%
    mutate(
      filename = 
        paste(allCombos$rest,
      allCombos$rest_factor, 
      allCombos$bars, 
      allCombos$bar_factor, 
      allCombos$arts, 
      allCombos$arts_factor, sep = "-"))
  
  return(allCombos)
}

#Function to generate separate dataframes for each of the scenarios
ScenarioGenerator <- function(dataset, corr_list, rest_factor, bar_factor, arts_factor) {

  allCombos <- expand.grid(rest_factor = rest_factor,
                           bar_factor = bar_factor,
                           arts_factor = arts_factor) 

  allCombos <- tibble::rowid_to_column(allCombos, "ID")

  comboList <- unique(allCombos[['ID']])
  allScenarios <- data.frame()

for (i in comboList) {
    
  thisScenario <-
    dataset %>%
    filter(corridor %in% corr_list) %>%
    dplyr::mutate(scenario = as.numeric(allCombos %>% filter(ID==i) %>% dplyr::select(ID)),
                  count_rest = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(rest_factor)) * count_rest,
                  count_rest_a = count_rest/phl_area_sqmi,
                  count_rest_a_log = log(count_rest_a + 1),
                  count_bars = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(bar_factor)) * count_bars,
                  count_bars_a = count_bars/phl_area_sqmi,
                  count_bars_a_log = log(count_bars_a + 1),
                  count_arts = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(arts_factor)) * count_arts,
                  count_arts_a = count_arts/phl_area_sqmi,
                  count_arts_a_log = log(count_arts_a + 1))
  
  Scenario_preds <- predict(rf_val_fit_time$.workflow, new_data = thisScenario %>% as.data.frame())
  Scenario_preds <- exp(Scenario_preds %>% as.data.frame())

  Scenario_final <- cbind(Scenario_preds, thisScenario %>%
                            dplyr::select(corridor,
                                          count_rest,
                                          count_arts,
                                          count_bars,
                                          Night_visits,
                                          phl_area_sqmi,
                                          scenario,
                                          geometry)) %>%
    dplyr::rename("predictions" = ".pred") %>% #clean-up
    mutate(predictions = round((predictions * phl_area_sqmi), digits = 0)) %>%
    st_as_sf()

  Scenario_final <- Scenario_final %>% st_as_sf() %>% st_transform(crs = "EPSG: 4326")

  Scenario_final <- Scenario_final %>%
    group_by(corridor, scenario) %>%
    summarize(Night_visits = sum(Night_visits),
              predictions = sum(predictions))

  Scenario_final <-
    Scenario_final %>%
    mutate(pct_change = round(((predictions - Night_visits)/Night_visits * 100), digits = 1)) %>%
    # mutate(pct_change = ifelse(corridor %in% corr_list, ((predictions - Night_visits)/Night_visits * 100), NA),
           # predictions = ifelse(corridor %in% corr_list, predictions, NA)) %>%
    as.data.frame()  %>%
    left_join(., ScenarioCombos %>% dplyr::select(scenario, filename)) %>%
    st_as_sf()

  Scenario_final <- as_Spatial(Scenario_final)

  writeOGR(Scenario_final,
           dsn = paste(unique(Scenario_final$filename), ".geojson"),
           'allScenario_final_small',
           driver = 'GeoJSON')
  
}
  return(Scenario_final)
}

#Preparing the dataset to run in the function
dat_scenario <-
  dat_pred %>%
  group_by(corridor, date_range_start) %>%
  summarize(count_rest = sum(restaurant, na.rm = TRUE),
            count_bars = sum(bars, na.rm = TRUE),
            count_arts = sum(arts, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  left_join(dat_pred_agg) %>%
  group_by(corridor) %>%
  drop_na(corridor, demo_MHI, demo_medrent)

#Running the function
rest_factor_select <- c(.95, 1, 1.05) #different scenarios
bar_factor_select <- c(.95, 1, 1.05)
arts_factor_select <- c(.95, 1, 1.05)

ScenarioCombos <- ComboGrid(rest_factor = rest_factor_select,
                            bar_factor = bar_factor_select,
                            arts_factor = arts_factor_select)

ScenarioGenerator(dataset = dat_scenario,
                          corr_list = c("30th Street",
                                        "54006000 Lancaster Ave",
                                        "Broad and Snyder",
                                        "Bustleton and Red Lion",
                                        "Callowhill East",
                                        "Castor and Magee",
                                        "Central Waterfront/Spring Garden",
                                        "City Ave and Belmont vicinity",
                                        "Front and Kensington",
                                        "Girard and Marshall",
                                        "Godfrey and Ogontz",
                                        "Kensington Ave/Harrowgate",
                                        "Market East",
                                        "Oregon Ave/5th-13th",
                                        "Presidential/Belair",
                                        "Richmond and Allegheny",
                                        'Snyder Plaza and Columbus Commons',
                                        "South Street/Front-8th",
                                        "Washington Avenue West"),
                          rest_factor = rest_factor_select,
                          bar_factor = bar_factor_select,
                          arts_factor = arts_factor_select)

# test95
# 
# test105 <- ScenarioGenerator(dataset = dat_scenario,
#                           corr_list = corr_select,
#                           rest_factor = rest_factor_select,
#                           bar_factor = bar_factor_select,
#                           arts_factor = arts_factor_select)
# test105
# 
test <- cbind(st_drop_geometry(test95) %>%
                rename(pct_change_95 = pct_change,
                       corridor_95 = corridor) %>%
                select(corridor_95, pct_change_95),
      st_drop_geometry(test105) %>%
                rename(pct_change_105 = pct_change,
                       corridor_105 = corridor) %>%
        select(corridor_105, pct_change_105))


test %>% 
  filter(pct_change_95 < 0) %>%
  filter(pct_change_105 > 0) %>%
  select(corridor_95) 


corr_list2 <- c("30th Street",
               "54006000 Lancaster Ave",
               "Broad and Snyder",
               "Bustleton and Red Lion",
               "Callowhill East",
               "Castor and Magee",
               "Central Waterfront/Spring Garden",
               "City Ave and Belmont vicinity",
               "Front and Kensington",
               "Girard and Marshall",
               "Godfrey and Ogontz",
               "Kensington Ave/Harrowgate",
               "Market East",
               "Oregon Ave/5th-13th",
               "Presidential/Belair",
               "Richmond and Allegheny",
               'Snyder Plaza and Columbus Commons',
               "South Street/Front-8th",
               "Washington Avenue West")

phl_corridors %>% filter(NAME %in% corr_list2) %>%
  ggplot() +
  geom_sf(data = phl_boundary) +
  geom_sf(fill = "red", color = "red")


```


#####

## Extra Code

```{r corridor vacancy rate}
# 
# corridors_filter <- phl_corridors %>%
#   select(OBJECTID, NAME, VAC_RATE) %>%
#   mutate(vacancy_rate = str_remove_all(VAC_RATE, pattern = "%"),
#          vacancy_rate = str_remove_all(vacancy_rate, pattern = "\r\n"),
#          vacancy_rate = as.numeric(vacancy_rate)) %>%
#   select(-VAC_RATE) %>%
#   st_as_sf()
# 
# # Plot commercial corridors with colors as vacancy rate
# ggplot() +
#   geom_sf(data = phl_boundary, fill = "grey 80") +
#   geom_sf(data = corridors_filter, 
#           aes(fill = vacancy_rate, color = vacancy_rate)) +
#   scale_fill_viridis_c() +
#   scale_color_viridis_c() +
#   labs(title = "Philadelphia Commercial Corridors") + 
#   mapTheme()
```

```{r}
#Filter by Restaurants
# dat_restaurants <- dat_join %>%
#   filter(top_category == "Restaurants and Other Eating Places") %>%
#   filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
#   mutate(GEOID10 = as.numeric(GEOID)) %>%
#   group_by(GEOID10) %>%
#   summarize(Total_Visits2018 = sum(NightVisits2018),
#             Total_Visits2020 = sum(NightVisits2020)) %>%
#   st_drop_geometry() %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)
# 
# #Plot restaurant map
# dat_restaurants %>%  
#   mutate(percent_change = case_when(Percent_Change > 100 ~ 100, 
#                                     Percent_Change <= 100 ~ Percent_Change)) %>%
#   ggplot() + 
#   geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
#   geom_sf(aes(fill = percent_change), color = "transparent") + 
#   scale_fill_distiller(palette="RdYlGn", direction = 1) +
#   labs(title = "Restaurant Trip % Change, April 2018 & April 2020") +
#   mapTheme()
```

```{r}
#Filter by Bars
# dat_bars <- dat_join %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)") %>%
#   filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
#   mutate(GEOID10 = as.numeric(GEOID)) %>%
#   group_by(GEOID10) %>%
#   summarize(Total_Visits2018 = sum(NightVisits2018),
#             Total_Visits2020 = sum(NightVisits2020)) %>%
#   st_drop_geometry() %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)
# 
# #Plot bar map
# dat_bars %>%  
#   # filter(Percent_Change < 300) %>%
#   mutate(percent_change = case_when(Percent_Change > 100 ~ 100, Percent_Change <= 100 ~ Percent_Change)) %>%
#   ggplot() + 
#   geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
#   geom_sf(aes(fill = percent_change), color = "transparent") + 
#   scale_fill_distiller(palette="RdYlGn", direction = 1) +
#   labs(title = "Bar Trip % Change, April 2018 & April 2020") +
#   mapTheme()
```