---
title: 'After Hours: Studying nightlife mobility patterns in  Philadelphia, Pennsylvania'
author: "Maddy Kornhauser, Brian Rawn, Sabrina Lee"
date: "5/2/2021"
output: 
  html_document: 
        code_folding: hide
        toc: true
        toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	out.width = "75%"
)
```

# Introduction

## Purpose

Our goal is to help business improvement districts (BIDs) and small businesses understand the patterns of nightlife across Philadelphia’s commercial corridors in order to further recovery efforts following the COVID-19 pandemic. 

## The Tool

An interactive data dashboard that allows users to understand nightlife patterns at the corridor level across Philadelphia. This dashboard would, for each corridor, answer the questions of “who, what, where, and when?” of nightlife visitors. The dashboard would also allow for comparisons to other corridors. Potential metrics that would be displayed include:

* Corridor popularity (volume of trips) over time. 
* The percentage of visitors attributable to different origin census tracts and a breakdown of associated demographic characteristics.
* Average distance traveled to restaurants/bars/theaters.
* Average dwell time by commercial use.
* The percentage drop in trips that restaurants/bars/theaters experienced as a result of COVID-19.
* For each, a comparison to the average of other commercial corridors.

In addition, the tool will have the additional functionality of being able to predict the future popularity of a commercial corridor given changes in time (hour, day, month), weather, volume of commercial establishments (count or floor area), and retail mix. This predictive functionality would help inform decisions relating to the regulation and expansion of nightlife activities.

## Applications

How will this tool be utilized for economic development? Potential applications include use by BIDs and small businesses to:

* Understand peak trip times by use and location in order to inform parking, transit, or commercial policies.
* Understand relative popularity of commercial corridors to inform decisions to grant licenses or small business assistance.
* Understand origins and demographics of visitors to more effectively target marketing resources. 
* Understand the future effect of more commercial establishments or square footage in a given commercial corridor.

## The SafeGraph Dataset

Safegraph uses anonymized cell phone GPS data to record trips to commercial points of interest. This data can tell us from where a trip was made, what time the trip was made, and how long the individual stated at the point of interest.

* Pros: 
  + Brand new dataset. 
  + Lots of unexplored applications and potential insights

* Cons: 
  + Data is new and has a significant amount of incorrectly attributed trips, especially in urban areas

# Set-up

Our code requires the following packages and datasets

```{r load packages, include=FALSE}
library(tidyverse)
library(tidycensus)
library(sf)
library(lubridate)
library(datetime)
library(viridis)
library(gridExtra)
library(kableExtra)
library(dplyr)
library(ggplot2)
library(gganimate)
library(FNN)
library(caret)
library(stargazer)
library(ranger)
library(tidymodels)

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}
q5 <- function(variable) {as.factor(ntile(variable, 5))}
palette3 <- viridis_pal()(3)
palette5 <- viridis_pal()(5)
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}
mapTheme_dark <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_rect(fill = "black"),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "black"),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}


plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 16,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    dplyr::summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}

setwd("~/GitHub/musa_practicum_nighttime")
```

Our code requires the following datasets.
```{r load & wrangle data}
dat <- read.csv("./data/moves_2018.csv")
data2020 <- read.csv("./data/moves_monthly2020.csv")

phila <- st_read("./demo/phila.geojson", quiet = TRUE)

dat2 <- dat %>% 
  dplyr::select(safegraph_place_id, 
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                visits_by_day, 
                poi_cbg, 
                visitor_home_cbgs, 
                visitor_daytime_cbgs, 
                visitor_work_cbgs, 
                visitor_country_of_origin,
                distance_from_home, 
                median_dwell, 
                bucketed_dwell_times, 
                related_same_day_brand, 
                related_same_month_brand, 
                popularity_by_hour, 
                popularity_by_day, 
                device_type) %>%
  left_join(., phila, by = "safegraph_place_id") %>% 
  st_as_sf() %>%
  st_transform('ESRI:102728')

#Block group shapefiles (projected & unprojected)
phl_cbg <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10))%>%
  st_transform('ESRI:102728') 
phl_cbg_unproj <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/2f982bada233478ea0100528227febce_0.geojson", quiet = TRUE) %>%
  mutate(GEOID10 = as.numeric(GEOID10),
         Lat = as.numeric(INTPTLAT10),
         Lon = as.numeric(INTPTLON10))

#Boundaries shapefiles (projected & unprojected)
phl_boundary <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728')

phl_boundary_unproj <- 
  st_read("https://opendata.arcgis.com/datasets/405ec3da942d4e20869d4e1449a2be48_0.geojson", quiet = TRUE)

#Corridor shapefiles (projected & unprojected)
phl_corridors <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)%>%
  st_transform('ESRI:102728') %>%
  mutate(corr_type = ifelse(CORRIDOR_TYPE == 1, "Neighborhood Subcenter", 
                            ifelse(CORRIDOR_TYPE == 2, "Neighborhood Center", 
                                   ifelse(CORRIDOR_TYPE == 3, "Community Center", 
                                          ifelse(CORRIDOR_TYPE == 4, "Regional Center", 
                                                 ifelse(CORRIDOR_TYPE == 5, "Superregional Center", 
                                                        ifelse(CORRIDOR_TYPE == 6, "Speciality Center", "Other")))))))

phl_corridors_unproj <- st_read("http://data.phl.opendata.arcgis.com/datasets/f43e5f92d34e41249e7a11f269792d11_0.geojson", quiet = TRUE)

#Neighborhood shapefiles (projected & unprojected)
phl_nhoods <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE) %>%
  st_transform('ESRI:102728')
phl_nhoods_unproj <- 
  st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", 
          quiet = TRUE)

#Planning district shapefiles (projected & unprojected)
# phl_dist <-
#   st_read("http://data.phl.opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson", 
#           quiet = TRUE) %>%
#   st_transform('ESRI:102728')
# 
# phl_dist_unproj <-
#   st_read("http://data.phl.opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson", 
#           quiet = TRUE)

#Philadelphia zip codes
phl_zip <- 
  st_read("http://data.phl.opendata.arcgis.com/datasets/b54ec5210cee41c3a884c9086f7af1be_0.geojson", quiet = TRUE) %>%
  st_transform('ESRI:102728') %>%
  mutate(CODE = as.numeric(CODE))
```

# Exploratory Data Analysis

## Philadelphia nightlife establishments

Our first research question is where Philadelphia nightlife establishments are located across the city. The following maps indicate where businesses that contribute to the city's nightlife economy are located. The categories include:

* Bars (Drinking Places)
* Restaurants 
* Arts Venues (Promoters of Performing Arts & Performing Arts Companies)

Figure X.X below shows the spatial patterns of the business categories. Bars and restaurants represent the highest number of businesses which are spread across the city. Hotels are mostly clustered in the central district of the city and near the airport in the southwest portion of the city. There are far fewer casinos and arts venues.

Throughout the analysis, we pay special attention to bars and restaurants, as these organizations are well distributed throughout the city and apply to a local Philadelphia customer base.

```{r establishment locations}
dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           # top_category == "Traveler Accommodation" |
           # top_category == "Gambling Industries" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
                              top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
                              top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
                              top_category == "Performing Arts Companies" ~ "Arts")) %>%
  ggplot() + 
  geom_sf(data = phl_cbg, fill = "grey80", color = "transparent") +
  geom_sf(color = "red", size = .1) +
  labs(title = "Location of Nightlife Establishments",
       subtitle = "Figure X.X") +
  facet_wrap(~category, nrow = 1) +
  mapTheme()
```

To look at the spatial patterns another way, we review the distribution of businesses  with a fishnet grid. The fishnet allows us to visualize clusters and hotspots. Starting first with restaurants, Figure X.X below demonstrates the spatial patterns of these businesses.  Though restaurants are well distributed throughout the city, there appears to be a higher concentration of yellow cells (indicating a higher count of restaurants) in the central part of the city. This corresponds to what we observe in the point data analysis. 
```{r unnesting hour dataset}

fishnet <- 
  st_make_grid(phl_boundary, cellsize = 1500, square = FALSE) %>%
  .[phl_boundary] %>% 
  st_sf() %>%
  mutate(uniqueID = rownames(.))

#Filter restaurants
restaurants <- dat2 %>%
  filter(top_category == "Restaurants and Other Eating Places")%>%
  mutate(Legend = "Restaurants")

#aggregate restaurant count by fishnet cell
restaurants_net <-
  dplyr::select(restaurants) %>% 
  mutate(countRestaurants = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRestaurants = replace_na(countRestaurants, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

#Bars
bars <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)") %>% 
  mutate(Legend = "Bars")

#aggregate bars by fishnet cell
bars_net <-
  dplyr::select(bars) %>% 
  mutate(countBars = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countBars = replace_na(countBars, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE)) %>%
  mutate(Legend = "Bars")

#Performing arts
performingarts <- dat2 %>%
  filter(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(Legend = "Performing Arts")

performingarts_net <-
  dplyr::select(performingarts) %>% 
  mutate(countPerformingarts = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countPerformingarts = replace_na(countPerformingarts, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

# Combining fishnets into a single dataframe
vars_net <- 
  rbind(restaurants, 
        bars, 
        performingarts) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  dplyr::summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(Legend,count, fill=0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup()

vars_net.long <- gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

#Plotting small multiple maps
for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange, c(mapList, 
                        ncol=3, top="Count of Nightlife Businesses per Fishnet", 
                        bottom = "Figure X.X"))
```

## Philadelphia Commercial Corridors

Next, we observe foot traffic along Philadelphia's commercial corridors. This analysis relies on a shapefile from the City of Philadelphia's Planning department which demarcates individual corridors and districts throughout the city. According to the [available metadata](https://metadata.phila.gov/#home/datasetdetails/564236a55737e1f263ae5e3f/representationdetails/56423a4e902dbdd813db9a55/) "locations range from large, regional and specialty destinations to corridors that reflect the evolving economy, culture, and aesthetic traditions of surrounding neighborhoods." This means that the gegoraphies vary in size and character.

Figure X.X shows the different types of commercial corridors based on classifcation by Philadelphia.
[INCLUDE DESCRIPTION OF COMMERCIAL CORRIDORS]

Corridor typologies
1. Neighborhood Subcenter - 10,000 - 35,000 sq.ft. GLA convenience store grocery, pharmacy, dry cleaner, deli, etc.
2. Neighborhood Center - 30,000 - 120,000 sq.ft. GLA supermarket, variety store, bank, pharmacy, post office, etc.
3. Community Center - 100,000 - 500, 000 sq. ft. GLA discount dept store, home improvement, "big boxes" or equiv., "power center"
4. Regional Center - 300,000 - 900,000+ sq.ft. GLA one or two full-line department stores or equivalent
5. Superregional Center - 500,000 - 2,000,000+ sq.ft. GLA three or more full-line department stores or equivalent
6. Specialty Center - specialty goods or services, dining, bars, amusements, arts, etc.

```{r}
phl_corridors %>%
  drop_na(corr_type) %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(aes(fill = corr_type), color = "transparent") +
  scale_fill_viridis_d() +
  labs(title = "Philadelphia Corridor Typologies",
       subtitle = "Figure X.X") +
  mapTheme() +
  theme(legend.position = "bottom",
        legend.title = element_blank())
```

```{r corridor vacancy rate}

corridors_filter <- phl_corridors %>%
  select(OBJECTID, NAME, VAC_RATE) %>%
  mutate(vacancy_rate = str_remove_all(VAC_RATE, pattern = "%"),
         vacancy_rate = str_remove_all(vacancy_rate, pattern = "\r\n"),
         vacancy_rate = as.numeric(vacancy_rate)) %>%
  select(-VAC_RATE) %>%
  st_as_sf()

# Plot commercial corridors with colors as vacancy rate
ggplot() +
  geom_sf(data = phl_boundary, fill = "grey 80") +
  geom_sf(data = corridors_filter, 
          aes(fill = vacancy_rate, color = vacancy_rate)) +
  scale_fill_viridis_c() +
  scale_color_viridis_c() +
  labs(title = "Philadelphia Commercial Corridors") + 
  mapTheme()
```

Figure X.X below breaks down the count of restaunts in a given corridor per square miile.  We find that central corridors and districts tend to have more restaurants per square mile. Other corridors. That said, corridors across the city have a high concentration of restaurants as well.
```{r}
###Restaurants (takes a really long time)
# dat_restaurants_grid <- dat_restaurants %>%
#   select(geometry) %>%
#   na.omit() %>%
#   st_as_sf() %>%
#   # st_transform('ESRI:102271') %>% 
#     distinct()
# 
# #Merge restaurants with commercial corridors 
# corridors_restaurants <- 
#   dplyr::select(dat_restaurants_grid) %>% 
#   mutate(countRestaurant = 1) %>% 
#   aggregate(., corridors_filter, sum) %>%
#   mutate(countRestaurant = replace_na(countRestaurant, 0),
#          uniqueID = rownames(.),
#          area = st_area(geometry) * .00000038610,
#          count_per_mile = as.numeric(countRestaurant / area),
#          cvID = sample(round(nrow(corridors_filter) / 24), size=nrow(corridors_filter), replace = TRUE))
# 
# #Plot map of number of restaurants per square mile
# ggplot() +
#   geom_sf(data = phillyBoundary, fill = "black") +
#   geom_sf(data = corridors_restaurants, aes(fill = count_per_mile), color = "transparent") +
#   scale_fill_viridis(trans = "sqrt") +
#   labs(title = "Count of Restaurants per Square Mile in Each Commercial Corridor",
#        subtitle = "Figure X.X") +
#   mapTheme()
```

Below is an animation showing restaurant popularity by corridor.
```{r}
#Create animated map of number of restaurant trips by corridor per hour
# dat_restaurants_cord <- dat_restaurants %>%
#   st_as_sf() %>%
#   st_transform('ESRI:102271') 
# 
# dat_corridors_restaurants <-
#   st_join(corridors_filter, dat_restaurants_cord, ) %>% 
#   group_by(NAME, GLA, Hour) %>%
#   summarize(
#             Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count),
#             Med_Dwell_Time = mean(median_dwell)) %>%
#   st_as_sf() 
# 
# dat_corridors_restaurants <- dat_corridors_restaurants %>%
#   mutate(
#     GLA = as.numeric(gsub(",", "", GLA)),
#     Visits_Per_Area = Total_Visits / GLA * 5)
# 
# #Animation of restaurant popularity by hour
# restaurant.corr.animation.data <-
#     dat_corridors_restaurants %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area < .4 ~ "5",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.8 ~ "4",
#                               Visits_Per_Area >= .8 & Visits_Per_Area <1.2 ~ "3",
#                               Visits_Per_Area >= 1.2 & Visits_Per_Area <1.6 ~ "2",
#                               Visits_Per_Area >= 2 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# restaurant_corr_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent") +   
#   geom_sf(data = restaurant.corr.animation.data, aes(fill = Visits_Per_Area), color = "transparent") +
#      scale_fill_viridis(trans = "sqrt") +
#     labs(title = "Restaurant Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
# 
# animate(restaurant_corr_animation, duration=20, renderer = gifski_renderer())
```

Figure X.X shows the number of bars in each commercial corridor per square mile. Again, we see the corridors around Center City generally showing a higher concentration of bars.
```{r Bars by corridor}
###Bars
# dat_bars_grid <- dat_bars %>%
#   select(geometry) %>%
#   #na.omit() %>%
#   st_as_sf() %>%
#   st_transform('ESRI:102271') %>%
#     distinct()
# 
# ###Bars
# corridors_bars <- 
#   dplyr::select(dat_bars_grid) %>% 
#   mutate(countBar = 1) %>% 
#   aggregate(., corridors_filter, sum) %>%
#   mutate(countBar = replace_na(countBar, 0),
#          uniqueID = rownames(.),
#          area = st_area(geometry) * .00000038610,
#          count_per_mile = as.numeric(countBar / area),
#          cvID = sample(round(nrow(corridors_filter) / 24), size=nrow(corridors_filter), replace = TRUE))
# 
# #Plot map of number of bars per square mile
# ggplot() +
#   geom_sf(data = phillyBoundary, fill = "black") +
#   geom_sf(data = corridors_bars, aes(fill = count_per_mile), color = "transparent") +
#   scale_fill_viridis(trans = "sqrt") +
#   labs(title = "Count of Bars per Square Mile in Each Commercial Corridor", 
#        subtitle = "Figure X.X") +
#   mapTheme()
```

Below is an animation showing bar popularity aggregated by commercial corridor.
```{r bars animation}
#Create animated map of number of bar trips by corridor per hour
# dat_bars_cord <- dat_bars %>%
#   st_as_sf() %>%
#   st_transform('ESRI:102271') 
# 
# dat_corridors_bars <-
#   st_join(corridors_filter, dat_bars_cord, ) %>% 
#   group_by(NAME, GLA, Hour) %>%
#   summarize(Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count),
#             Med_Dwell_Time = mean(median_dwell)) %>%
#   st_as_sf() 
# 
# dat_corridors_bars <- dat_corridors_bars %>%
#   mutate(
#     GLA = as.numeric(gsub(",", "", GLA)),
#     Visits_Per_Area = Total_Visits / GLA * 5)
# 
# #Animation of bar popularity by hour
# bar.corr.animation.data <-
#     dat_corridors_bars %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area < .4 ~ "5",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.8 ~ "4",
#                               Visits_Per_Area >= .8 & Visits_Per_Area <1.2 ~ "3",
#                               Visits_Per_Area >= 1.2 & Visits_Per_Area <1.6 ~ "2",
#                               Visits_Per_Area >= 2 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# bar_corr_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent") +   
#   geom_sf(data = bar.corr.animation.data, aes(fill = Visits_Per_Area), color = "transparent") +
#      scale_fill_viridis(trans = "sqrt") +
#     labs(title = "Bar Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
# 
# animate(bar_corr_animation, duration=20, renderer = gifski_renderer())
```

## The Impacts of COVID-19 on Nightlife Establishments & Commercial Corridors
```{r data wrangling for COVID-19}
# Modify 2018 data
dat_2018 <- 
  dat %>% 
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2018 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_2018 <- dat_2018 %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                popularity_by_day,
                NightVisits2018) %>%
  rename(raw_visit_counts2018 = raw_visit_counts, 
         raw_visitor_counts2018 = raw_visitor_counts, 
         popularity_by_day2018 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7))

dat_2020 <- 
  data2020 %>% 
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #remove brackets
  unnest(popularity_by_hour) %>% #unnest values
  separate(.,
           popularity_by_hour,
           c("18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>%
  mutate(.,NightVisits2020 = as.numeric(`18`) + as.numeric(`19`) + as.numeric(`20`) + as.numeric(`21`) + as.numeric(`22`) + as.numeric(`23`))

dat_join <- dat_2020 %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                date_range_start, 
                date_range_end, 
                raw_visit_counts,
                raw_visitor_counts, 
                popularity_by_day,
                NightVisits2020) %>%
  rename(raw_visit_counts2020 = raw_visit_counts, 
         raw_visitor_counts2020 = raw_visitor_counts, 
         popularity_by_day2020 = popularity_by_day) %>%
  mutate(month = substring(date_range_start,6,7)) %>%
  inner_join(., dat_2018, by = c("safegraph_place_id", "month", "location_name")) %>%
  mutate(Month = case_when(month == "01" ~ "January",
                    month == "02" ~ "February",
                    month == "03" ~ "March",
                    month == "04" ~ "April",
                    month == "05" ~ "May", 
                    month == "06" ~ "Jun",
                    month == "07" ~ "May",
                    month == "08" ~ "May",
                    month == "09" ~ "May",
                    month == "10" ~ "May",
                    month == "11" ~ "May",
                    month == "12" ~ "May"))

dat_join <- dat_join %>% 
  dplyr::select(safegraph_place_id, 
                location_name,
                raw_visit_counts2018,
                raw_visit_counts2020,
                NightVisits2018,
                NightVisits2020,
                popularity_by_day2018,
                popularity_by_day2020,
                month) %>%
  left_join(., phila, by = "safegraph_place_id") %>% 
  st_as_sf() %>%
  st_transform('ESRI:102728') 
```

First, we observe citywide changes in foot traffic over the course of the pandemic. Comparing 2020 traffic to our 2018 dataset, we see that traffic across the city drastically decreased in March 2020 and represented less then half of the 2018 traffic. This trend continued thorughout the year.
```{r}
#Citywide nighttime visits
dat_citywide <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot citywide chart
dat_citywide %>%
ggplot(., aes(x = month, y = Percent_Change, fill = Percent_Change)) + 
  geom_col() +
  scale_fill_viridis_c() +
  # scale_fill_distiller(palette="viridis", direction = 1) +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X", y = "Percent Change", x = "Month") +
  plotTheme() 
```

Next we split the percent change in traffic out by business types relevant to our nightlife study: arts establishments, bars, and restaurants. While arts establishments indicate that there was some recovery towards the end of 2020, bars and restaurants suffered decreased traffic throughout the year. This divergent trend from the arts establishments could be related to stricter policies regarding occupancy at bars and restaurants, where you have to remove your mask to eat and drink, or public discomfort with visitng these businesses.
```{r}
#Separate by commercial use  
dat_citywide2 <- dat_join %>%
    filter(top_category == "Drinking Places (Alcoholic Beverages)" |
             top_category == "Restaurants and Other Eating Places" |
             top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
             top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
           top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
           top_category == "Performing Arts Companies" ~ "Arts")) %>%
    group_by(category, month) %>%
    summarize(Total_Visits2018 = sum(NightVisits2018),
              Total_Visits2020 = sum(NightVisits2020)) %>%
    mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)  
  
#Plot citywide chart by commercial use
dat_citywide2 %>%
  ggplot(., aes(x = month, y = Percent_Change, fill = Percent_Change)) + 
  geom_col() +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X") +
  scale_fill_viridis_c() +
  # scale_fill_distiller(palette="PiYG", direction = 1) +
  facet_wrap(~category) +
  plotTheme() +
  theme(legend.position = "bottom")
```

Lookign at the trends another way, the below line plot shows how the traffic patterns for bars and restaurants were very similar, but the arts establishments made a stronger rebound at the end of 2020.
```{r}
rbind(
  (dat_join %>% 
  group_by(month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100,
         category = "All")), 
  dat_citywide2) %>%
  ggplot(., aes(x = month, y = Percent_Change, group = category, color = category)) + 
  geom_line(lwd = 1.5) +
  geom_hline(yintercept=0, lwd = 1.5, linetype="dotted")+
  scale_color_manual(values = c("#d3d3d3", "#440154", "#21908C", "#FDE725")) +
  scale_x_discrete(name ="Month")+  
  scale_y_continuous(name ="Percent Change") +
  labs(title = "Philadelphia Commercial Trip % Change, 2018 & 2020",
       subtitle = "Figure X.X") +
  plotTheme()
```

The following figure shows the change in restaurant traffic by Philadelphia block group. With the exception of a few areas, all block groups indicated a sharp decrease in restaurant traffic, many by over 50%.
```{r}
#Filter by Restaurants
dat_restaurants <- dat_join %>%
  filter(top_category == "Restaurants and Other Eating Places") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  group_by(GEOID10) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  st_drop_geometry() %>%
  left_join(phl_cbg) %>% 
  st_as_sf() %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot restaurant map
dat_restaurants %>%  
  mutate(percent_change = case_when(Percent_Change > 100 ~ 100, 
                                    Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
  geom_sf(aes(fill = percent_change), color = "transparent") + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Restaurant Trip % Change, April 2018 & April 2020") +
  mapTheme()
```

The same is largely true of bars, thoguh there are some exceptions. It is possible that some of the areas showing an increase in traffic were related to the availability of outdoor space, as more densly populated areas of the city underwent a severe drop.
```{r}
#Filter by Bars
dat_bars <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  group_by(GEOID10) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  st_drop_geometry() %>%
  left_join(phl_cbg) %>% 
  st_as_sf() %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot bar map
dat_bars %>%  
  # filter(Percent_Change < 300) %>%
  mutate(percent_change = case_when(Percent_Change > 100 ~ 100, Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
  geom_sf(aes(fill = percent_change), color = "transparent") + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Bar Trip % Change, April 2018 & April 2020") +
  mapTheme()
```

The following map shows changes in traffic for all nightlife categories.
```{r}
dat_night <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
             top_category == "Restaurants and Other Eating Places" |
             top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
             top_category == "Performing Arts Companies") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  group_by(GEOID10) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  st_drop_geometry() %>%
  left_join(phl_cbg) %>% 
  st_as_sf() %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100)

#Plot map
dat_night %>%  
  mutate(percent_change = case_when(Percent_Change > 100 ~ 100, 
                                    Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey20", color = "black")+
  geom_sf(aes(fill = percent_change), color = "transparent") + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Nightlife Trip % Change, April 2018 & April 2020") +
  mapTheme()
```

Finally, we are interested to see how this impacts individual commercial corridors across Philadelphia. The below map shows decrease of traffic to nightlife establishments along such corridors. While some smaller corridors did not experience much change in traffic or even a small increase in traffic, the majority of corridors saw a large decrease in traffic. This is particularly evident in Center City, along Market Street in West Philadelphia and at the airport. 

```{r corridor analysis}
corridors_filter <- phl_corridors %>%
  select(OBJECTID, NAME, GLA, P_DIST, ST_EXT, PT_ADD, VAC_RATE) %>%
  mutate(VAC_RATE = str_remove_all(VAC_RATE, pattern = "%")) %>%
  mutate(VAC_RATE = as.numeric(VAC_RATE)) %>%
  st_as_sf() %>%
  st_transform('ESRI:102728') 
  
dat_corr <- dat_join %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  filter(month == '04'| month == '05' | month == '06' | month == '07' | month == '08' | month == '09' | month =='10' | month == '11' | month == '12') %>%
  mutate(GEOID10 = as.numeric(GEOID)) %>%
  st_join(corridors_filter) %>% 
  group_by(NAME.y, month) %>%
  summarize(Total_Visits2018 = sum(NightVisits2018),
            Total_Visits2020 = sum(NightVisits2020)) %>%
  mutate(Percent_Change = (Total_Visits2020 - Total_Visits2018)/Total_Visits2018*100) %>%
  drop_na(NAME.y) %>%
  st_as_sf() %>%
  st_transform('ESRI:102728') %>%
  st_drop_geometry() 

dat_corr <- dat_corr %>%
  mutate(NAME = NAME.y) %>%
  left_join(corridors_filter)

#Average across all months
dat_corr_avg <- dat_corr %>%  
  group_by(NAME) %>%
  summarize(Percent_Change = mean(Percent_Change))

#All Commercial Uses Corridor Map
dat_corr %>%  
  filter(month == "05") %>%
  mutate(Percent_Change = case_when(Percent_Change > 100 ~ 100, 
                                    Percent_Change <= 100 ~ Percent_Change)) %>%
  ggplot() + 
  geom_sf(data = phl_boundary, fill = "grey10", color = "darkgrey")+
  geom_sf(aes(fill = Percent_Change, geometry = geometry), color = "transparent") + 
  scale_fill_distiller(palette="RdYlGn", direction = 1) +
  labs(title = "Commercial Nighttime Trip % Change, April 2018 & 2020") +
  mapTheme()
```

## Hourly traffic volume across corridor and establishment types

Next, we explore when visitors make trips to nightlife establishments. To do this, we worked with the popularity_by_hour SafeGraph variable, which sums the total number of visitors by hour for each month.

Figure X.X shows the average foot traffic by business type over the course of a day. This graphic indicates that though certain business types are considererd part of the nightlife economy, they do not exclusively experience traffic in the evenings. Restaurants are a good example of this, where the data indicates that the highest levels of traffic occur in the middle of the day. Arts venues, on the other hand, have a clear patterns indicating that they are more popular later in the day.
```{r traffic by nightlife establishment}
#Unnesting popularity by hour variable
dat_hour <- 
  dat2 %>% 
  select(safegraph_place_id, 
         date_range_start, 
         top_category, 
         sub_category, 
         popularity_by_hour, 
         poi_cbg, 
         median_dwell) %>% #select variables
  mutate(popularity_by_hour = str_remove_all(popularity_by_hour, pattern = "\\[|\\]")) %>% #clean-up
  unnest(popularity_by_hour) %>% #unnest
  separate(.,
           popularity_by_hour,
           c("0", "1", "2", "3", "4", "5", "6", 
             "7", "8", "9", "10", "11", "12", 
             "13", "14", "15", "16", "17", "18",
             "19", "20", "21", "22", "23"),
           sep = ",") %>% #separate hour values into individual columns
  pivot_longer(cols = 4:27, names_to = "Hour", values_to = "Count") %>% #convert to long format
  mutate(Hour = as.numeric(Hour),
         Count = as.numeric(Count)) #convert hour trip counts to numeric values

dat_hour %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = case_when(top_category == "Drinking Places (Alcoholic Beverages)" ~ "Bars",
                              top_category == "Restaurants and Other Eating Places" ~ "Restaurants",
                              top_category == "Promoters of Performing Arts, Sports, and Similar Events" ~ "Arts",
                              top_category == "Performing Arts Companies" ~ "Arts")) %>%
  group_by(Hour, category) %>%
  dplyr::summarize(Count = mean(Count)) %>%
  ggplot(., aes(x = Hour, y = Count)) + 
  geom_col() +
  labs(title = "Philadelphia Nightlife Organizations, Average Traffic by Hour",
       subtitle = "Figure X.X") +
  facet_wrap(~category, scales = "free") +
  plotTheme()
```

The following animation shows restaurant visitor counts by census block group over the course of the day. We observe the highest amount of traffic in center city in the middle of the day and then a resurgence of traffic elsewhere in the city in the evening. This suggests that people dine at neighborhood establishments close to their home in the evening.
```{r}
# dat_restaurants <-
#   dat_hour %>%
#   filter(top_category == "Restaurants and Other Eating Places") 
# 
# dat_restaurant_filter <-
#   dat_restaurants %>%
#   dplyr::rename(., GEOID10 = poi_cbg) %>%
#   dplyr::group_by(GEOID10, Hour) %>%
#   dplyr::summarize(Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count)) %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Visits_Per_Area = Total_Visits / Shape__Area * 100)
# 
# #Animation of restaurant popularity by hour
# restaurant.animation.data <-
#     dat_restaurant_filter %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area < .4 ~ "5",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.8 ~ "4",
#                               Visits_Per_Area >= .8 & Visits_Per_Area <1.2 ~ "3",
#                               Visits_Per_Area >= 1.2 & Visits_Per_Area <1.6 ~ "2",
#                               Visits_Per_Area >= 2 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# restaurant_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent") +   
#   geom_sf(data = restaurant.animation.data, aes(fill = Pop_String), color = "transparent") +
#     scale_fill_manual(values = palette5) +
#     labs(title = "Restaurant Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
#   
# 
# animate(restaurant_animation, duration=20, renderer = gifski_renderer())
```

The following animation shows the same metric for bars. We observe traffic increasing throughout the day starting in the afternoon.
```{r bar animation}
# #Bar Analysis
# #Filter Bars
# dat_bars <- dat_hour %>%
#   filter(top_category == "Drinking Places (Alcoholic Beverages)") 
# 
# #Merge CBGs with popularity by hour data
# dat_bars_filter <-
#   dat_bars %>%
#   dplyr::rename(., GEOID10 = poi_cbg) %>%
#   dplyr::group_by(GEOID10, Hour) %>%
#   dplyr::summarize(Avg_Popularity = mean(Count),
#             Total_Visits = sum(Count)) %>%
#   left_join(phl_cbg) %>% 
#   st_as_sf() %>%
#   mutate(Visits_Per_Area = Total_Visits / Shape__Area * 100)
# 
# #Animation of bar popularity by hour
# bar.animation.data <-
#     dat_bars_filter %>%
#     st_sf() %>%
#     mutate(Pop_String = case_when(Visits_Per_Area == 0 ~ "5",
#                               Visits_Per_Area > 0 & Visits_Per_Area <.2 ~ "4",
#                               Visits_Per_Area >= .2 & Visits_Per_Area <.4 ~ "3",
#                               Visits_Per_Area >= .4 & Visits_Per_Area <.6 ~ "2",
#                               Visits_Per_Area >= .6 ~ "1")) %>%
#     mutate(Pop_String  = fct_relevel(Pop_String, "5","4","3","2","1"))
# 
# bar_animation <-
#   ggplot() +
#   geom_sf(data = phl_cbg, fill = "#440255", color = "transparent", ) +
#   geom_sf(data = bar.animation.data, aes(fill = Pop_String), color = "transparent") +
#     scale_fill_manual(values = palette5) +
#     labs(title = "Bar Popularity by Hour",
#          subtitle = "One Hour Intervals: {current_frame}") +
#   theme(panel.background = element_rect(fill = "black"),
#          panel.grid.major = element_line(color = "transparent"),
#           panel.grid.minor = element_line(colour = "transparent")) +
#     transition_manual(Hour)
# 
# animate(bar_animation, duration=20, renderer = gifski_renderer())
```

## Hourly traffic by corridor types

```{r wrangling new hour variables}
dat_1_6 <- dat_hour %>%
  #select trip counts between the hours of 1AM and 6AM
  filter(Hour == "1" | Hour == "2" | Hour == "3" | Hour == "4" | Hour == "5" | Hour == "6") %>% 
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs1_6 = sum(Count)) 

dat_7_12 <- dat_hour %>%
  #select trip counts between the hours of 7AM and 12PM
  filter(Hour == "7" | Hour == "8" | Hour == "9" | Hour == "10" | Hour == "11" | Hour == "12") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs7_12 = sum(Count)) 

dat_13_18 <- dat_hour %>%
  #select trip counts between the hours of 1PM and 6PM
  filter(Hour == "13" | Hour == "14" | Hour == "15" | Hour == "16" | Hour == "17" | Hour == "18") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs13_18 = sum(Count)) 

dat_19_0 <- dat_hour %>%
  #select trip counts between the hours of 6PM and 12AM
  filter(Hour == "19" | Hour == "20" | Hour == "21" | Hour == "22" | Hour == "23" | Hour == "0") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs19_0 = sum(Count)) 

dat_workday <- dat_hour %>%
  #select trip counts between workday hours of 9AM and 6PM
  filter(Hour == "9" | Hour == "10" | Hour == "11" | Hour == "12" | Hour == "13" | Hour == "14" |Hour == "15" | Hour == "16" |Hour == "17" |Hour == "18") %>%
  group_by(safegraph_place_id, date_range_start) %>%
  summarize(Hrs_workday = sum(Count))

#Combine into new dataset with hour trip counts and corridor + neighborhood information
dat3 <- 
  dat2 %>% 
  left_join(dat_1_6, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_7_12, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_13_18, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_19_0, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_workday, by = c('safegraph_place_id', 'date_range_start')) %>%
  st_join(phl_corridors, join = st_intersects) %>%
  st_join(phl_nhoods, join = st_intersects)
```

```{r}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  group_by(corr_type) %>%
  summarise(Early_AM = sum(Hrs1_6),
            Late_AM = sum(Hrs7_12),
            Early_PM = sum(Hrs13_18),
            Late_PM = sum(Hrs19_0)) %>%
  pivot_longer(cols = 2:5,
               names_to = "Time",
               values_to = "Traffic") %>%
  ggplot(aes(fill=factor(Time, levels=c("Late_PM", 
                                        "Early_PM", 
                                        "Late_AM", 
                                        "Early_AM")), 
             y=Traffic, 
             x=factor(corr_type, levels=c("Speciality Center",
                                          "Superregional Center",
                                          "Regional Center",
                                          "Community Center",
                                          "Neighborhood Center",
                                          "Neighborhood Subcenter")))) + 
  geom_bar(position="fill", stat="identity") +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(title = "Share of Traffic by Time of Day Across Corridor Types",
       subtitle = "Figure X.X") +
  plotTheme() +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

```{r}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  mutate(category = ifelse(top_category == "Drinking Places (Alcoholic Beverages)", "Bars",
                           ifelse(top_category == "Restaurants and Other Eating Places", "Restaurants",
                                  ifelse(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
                                           top_category == "Performing Arts Companies", "Arts", "Other")))) %>%
  group_by(corr_type, category) %>%
  summarise(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  pivot_longer(cols = 3:6,
               names_to = "Time",
               values_to = "Traffic") %>%
  ggplot(aes(fill=factor(Time, levels=c("Hrs19_0", "Hrs13_18", "Hrs7_12", "Hrs1_6")), 
             y=Traffic, 
             x=category)) + 
  geom_bar(position="fill", stat="identity") +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(title = "Total Daily Traffic Volume by Corridor Type",
       subtitle = "Figure X.X") +
  facet_wrap(~corr_type) +
  guides(fill=guide_legend(title=NULL)) +
  plotTheme()
```

## Share of trips that occurs during the evening hours
```{r bar plot}
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  group_by(corr_type) %>%
  summarize(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  mutate(TotalTrips = Hrs1_6 + Hrs7_12 + Hrs13_18 + Hrs19_0,
         Pct.EveningTrips = Hrs19_0 / TotalTrips *100) %>%
  ggplot(aes(y = Pct.EveningTrips, x = corr_type)) +
  geom_bar(stat = "identity") + 
  plotTheme() +
  scale_x_discrete(name ="Corridor Type")+  
  scale_y_continuous(name ="Percent of Trips during Evening")
```

```{r map}
dat3 %>%
  group_by(NAME.y) %>%
  summarize(Hrs1_6 = sum(Hrs1_6),
            Hrs7_12 = sum(Hrs7_12),
            Hrs13_18 = sum(Hrs13_18),
            Hrs19_0 = sum(Hrs19_0)) %>%
  mutate(TotalTrips = Hrs1_6 + Hrs7_12 + Hrs13_18 + Hrs19_0,
         Pct.EveningTrips = Hrs19_0 / TotalTrips *100) %>%
  st_drop_geometry() %>%
  dplyr::rename(NAME = NAME.y) %>%
  left_join(phl_corridors %>% select(NAME, geometry)) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = 'grey80', color = 'grey40') +
  geom_sf(aes(fill = q5(Pct.EveningTrips)), color = "transparent") +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Share of Evening Trips \n(Quintile)") +
  # geom_sf(aes(fill = Pct.EveningTrips), color = "transparent") +
  # scale_fill_viridis() +
  mapTheme() +
  theme(legend.position = "bottom")
```

## Trip Flows

### Origins & destinations

The SafeGraph data fundamentally captures flow of people across space by connecting a series of origins and destinations. By mapping the origins and destinations of trips taking place across Philadlephia, we can observe which regions of the city draw from a larger crowd across the city, and which areas cater to a more local population.

The following maps look at the origins and destinations for trips to restaurants, bars, and arts venues across the city. Specifically, it shows the distance between the centroid of the origin neighborhood to the centroid of the destination commercial corridor. We selected 6 corridors across Philadelphia in different areas of the city that we felt represented a diverse array of commercial corridors in the city. Going forward, we would like to run a K-means clustering test to help sort the corridors into like categories that will help us understand the distinct profiles of corridors in Philadelphia.

The code draws each line segments based on lat/long coordinates of the origin an destination centroid (could not get this to work with projected data). Note that trips to destinations located outside of the commercial corridors are left off of these maps. 

The following code block loads unprojected shapefiles for the block groups and city boundary as well as wrangle the data into a list of individual origins and destinations for nightlife-related businesses.
```{r flows data wrangling}
flows <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>% #filter for business types
  st_join(phl_corridors) %>% #join destinations to phl corridors (apply corridor destination to each trip)
  st_as_sf() %>%
  st_drop_geometry() %>% 
  select(safegraph_place_id, 
         date_range_start,
         top_category,
         poi_cbg,
         visitor_home_cbgs,
         NAME.y) %>% #select columns
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\[|\\]")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = "\\{|\\}")) %>%
  mutate(visitor_home_cbgs = str_remove_all(visitor_home_cbgs, pattern = '\\"|\\"')) %>%
  mutate(visitor_home_cbgs = str_split(visitor_home_cbgs, pattern = ",")) %>%
  unnest(visitor_home_cbgs) %>% #unnest visitor cbg column
  separate(.,
           visitor_home_cbgs,
           c("visitor_cbg", "count"),
           sep = ":") %>% #separate count column from visitor cbg
  mutate(count = as.numeric(count),
         visitor_cbg = as.numeric(visitor_cbg)) %>%
  dplyr::rename(., corridor_dest = NAME.y) %>%
  drop_na(corridor_dest) #Remove trips with destinations outside of corridors

#prepare PHL boundary file to coordinates for plotting
phl_boundary_unproj <-
  phl_boundary_unproj %>%
  st_coordinates() # split out coordinates

phl_boundary_unproj <-
  as.data.frame(phl_boundary_unproj) # save as dataframe

#----MAP V1: NEIGHBORHOOD CENTROID TO CORRIDOR CENTROIDS
#Generate CBG centroid
phl_cbg_cent <- 
  phl_cbg_unproj %>% 
  select(GEOID10, geometry) %>% 
  st_centroid()

#Generate neighborhood centroids
phl_nhood_cent <- 
  phl_nhoods_unproj %>% 
  select(name) %>%
  st_centroid()

#Generate corridor centroid
phl_corr_cent <- 
  phl_corridors_unproj %>% 
  select(NAME, geometry) %>% 
  st_centroid()

#Join CBG centroid to neighborhood shapefile
phl_cbg_nhood <- 
  st_join(phl_nhoods_unproj, phl_cbg_cent, join = st_intersects) %>%
  select(GEOID10, name) %>%
  st_centroid()

flows_nhood <- flows %>%
  left_join(phl_cbg_nhood, by=c("visitor_cbg"="GEOID10")) %>% #join visitor CBGs to nhoods
  dplyr::rename(., nhood_origin = name) %>% #cleanup columns for clarity
  drop_na(nhood_origin) %>% #dropping trips outside of Philadelphia
  st_as_sf() %>%
  st_drop_geometry() %>% 
  group_by(nhood_origin, top_category, corridor_dest) %>% #grouping trip counts by origin neighborhood
  summarize(count = sum(count)) %>%
  left_join(phl_nhood_cent, by=c("nhood_origin"="name")) %>% #join origin nhood to nhood centroid
  left_join(., phl_corr_cent, by=c("corridor_dest"="NAME")) %>% #join destination corridor to corr centroid
  dplyr::rename(., origin.geom = geometry.x,
                        dest.geom = geometry.y) #clean-up columns for clarity

#Convert from tibble to data frame for next step
flows_nhood <- as.data.frame(flows_nhood) 

#split point data into lat and long columns
flows_nhood <- flows_nhood %>% 
  mutate(lat.origin = unlist(map(flows_nhood$origin.geom,1)),
         long.origin = unlist(map(flows_nhood$origin.geom,2)),
         lat.dest = unlist(map(flows_nhood$dest.geom,1)),
         long.dest = unlist(map(flows_nhood$dest.geom,2)),
         id = as.character(c(1:nrow(.))))

#Maps - straight line segment example
flows_nhood %>% 
  filter(corridor_dest == "East Girard" | 
           corridor_dest == 'Navy Yard' | 
           corridor_dest == '5th and Olney' | 
           corridor_dest == 'East Passyunk' |
           corridor_dest == '36th Street and vicinity' |
           corridor_dest == 'Market West') %>% 
  ggplot() + 
  geom_polygon(data = phl_boundary_unproj, aes(x=X, y=Y), fill = "grey40") + 
  geom_segment(aes(x = lat.origin, y = long.origin, xend = lat.dest, yend = long.dest,  
                   color=log(count)),
               # arrow = arrow(length = unit(0.01, "cm")), 
               size = .5,
               lineend = "round") +
  # scale_colour_distiller(palette="Reds", name="Count", guide = "colorbar", direction = 1) +
  scale_color_viridis_c() +
  coord_equal() +
  mapTheme() + 
  facet_wrap(~corridor_dest, ncol = 3) +
  labs(title = "Trips")
```

## Other Exploratory Analysis with SafeGraph Data

```{r}
dat3 %>%
  drop_na(NAME.y) %>%
  group_by(NAME.y) %>%
  summarize(distance_from_home = mean(distance_from_home, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  rename("NAME" = "NAME.y") %>%
  left_join(., phl_corridors) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(aes(fill = q5(distance_from_home)), color = "transparent") +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Distance from Home (Quintile)") +
  labs(title = "Distance from Home",
       subtitle = "Figure X.X") +
  mapTheme() +
  theme(legend.position = "bottom")

#Barplots
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(corr_type) %>%
  summarise(Avg_Distance_m = mean(distance_from_home, na.rm = TRUE)) %>%
  ggplot(aes(y=Avg_Distance_m, 
             x=factor(corr_type, levels=c("Neighborhood Subcenter",
                                          "Neighborhood Center",
                                          "Community Center",
                                          "Regional Center",
                                          "Superregional Center",
                                          "Speciality Center")))) + 
  geom_bar(stat="identity") +
  scale_fill_viridis_d() +
  labs(title = "Distance from Home",
       subtitle = "Figure X.X") +
  # facet_wrap(~corr_type) +
  guides(fill=guide_legend(title=NULL)) +
  theme(axis.title.x = element_blank()) +
  plotTheme() 
```

The following Figures look at the median dwell time by bars and restaurants per commercial corridor.
```{r}
dat3 %>%  
  drop_na(NAME.y, corr_type) %>%
  group_by(NAME.y) %>%
  summarize(median_dwell = median(median_dwell, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  rename("NAME" = "NAME.y") %>%
  left_join(., phl_corridors) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(data = phl_boundary, fill = "grey60", color = "transparent") +
  geom_sf(aes(fill = q5(median_dwell)), color = "transparent") +
  scale_fill_manual(values = palette5,
                    aesthetics = c("colour", "fill"),
                    name = "Median Dwell \n(Quintile)") +
  mapTheme()

#Barplots
dat3 %>%
  st_drop_geometry() %>%
  drop_na(corr_type) %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)" |
           top_category == "Restaurants and Other Eating Places" |
           top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  group_by(corr_type) %>%
  summarise(Dwell = median(median_dwell, na.rm = TRUE)) %>%
  ggplot(aes(y=Dwell, 
             x=factor(corr_type, levels=c("Neighborhood Subcenter",
                                          "Neighborhood Center",
                                          "Community Center",
                                          "Regional Center",
                                          "Superregional Center",
                                          "Speciality Center")))) + 
  geom_bar(stat="identity") +
  scale_fill_viridis_d() +
  labs(title = "Median Dwell by Establishment and Corridor Type",
       subtitle = "Figure X.X") +
  guides(fill=guide_legend(title=NULL)) +
  plotTheme()
```

# Predictive Model
Our model will predict the number of nighttime trips to commercial corridors (trips between the hours of 7PM and 12AM) given features of the corridor such as retail mix, amenities, location, etc. Ultimately, we plan to use this model as a scenario-based tool that allows users to adjust the business mix for a given corriodr as a way to understand how different economic development strategies will impact popularity.

While the model will predict the number of trips, the ultimate output for the user will be relative popularity of the corridor compared to the average. This is becasue the data is inherently noisy and we cannot be confident that a raw trip count is accurate.

## Data Pull
This first code block loads in data that we will use for the predictive model.
```{r loading in prediction data, message=FALSE, warning=FALSE}
#SafeGraph Features
bar.sf <- dat2 %>%
  filter(top_category == "Drinking Places (Alcoholic Beverages)") %>%
  dplyr::select(location_name) %>%
  st_as_sf(coords = "geometry", crs = 4326, agr = "constant")

restaurant.sf <- dat2 %>%
  filter(top_category == "Restaurants and Other Eating Places") %>%
  dplyr::select(location_name) %>%
  st_as_sf()

arts.sf <- dat2 %>%
  filter(top_category == "Promoters of Performing Arts, Sports, and Similar Events" |
           top_category == "Performing Arts Companies") %>%
  dplyr::select(location_name) %>%
  st_as_sf()

# college.sf <- dat2 %>%
#   filter(top_category == "Colleges, Universities, and Professional Schools") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

sports.sf <- dat2 %>%
  filter(top_category == "Spectator Sports") %>%
  dplyr::select(location_name) %>%
  st_as_sf()

# casinos.sf <- dat2 %>%
#   filter(sub_category == "Casino Hotels") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

# hotels.sf <- dat2 %>%
#   filter(sub_category == "Hotels (except Casino Hotels) and Motels") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

# parking.sf <- dat2 %>%
#   filter(sub_category == "Parking Lots and Garages") %>%
#   dplyr::select(location_name) %>%
#   st_as_sf()

#Philadelphia Features
phl_corridors_pred <- phl_corridors %>%
  st_as_sf() %>%
  dplyr::select(4:5,18, 'corr_type') %>%
  rename(., corridor = NAME,
         district = P_DIST,
         vacancy_rate = VAC_RATE) %>%
  mutate(vacancy_rate = str_remove_all(vacancy_rate, pattern = "%"),
         vacancy_rate = str_remove_all(vacancy_rate, pattern = "\r\n"),
         vacancy_rate = as.numeric(vacancy_rate),
         corr_area_sqft = as.numeric(st_area(phl_corridors)),
         corr_area_sqmi = as.numeric(st_area(phl_corridors)*0.000000035870))

phl_corridors_pred$vacancy_rate <- phl_corridors_pred$vacancy_rate %>% replace_na(0)

# phl_dist <-
#   st_read("http://data.phl.opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson",
#           quiet = TRUE) %>%
#   st_transform('ESRI:102728')

# phl_nhoods <- 
#   st_read("https://raw.githubusercontent.com/azavea/geo-data/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson", quiet = TRUE) %>%
#   st_transform('ESRI:102728') %>%
#   dplyr::select(mapname) %>%
#   dplyr::rename(., neighborhood = mapname)

# CenterCity.sf <- phl_dist %>% 
#   dplyr::select(DIST_NAME) %>%
#   filter(DIST_NAME == "Central") %>%
#   st_centroid()

# CityHall.sf <- 
#   dat3 %>% 
#   dplyr::select(location_name, date_range_start, top_category) %>%
#   filter(location_name == "City Hall", date_range_start == "2018-01-01T05:00:00Z")

# Temple.sf <- 
#   dat3 %>% 
#   dplyr::select(location_name, date_range_start, top_category) %>%
#   filter(location_name == "Temple University", 
#          top_category == "Colleges, Universities, and Professional Schools",
#          date_range_start == "2018-01-01T05:00:00Z")

UPenn.sf <- 
  dat3 %>% 
  dplyr::select(location_name, date_range_start, top_category) %>%
  filter(location_name == "Univ of Penn",
         top_category == "Colleges, Universities, and Professional Schools",
         date_range_start == "2018-01-01T05:00:00Z")

septaStops <- 
  rbind(
    st_read("https://opendata.arcgis.com/datasets/8c6e2575c8ad46eb887e6bb35825e1a6_0.geojson", quiet = TRUE) %>% 
      dplyr::mutate(Line = "El") %>% 
      st_transform('ESRI:102728') %>%
      dplyr::select(Station, Line),
    st_read("https://opendata.arcgis.com/datasets/2e9037fd5bef406488ffe5bb67d21312_0.geojson", quiet = TRUE) %>%
      dplyr::mutate(Line ="Broad_St") %>%
      st_transform('ESRI:102728') %>%
      dplyr::select(Station, Line)) 

parks <-
  st_read("https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson", 
          quiet = TRUE) %>%
  st_transform('ESRI:102728') %>%
  dplyr::select(PUBLIC_NAME)

phl_building_footprints <-
  st_read("https://opendata.arcgis.com/datasets/ab9e89e1273f445bb265846c90b38a96_0.geojson", 
          quiet = TRUE) %>%
  dplyr::select(ADDRESS) %>%
  st_transform('ESRI:102728')

phl_building_footprints <- phl_building_footprints %>%
  dplyr::mutate(bld_area_sqft = as.numeric(st_area(phl_building_footprints)),
         bld_area_sqmi = as.numeric(st_area(phl_building_footprints)*0.000000035870))

# phl_busstop <-
#   st_read("https://opendata.arcgis.com/datasets/e09e9f98bdf04eada214d2217f3adbf1_0.geojson") %>%
#   st_transform('ESRI:102728') %>%
#   .[phl_boundary,] %>%
#   filter(Mode == "Bus")

phl_trolley <-
  st_read("https://opendata.arcgis.com/datasets/e09e9f98bdf04eada214d2217f3adbf1_0.geojson") %>%
  st_transform('ESRI:102728') %>%
  .[phl_boundary,] %>%
  filter(Mode == "Trolley")

#Demographic data
phl_blockgroups <- 
  get_acs(geography = "block group", 
          variables = c("B01003_001E", 
                        "B02001_002E", 
                        "B01002_001E",
                        "B19013_001E", 
                        "B25064_001E"
                        # "B03002_012E",
                        # "B02001_003E"
                        ),
          year=2018, 
          state=42, 
          county=101, 
          geometry=T, 
          output = "wide") %>%
  st_transform('ESRI:102728')%>%
  dplyr::rename(TotalPop = B01003_001E,
                White = B02001_002E,
                MedAge = B01002_001E,
                MedHHInc = B19013_001E,
                MedRent = B25064_001E,
                # Hisp = B03002_012E,
                # Black = 	B02001_003E,
                GEOID10 = GEOID) %>%
  dplyr::select(-ends_with("M")) %>%
  dplyr::mutate(pctWhite = ((White / TotalPop)*100),
                # pctBlack = ((Black / TotalPop)*100),
                # pctHisp = ((Hisp / TotalPop)*100),
                tract_area_mi = as.numeric(st_area(geometry)*0.000000035870),
                popdens_mi = TotalPop / tract_area_mi
         ) %>%
  st_as_sf()

st_c <- st_coordinates
```

## Feature Engineering
Because we are looking to predict nighttime trips, we must isolate the trips that occur during the evening hours as our depedent variable. The folowing code aggregates datasets created above into a new dataframe that includes Philadelphia information, buildings and data by hourly trips. The dataframe drops all trips with destiantions outside of commercial corridors.
```{r}
dat_pred_temp <- 
  dat2 %>% 
  left_join(dat_1_6, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_7_12, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_13_18, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_19_0, by = c('safegraph_place_id', 'date_range_start')) %>%
  left_join(dat_workday, by = c('safegraph_place_id', 'date_range_start')) %>%
  st_join(phl_blockgroups) %>%
  st_join(phl_nhoods) %>%
  st_join(phl_corridors_pred) %>%
  st_join(., phl_building_footprints) %>%
  drop_na(corridor)
```

Our features fall broadly into the following categories:

* *Philadelphia summary Features*: These are features that capture the built environment, such as the averaage size of the buildings along the corridor and the area of the corridor. 
* *SafeGraph global Features*:  These are variables provided by SafeGraph to explain visitor behavior at various points of interest. This includes the average distance from home a visitor travels to a destination  or how long they spend at a destination. These have been aggregated up to the corridor level.
* *Normalized Count Features*: These features normalize the number of amenities (business types, institutions) by the area of a given corridor.
* *Nearest Neighbor Features*: These features capture nearest neighbor distance to other Philadelphia amenities, such as parks, transit and Center City.
* *Demographic Features*: Pulled from the census, these features capture racial, and socio economic characteristics at the corridor level.

Next we wrangle the data to aggregate it at the corridor level. To start, we are looking at aggregated SafeGraph variables, such as median dwell time and average distance from home. 

We also review the share of certain business types and characteristics along a specific corridor. These variables count the SafeGraph points of interest that fit into given category (bars, restaurants, college) and divide it by hte total number of businesses along the corridor. We also divide by 12 since the data is disaggregated by month.

Finally, this code generates nearest neighbor variables for business by corridor.
```{r Observe correlations}
#Engineer variables at the destination level.
dat_pred <-
  dat_pred_temp %>%
  dplyr::mutate(total = 1,
         bars = ifelse(top_category == 'Drinking Places (Alcoholic Beverages)', 1, 0),
         restaurant = ifelse(top_category == 'Restaurants and Other Eating Places', 1, 0),
         arts = ifelse(top_category == 'Promoters of Performing Arts, Sports, and Similar Events' |
                         top_category == 'Performing Arts Companies', 1, 0),
         grocery = ifelse(top_category == 'Grocery Stores', 1, 0),
         # childcare = ifelse(top_category == "Child Day Care Services", 1, 0),
         # gas = ifelse(top_category == "Gasoline Stations", 1, 0),
         # religious = ifelse(top_category == "Religious Organization", 1, 0),
         # personal = ifelse(top_category == "Personal Care Services", 1, 0),
         # liquor = ifelse(top_category == "Beer, Wine, and Liquor Stores", 1, 0),
         # amusement = ifelse(top_category == 'Other Amusement and Recreation Industries', 1, 0),
         # college = ifelse(top_category == 'Colleges, Universities, and Professional Schools', 1, 0),
         sports = ifelse(top_category == 'Spectator Sports', 1, 0),
         # museum = ifelse(top_category == 'Museums, Historical Sites, and Similar Institutions', 1, 0),
         # hotels = ifelse(top_category == 'Traveler Accommodation', 1, 0),
         transit_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(septaStops)), 2),
         # bars_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(bar.sf)), 4),
         # rest_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(restaurant.sf)), 4),
         # arts_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(arts.sf)), 4),
         # college_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(college.sf)), 1),
         # sports_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(sports.sf)), 1),
         # hotels_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(hotels.sf)), 4),
         # casinos_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(casinos.sf)), 1),
         parks_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(parks)), 4),
         # parking_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(parking.sf)), 1),
         # busstop_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(phl_busstop)), 4),
         trolley_nn = nn_function(st_c(st_centroid(dat_pred_temp)), st_c(st_centroid(phl_trolley)), 4),
         late_night = if_else(grepl("Late Night", dat_pred_temp$category_tags), 1, 0),
         # bar_pub = if_else(grepl("Bar or Pub", dat_pred_temp$category_tags), 1, 0),
         # drinks = if_else(grepl("Drinks", dat_pred_temp$category_tags), 1, 0),
         # cocktail = if_else(grepl("Cocktail Lounge", dat_pred_temp$category_tags), 1, 0),
         # SocHill = if_else(neighborhood == "Society Hill", 1, 0),
         # UCity = if_else(neighborhood == "University City", 1, 0),
         # NavyYard = if_else(neighborhood == "Navy Yard", 1, 0),
         # PM_Workday = Hrs19_0 / Hrs_workday,
         # AM_PM = (Hrs1_6 + Hrs7_12) / (Hrs13_18+Hrs19_0),
         # restaurant_sqft = ifelse(top_category == "Restaurants and Other Eating Places", bld_area_sqft, 0),
         # bars_sqft = ifelse(top_category == "Drinking Places (Alcoholic Beverages)", bld_area_sqft, 0),
         closing_time = ifelse(str_detect(open_hours, paste(c("20:00", "21:00", "22:00", "23:00", "0:00", "1:00", "2:00", "3:00"), collapse = "|")), "OPEN LATE", "NOT OPEN LATE"),
         closing_time = ifelse(is.na(closing_time) == TRUE, "NO DATA", closing_time),
         open_late = ifelse(closing_time == "OPEN LATE", 1, 0)
	)

# dat_pred$CenterCity <- as.numeric(st_distance(dat_pred, CenterCity.sf))
# dat_pred$CityHall <- as.numeric(st_distance(dat_pred, CityHall.sf))
# dat_pred$Temple <- as.numeric(st_distance(dat_pred, Temple.sf))
dat_pred$UPenn <- as.numeric(st_distance(dat_pred, UPenn.sf))

#Aggregating up to the corridor level
dat_pred_agg <- 
  dat_pred %>%
  group_by(corridor, date_range_start, corr_type) %>%
  summarize(Night_visits = sum(Hrs19_0),
            Workday_visits = sum(Hrs_workday),
            phl_area_sqmi = mean(corr_area_sqmi, na.rm = TRUE),
            Night_visits_sqmi = (Night_visits + 1) / phl_area_sqmi,
            Night_visits_sqmi_log = log(Night_visits_sqmi),
            Workday_visits_sqmi = (Workday_visits +1) / phl_area_sqmi,
            Workday_visits_sqmi_log = log(Workday_visits_sqmi),
            total = sum(total),
            phl_building_size = mean(bld_area_sqft +1, na.rm = TRUE),
            phl_building_size_log = log(phl_building_size),
            # phl_building_size_med = median(bld_area_sqft, na.rm = TRUE),
            # phl_CenterCity = mean(CenterCity),
            # phl_CityHall = mean(CityHall),
            # phl_CityHall_log = log(phl_CityHall),
            # phl_Temple = mean(Temple),
            phl_UPenn = mean(UPenn),
            # phl_vacrate = mean(vacancy_rate + 1),
            # phl_vacrate_log = log(phl_vacrate),
            # phl_rest_sqft = mean(restaurant_sqft +1,na.rm = T),
            # phl_rest_sqft_log = log(phl_rest_sqft),
            # phl_bar_sqft = mean(bars_sqft +1, na.rm = T),
            # phl_bar_sqft_log = log(phl_bar_sqft),
            # sg_visitors = sum(raw_visitor_counts),
            # sg_visits = sum(raw_visit_counts),
            sg_dwell = mean(median_dwell, na.rm = TRUE),
            sg_distance_home = mean(distance_from_home, na.rm = TRUE),
            # sg_workday = mean(PM_Workday, na.rm = TRUE),
            # sg_AM_PM = mean(AM_PM, na.rm = TRUE),
            sg_distance_home_log = log(sg_distance_home),
            count_bars_a = (sum(bars, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_rest_a = (sum(restaurant, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_arts_a = (sum(arts, na.rm = TRUE) +1)/phl_area_sqmi,
            # count_jrcol_a = sum(jrcol, na.rm = TRUE)/phl_area_sqmi,
            # count_college_a = (sum(college, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_sports_a = (sum(sports, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_museums_a = (sum(museum, na.rm = TRUE)  + 1)/phl_area_sqmi,
            # count_amuse_a = (sum(amusement, na.rm = TRUE)  + 1)/phl_area_sqmi,
            # count_hotels_a = (sum(hotels, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_grocery_a = (sum(grocery, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_childcare_a = (sum(childcare, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_gas_a = (sum(gas, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_religious_a = (sum(religious, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_personal_a = (sum(personal, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_retailmix_top = n_distinct(top_category),
            count_retailmix_sub = n_distinct(sub_category),
            count_late_tag = (sum(late_night, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_barpub_tag = (sum(bar_pub, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_drinks_tag = (sum(drinks, na.rm = TRUE) + 1)/phl_area_sqmi,
            # count_cocktail_tag = (sum(cocktail, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_openlate = (sum(open_late, na.rm = TRUE) + 1)/phl_area_sqmi,
            count_bars_a_log = log(count_bars_a),
            count_rest_a_log = log(count_rest_a),
            count_arts_a_log = log(count_arts_a),
            count_grocery_a_log = log(count_grocery_a),
            # count_religious_a_log = log(count_religious_a),
            # count_childcare_a_log = log(count_childcare_a),
            # log_jrcol_a = log(sum(jrcol, na.rm = TRUE)/phl_area_sqmi),
            # log_college_a = log(sum(college, na.rm = TRUE)/phl_area_sqmi),
            # log_sports_a = log(sum(sports, na.rm = TRUE)/phl_area_sqmi),
            # log_museums_a = log(sum(museum, na.rm = TRUE)/phl_area_sqmi),
            # count_amuse_a_log = log(count_amuse_a),
            # count_barpub_log = log(count_barpub_tag),
            count_late_log = log(count_late_tag),
            count_retailmix_top_log = log(count_retailmix_top),
            count_retailmix_sub_log = log(count_retailmix_sub),
            count_openlate_log = log(count_openlate),
            nn_transit = mean(transit_nn),
            nn_parks = mean(parks_nn),
            # nn_parking = mean(parking_nn),
            # nn_busstop = mean(busstop_nn),
            nn_trolley = mean(trolley_nn),
            # nn_bars = mean(bars_nn),
            # nn_rest = mean(rest_nn),
            # nn_arts = mean(arts_nn),
            # nn_college = mean(college_nn),
            # nn_sports = mean(sports_nn),
            # nn_casinos = mean(casinos_nn),
            # nn_hotels = mean(hotels_nn),
            nn_parks_log = log(nn_parks),
            nn_transit_log = log(nn_transit),
            # nn_parking_log = log(nn_parking),
            # nn_busstop_log = log(nn_busstop),
            nn_trolley_log = log(nn_trolley),
            demo_popdens = mean(popdens_mi),
            demo_popdens_log = log(demo_popdens),
            demo_pctWhite = weighted.mean(pctWhite, Hrs19_0, na.rm = TRUE),
            # demo_pctBlack = weighted.mean(pctBlack, Hrs19_0, na.rm = TRUE),
            # demo_pctHisp = weighted.mean(pctHisp, Hrs19_0, na.rm = TRUE),
            # demo_pctHisp_log = log(demo_pctHisp + 1),
            demo_medAge = weighted.mean(MedAge, Hrs19_0, na.rm = TRUE),
            demo_MHI = weighted.mean(MedHHInc, Hrs19_0, na.rm = TRUE),
            demo_medrent = weighted.mean(MedRent, Hrs19_0, na.rm = TRUE)) %>% 
  # mutate_if(is.numeric, list(~na_if(., Inf))) %>%
  st_drop_geometry() %>%
  left_join(phl_corridors_pred %>% dplyr::select(corridor)) %>%
  drop_na(corridor, demo_MHI, demo_medrent) %>% #Some of the census variables aren't reporting for our block groups
  st_as_sf() %>%
  ungroup() %>%
  na.omit(st_distance_home)
```

### Linear Model

Using the features we engineered above, we split our data into a training and test set and run a linear regression model in the following code block. The results of the regression are shown below.
```{r model building}
#Setting up test and training datasets
set.seed(414)
inTrain <- createDataPartition(y=dat_pred_agg$Night_visits_sqmi_log, p = .60, list = FALSE)

phl.training <- dat_pred_agg[inTrain,]
phl.test <- dat_pred_agg[-inTrain,]

reg.vars <- c('Night_visits_sqmi_log',
              'phl_building_size_log',
              'phl_UPenn',
              'sg_distance_home_log',
              'sg_dwell',
              'count_bars_a_log',
              'count_rest_a_log',
              'count_arts_a_log',
              'count_grocery_a_log',
              'count_sports_a',
              'count_retailmix_top',
              'count_retailmix_sub_log',
              'count_openlate_log',
              'nn_transit_log',
              'nn_parks_log',
              'nn_trolley',
              'count_late_tag',
              'corr_type',
              'count_late_log',
              'demo_pctWhite',
              'demo_medAge',
              'demo_popdens',
              'demo_medrent',
              'demo_MHI')

#Multivariate Linear regression
reg1 <- 
  lm(Night_visits_sqmi_log ~ ., #change lm to ranger, predictions are a little different
     data = st_drop_geometry(phl.training) %>% 
       dplyr::select(reg.vars))
             
summary(reg1)
```

### Model Errors

Both models' errors are summarized in the following table. Currently we see that the subset of data does not have a particularly noticeable impact on the model's accuracy.

```{r, out.width = "100%"}
phl.test_table <-
  phl.test %>%
  st_drop_geometry() %>%
  mutate(Regression = "Linear Regression",
         Visits.Predict = exp(predict(reg1, phl.test)),
         Visits.Error = Visits.Predict - Night_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Night_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Night_visits_sqmi)) / Visits.Predict)

ErrorTable <-
  phl.test_table %>%
  dplyr::summarize(Regression = "Linear Regression",
                   MAE = mean(Visits.AbsError, na.rm = T),
                   MAPE = mean(Visits.AbsError, na.rm = T) / mean(Night_visits_sqmi, na.rm = T))

ErrorTable %>% 
  group_by(Regression) %>%
  arrange(desc(MAE)) %>% 
  kable(caption = "MAE and MAPE for Test Set Data") %>% kable_styling()
```

The following chart compares the predicted values to the actual values for the training and test sets for the full dataset. The predicted value (green line) actually lines up pretty well with the actual value (orange line). We are underpredicting in both the training and the tests sets. 
```{r pred actual scatterplot, out.width = "100%"}
reg1_predict <- exp(predict(reg1, newdata = phl.test))

rmse.train <- caret::MAE(exp(predict(reg1)), phl.training$Night_visits_sqmi)
rmse.test <- caret::MAE(reg1_predict, phl.test$Night_visits_sqmi)

preds.train <- data.frame(pred   = exp(predict(reg1)),
                          actual = phl.training$Night_visits_sqmi,
                          source = "training data")
preds.test  <- data.frame(pred   = reg1_predict,
                          actual = phl.test$Night_visits_sqmi,
                          source = "testing data")

preds <- rbind(preds.train, preds.test)

ggplot(preds, aes(x = pred, y = actual, color = source)) +
  geom_point() +
  geom_smooth(method = "lm", color = "green") +
  geom_abline(color = "orange") +
  theme_bw() +
  coord_equal() +
  facet_wrap(~source, ncol = 2) +
  labs(title = "Comparing predictions to actual values",
       x = "Predicted Value",
       y = "Actual Value",
       subtitle = "Figure X.X") +
  theme(
    legend.position = "none"
  )
```

### Cross Validation

We also test for generalizability with cross validation for the full dataset with the below code. The plot shows the Mean Average Error across 100 folds. 
```{r, out.width = "100%"}
fitControl <- trainControl(method = "cv", 
                           number = 10,
                           savePredictions = TRUE)

set.seed(414)
reg1.cv <- 
  train(Night_visits_sqmi_log ~ ., data = st_drop_geometry(dat_pred_agg) %>% 
          dplyr::select(reg.vars), 
        method = "lm", 
        trControl = fitControl, 
        na.action = na.pass)

reg1.cv.resample <- reg1.cv$resample

reg1.cv 
ErrorHist <- 
  ggplot(reg1.cv.resample, aes(x=MAE)) + 
  geom_histogram(color = "grey40", fill = "#27fdf5", bins = 50) + 
  labs(title="Linear Model: Histogram of Mean Average Error Across 100 Folds",
       subtitle = "Figure X.X") +
  plotTheme()

ErrorHist
```

### Mapping Errors & Errors by Corridor Type

Finally, we map the errors by commercial corridor in the following figures. The absolute errors indicate that our model is less accurate predicting nighttime traffic for larger, more heavily-trafficked corridors. The Percent Errors map on the right, actually tells a slightly different story with the highest quintile of percent error along the smaller corridors throughout the city. 
```{r, out.width = "100%"}
cv_preds <- reg1.cv$pred

map_preds <- dat_pred_agg %>% 
  rowid_to_column(var = "rowIndex") %>% 
  left_join(cv_preds, by = "rowIndex") %>%
  group_by(corridor, corr_type) %>% #CONFIRM THIS APPROACH WITH MATT!
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            pred = mean(pred)) %>% 
  dplyr::mutate(Visits.AbsError = abs(exp(pred) - Night_visits_sqmi),
         PercentError = (Visits.AbsError / Night_visits_sqmi)*100) 

#Quintile maps
ErrorPlot1 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds, aes(fill = q5(Visits.AbsError)), color = "transparent") +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds,"Visits.AbsError"),
                      name="Quintile\nBreaks") +
  labs(title="Absolute Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

ErrorPlot2 <- ggplot() +
  geom_sf(data = phl_boundary, fill = "grey80", color = "grey40") +
  geom_sf(data = map_preds, aes(fill = q5(PercentError)), color = "transparent") +
  scale_fill_manual(values = palette5,
                      labels=qBr(map_preds, "PercentError"),
                      name="Quintile\nBreaks") +
  labs(title="Percent Errors",
       subtitle = "Night Visit Predictions",
       caption = "Figure X.X") +
  mapTheme()

grid.arrange(ErrorPlot1, ErrorPlot2, ncol=2)
```

The following table summarizes error by corridor type.
```{r}
#Comparing errors by corr type
map_preds_corr <- 
  map_preds %>%
  dplyr::mutate(MAE = round(abs(exp(pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(corr_type) %>% 
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>% 
  st_drop_geometry() %>%
  dplyr::select(corr_type, MAE, MAPE)

map_preds_corr[order(factor(map_preds_corr$corr_type, 
                            levels = c("Neighborhood Subcenter",
                                       "Neighborhood Center",
                                       "Community Center",
                                       "Regional Center",
                                       "Superregional Center",
                                       "Speciality Center"))),] %>%
  kable(caption = "Errors by Corridor Type") %>%
  kable_styling()
```

## Random Forest Model

### Feature Selection

To cope with the non-linearity in the model, we also tried the same features in a random forest model. In the below summary table, we see much improvement in the error terms (21% down from about 40%) and a .7 R squared.
```{r ranger}
set.seed(414)
inTrain <- createDataPartition(y=dat_pred_agg$Night_visits_sqmi_log, p = .60, list = FALSE)

phl.training.rf <- dat_pred_agg[inTrain,]
phl.test.rf <- dat_pred_agg[-inTrain,]

#Multivariate regression
rf1 <- 
  ranger(Night_visits_sqmi_log ~ ., #change lm to ranger, predictions are a little different
     data = st_drop_geometry(phl.training.rf) %>%
             dplyr::select(reg.vars),
     importance = "impurity")

rf1
```

### Hypertuning Parameters
```{r}
set.seed(414)

phl.training.rf_fit <- dat_pred_agg[inTrain,]
phl.test.rf_fit <- dat_pred_agg[-inTrain,]

data_split <- initial_split(dat_pred_agg, strata = "Night_visits_sqmi_log", prop = 0.60)

model_rec <- recipe(Night_visits_sqmi_log ~ ., data = phl.training.rf %>% 
                      dplyr::select(reg.vars) %>% 
                      st_drop_geometry())

#Splitting by month
cv_splits_time <- group_vfold_cv(phl.training.rf%>%
                      dplyr::select(date_range_start, reg.vars) %>%
                      st_drop_geometry(),
                      strata = "Night_visits_sqmi_log",
                      group = "date_range_start")

rf_plan <- rand_forest() %>%
  set_args(mtry  = tune()) %>%
  set_args(min_n = tune()) %>%
  set_args(trees = 1000) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("regression")

#Setting parameters to try
rf_grid <- expand.grid(mtry = c(2, 5, 10, 15, 20), 
                       min_n = c(5, 10, 50))

rf_wf <-
  workflow() %>% 
  add_recipe(model_rec) %>% 
  add_model(rf_plan)

control <- control_resamples(save_pred = TRUE, verbose = TRUE)

#Test hyperparameters
rf_tuned_time <- rf_wf %>%
  tune::tune_grid(.,
                  resamples = cv_splits_time,
                  grid      = rf_grid,
                  control   = control,
                  metrics   = metric_set(rmse, rsq))

show_best(rf_tuned_time, metric = "rmse", n = 15)

rf_best_params_time  <- select_best(rf_tuned_time, metric = "rmse")

rf_best_wf_time <- finalize_workflow(rf_wf, rf_best_params_time)

rf_val_fit_time <- rf_best_wf_time %>% 
  last_fit(split     = data_split,
           control   = control,
           metrics   = metric_set(mae, rsq))

rf_val_fit_time$.metrics
```

### Feature Importance
```{r}
library(vip)
rf_val_fit_time %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 23) +
  plotTheme() +
  labs(title = "Random Forest Model Feature Importance", 
         subtitle = "Figure X.X")
```

### Evaluating Errors
```{r}
rf1_predict.train_fit <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(phl.training.rf_fit))
rf1_predict.train_fit <- exp(rf1_predict.train_fit %>% as.data.frame())

rf1_predict.test_fit <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(phl.test.rf_fit))
rf1_predict.test_fit <- exp(rf1_predict.test_fit %>% as.data.frame())  

rmse.train.rf_fit <- caret::MAE(rf1_predict.train_fit, phl.training.rf$Night_visits_sqmi)
rmse.test.rf_fit <- caret::MAE(rf1_predict.test_fit, phl.test.rf$Night_visits_sqmi)

preds.train.rf_fit <- data.frame(pred   = rf1_predict.train_fit,
                          actual = phl.training.rf$Night_visits_sqmi,
                          source = "training data")
preds.test.rf_fit <- data.frame(pred   = rf1_predict.test_fit,
                          actual = phl.test.rf$Night_visits_sqmi,
                          source = "testing data")

preds.rf_fit <- rbind(preds.train.rf_fit, preds.test.rf_fit)

ggplot(preds.rf_fit, aes(x = .pred, y = actual, color = source)) +
  geom_point() +
  geom_smooth(method = "lm", color = "green") +
  geom_abline(color = "orange") +
  theme_bw() +
  coord_equal() +
  facet_wrap(~source, ncol = 2) +
  labs(title = "Comparing predictions to actual values - Random Forest Model",
       x = "Predicted Value",
       y = "Actual Value",
       subtitle = "Figure X.X") +
  theme(
    legend.position = "none"
  )
```

Something's wrong here!

```{r, out.width = "100%"}
phl.test.rf_table <-
  phl.test.rf %>%
  st_drop_geometry() %>%
  mutate(Regression = "Random Forest Regression",
         Visits.Predict = rf1_predict.test,
         Visits.Error = Visits.Predict - Night_visits_sqmi,
         Visits.AbsError = abs(Visits.Predict - Night_visits_sqmi),
         Visits.APE = (abs(Visits.Predict - Night_visits_sqmi)) / Visits.Predict)

rbind(phl.test.rf_table, phl.test_table) %>%
  group_by(Regression) %>%
  dplyr::summarize(MAE = mean(Visits.AbsError, na.rm = T),
                   MAPE = mean(Visits.APE, na.rm = T) / mean(Night_visits_sqmi, na.rm = T)) %>% 
  kable(caption = "MAE and MAPE for Test Set Data") %>% kable_styling()
```


```{r}
set.seed(414)
folds <- vfold_cv(dat_pred_agg, v = 10)

reg1.cv.rf <- rf_best_wf_time %>% fit_resamples(folds, metrics = metric_set(mae)) 

reg1.cv.rf <- collect_metrics(reg1.cv.rf, summarize = FALSE) 

rbind(reg1.cv.resample %>% 
        mutate(Regression = "Linear Model") %>% 
        dplyr::select(MAE, Regression), 
      reg1.cv.rf %>% 
        mutate(Regression = "Random Forest Model") %>% 
        dplyr::select(.estimate, Regression) %>%
        dplyr::rename("MAE" = ".estimate")) %>%
  ggplot(aes(x=MAE)) + 
  geom_histogram(color = "grey40", fill = "#27fdf5", bins = 50) + 
  labs(title="Full Dataset: Histogram of Mean Average Error Across 10 Folds",
       subtitle = "Figure X.X") +
  facet_wrap(~Regression, ncol = 1) +
  scale_x_continuous(name = "Mean Average Error") +
  scale_y_continuous(name = "Count") +
  plotTheme()
```

### Leave One Group Out Cross Validation
```{r}
rf1_predict.full <- predict(rf_val_fit_time$.workflow, new_data = st_drop_geometry(dat_pred_agg))
# rf1_predict.full <- exp(rf1_predict.full %>% as.data.frame())

# cv_preds_rf <- rf_val_fit_time$.predictions %>% as.data.frame()

map_preds_rf <- dat_pred_agg %>% cbind(rf1_predict.full) #NOT SURE THIS IS RIGHT!

#Comparing errors by time
map_preds_rf %>%
  dplyr::mutate(MAE = round(abs(exp(.pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(date_range_start) %>% 
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>% 
  st_drop_geometry() %>%
  dplyr::select(date_range_start, MAE, MAPE) %>%
  mutate(date_range_start = str_remove_all(date_range_start, pattern = "T05:00:00Z"),
         date_range_start = str_remove_all(date_range_start, pattern = "T04:00:00Z")) %>%
  kable(caption = "Errors by Month") %>%
  kable_styling()

#Comparing errors by corr type
map_preds_corr_rf <- 
  map_preds_rf %>%
  dplyr::mutate(MAE = round(abs(exp(.pred) - Night_visits_sqmi),2),
                MAPE = round((MAE / Night_visits_sqmi)*100,2)) %>%
  group_by(corr_type) %>% 
  summarise(Night_visits_sqmi = mean(Night_visits_sqmi),
            MAE = mean(MAE),
            MAPE = mean(MAPE)) %>% 
  st_drop_geometry() %>%
  dplyr::select(corr_type, MAE, MAPE)

map_preds_corr_rf[order(factor(map_preds_corr_rf$corr_type, 
                            levels = c("Neighborhood Subcenter",
                                       "Neighborhood Center",
                                       "Community Center",
                                       "Regional Center",
                                       "Superregional Center",
                                       "Speciality Center"))),] %>%
  kable(caption = "Errors by Corridor Type") %>%
  kable_styling()
```

NEED TO ADD WORKDAY MODEL

#App Development

```{r}
#Funcion to generate a grid with the combinations.
ComboGrid <- function(rest_factor, bar_factor, arts_factor) {
  
  allCombos <- expand.grid(rest_factor = rest_factor*100,
                           bar_factor = bar_factor*100,
                           arts_factor = arts_factor*100) 
  
  allCombos <- tibble::rowid_to_column(allCombos, "scenario")
  
  allCombos <- 
    allCombos %>% 
    mutate(
      rest = "rest",
      bars = "bars",
      arts = "arts")
  
  allCombos <- allCombos %>%
    mutate(
      filename = 
        paste(allCombos$rest,
      allCombos$rest_factor, 
      allCombos$bars, 
      allCombos$bar_factor, 
      allCombos$arts, 
      allCombos$arts_factor, sep = "-"))
  
  return(allCombos)
}

#Function to generate separate dataframes for each of the scenarios
ScenarioGenerator <- function(dataset, corr_list, rest_factor, bar_factor, arts_factor) {

  allCombos <- expand.grid(rest_factor = rest_factor,
                           bar_factor = bar_factor,
                           arts_factor = arts_factor) 

  allCombos <- tibble::rowid_to_column(allCombos, "ID")

  comboList <- unique(allCombos[['ID']])
  allScenarios <- data.frame()

for (i in comboList) {
    
  thisScenario <-
    dataset %>%
    dplyr::mutate(scenario = as.numeric(allCombos %>% filter(ID==i) %>% dplyr::select(ID)),
                  count_rest = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(rest_factor)) * count_rest,
                  count_rest_a = count_rest/phl_area_sqmi,
                  count_rest_a_log = log(count_rest_a + 1),
                  count_bars = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(bar_factor)) * count_bars,
                  count_bars_a = count_bars/phl_area_sqmi,
                  count_bars_a_log = log(count_bars_a + 1),
                  count_arts = as.numeric(allCombos %>% filter(ID == i) %>% dplyr::select(arts_factor)) * count_arts,
                  count_arts_a = count_arts/phl_area_sqmi,
                  count_arts_a_log = log(count_arts_a + 1))
  
  Scenario_preds <- predict(rf1, data = thisScenario %>% as.data.frame())
  Scenario_preds <- exp(Scenario_preds$predictions) %>% as.data.frame()

  Scenario_final <- cbind(Scenario_preds, thisScenario %>%
                            dplyr::select(corridor,
                                          count_rest,
                                          count_arts,
                                          count_bars,
                                          Night_visits,
                                          phl_area_sqmi,
                                          scenario,
                                          geometry)) %>%
    dplyr::rename("predictions" = ".") %>% #clean-up
    mutate(predictions = predictions * phl_area_sqmi) %>%
    st_as_sf()

  Scenario_final <- Scenario_final %>% st_as_sf() %>% st_transform(crs = "EPSG: 4326")

  Scenario_final <- Scenario_final %>%
    group_by(corridor, scenario) %>%
    summarize(Night_visits = sum(Night_visits),
              predictions = sum(predictions))

  Scenario_final <-
    Scenario_final %>%
    # mutate(pct_change = (predictions - Night_visits)/Night_visits * 100) %>%
    mutate(pct_change = ifelse(corridor %in% corr_list, ((predictions - Night_visits)/Night_visits * 100), NA),
           predictions = ifelse(corridor %in% corr_list, predictions, NA)) %>%
    as.data.frame()  %>%
    left_join(., ScenarioCombos %>% dplyr::select(scenario, filename)) %>%
    st_as_sf()
  
  Scenario_final <- as_Spatial(Scenario_final)
  
  writeOGR(Scenario_final,
           dsn = paste(unique(Scenario_final$filename), ".geojson"),
           'allScenario_final_small',
           driver = 'GeoJSON')
  
}
  # return(Scenario_final)
}
```

Prepare dataset for function
```{r }
dat_scenario <-
  dat_pred %>%
  group_by(corridor, date_range_start) %>%
  summarize(count_rest = sum(restaurant, na.rm = TRUE),
            count_bars = sum(bars, na.rm = TRUE),
            count_arts = sum(arts, na.rm = TRUE)) %>%
  st_drop_geometry() %>%
  left_join(dat_pred_agg) %>%
  group_by(corridor) %>%
  drop_na(corridor, demo_MHI, demo_medrent)
```

Running the function
```{r}
rest_factor_select <- c(.95, 1, 1.05)
bar_factor_select <- c(.95, 1, 1.05)
arts_factor_select <- c(.95, 1, 1.05)

# corr_select <- dat_pred_agg %>% select(corridor) %>% st_drop_geometry() %>% unique() %>% head(20) %>% pull()
# corr_select <- dat_pred_agg %>% filter(corr_type == "Speciality Center") %>% select(corridor) %>% st_drop_geometry() %>% unique() %>% pull()

ScenarioCombos <- ComboGrid(rest_factor = rest_factor_select,
                            bar_factor = bar_factor_select,
                            arts_factor = arts_factor_select)

ScenarioGenerator(dataset = dat_scenario,
                          corr_list = c("2nd and Fairmount",
                                        "30th Street",
                                        "48th and Spruce",
                                        "5th and Olney",
                                        "Broad and Hunting Park",
                                        "Callowhill East",
                                        "City Avenue/50th-52nd",
                                        "Grant and the Boulevard",
                                        "Lancaster and Girard",
                                        "Lower Aramingo Avenue",
                                        "Presidential/Belair",
                                        "Snyder Avenue/17th-23rd",
                                        "Snyder Plaza and Columbus Commons"),
                          rest_factor = rest_factor_select,
                          bar_factor = bar_factor_select,
                          arts_factor = arts_factor_select)

# test95
# 
# test105 <- ScenarioGenerator(dataset = dat_scenario,
#                           corr_list = corr_select,
#                           rest_factor = rest_factor_select,
#                           bar_factor = bar_factor_select,
#                           arts_factor = arts_factor_select)
# test105
# 
# cbind(st_drop_geometry(test95) %>%select(corridor, pct_change),
#       st_drop_geometry(test105) %>%select(corridor, pct_change))


corr_list <- c("2nd and Fairmount",
               "30th Street",
               "48th and Spruce",
               "5th and Olney",
               "Broad and Hunting Park",
               "Callowhill East",
               "City Avenue/50th-52nd",
               "Grant and the Boulevard",
               "Lancaster and Girard",
               "Lower Aramingo Avenue",
               "Presidential/Belair",
               "Snyder Avenue/17th-23rd",
               "Snyder Plaza and Columbus Commons")

phl_corridors %>% filter(NAME %in% corr_list) %>%
  ggplot() +
  geom_sf(data = phl_boundary) +
  geom_sf(fill = "red", color = "red")


```